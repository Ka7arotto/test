1 void btrfs_clear_buffer_dirty(struct btrfs_trans_handle *trans,
2 			      struct extent_buffer *eb)
4 	struct btrfs_fs_info *fs_info = eb->fs_info;
5 	int num_folios;
7 	btrfs_assert_tree_write_locked(eb);
9 	if (trans && btrfs_header_generation(eb) != trans->transid)
10 		return;
21 	if (btrfs_is_zoned(fs_info)) {
22 		set_bit(EXTENT_BUFFER_ZONED_ZEROOUT, &eb->bflags);
23 		return;
26 	if (!test_and_clear_bit(EXTENT_BUFFER_DIRTY, &eb->bflags))
27 		return;
29 	percpu_counter_add_batch(&fs_info->dirty_metadata_bytes, -eb->len,
30 				 fs_info->dirty_metadata_batch);
32 	if (eb->fs_info->nodesize < PAGE_SIZE)
33 		return clear_subpage_extent_buffer_dirty(eb);
35 	num_folios = num_extent_folios(eb);
36 	for (int i = 0; i < num_folios; i++) {
37 		struct folio *folio = eb->folios[i];
39 		if (!folio_test_dirty(folio))
40 			continue;
41 		folio_lock(folio);
42 		btree_clear_folio_dirty(folio);
43 		folio_unlock(folio);
45 	WARN_ON(atomic_read(&eb->refs) == 0);