1 void page_cache_ra_order(struct readahead_control *ractl,
2 		struct file_ra_state *ra, unsigned int new_order)
4 	struct address_space *mapping = ractl->mapping;
5 	pgoff_t index = readahead_index(ractl);
6 	pgoff_t limit = (i_size_read(mapping->host) - 1) >> PAGE_SHIFT;
7 	pgoff_t mark = index + ra->size - ra->async_size;
8 	int err = 0;
9 	gfp_t gfp = readahead_gfp_mask(mapping);
11 	if (!mapping_large_folio_support(mapping) || ra->size < 4)
12 		goto fallback;
14 	limit = min(limit, index + ra->size - 1);
16 	if (new_order < MAX_PAGECACHE_ORDER) {
17 		new_order += 2;
18 		new_order = min_t(unsigned int, MAX_PAGECACHE_ORDER, new_order);
19 		new_order = min_t(unsigned int, new_order, ilog2(ra->size));
22 	filemap_invalidate_lock_shared(mapping);
23 	while (index <= limit) {
24 		unsigned int order = new_order;
27 		if (index & ((1UL << order) - 1))
28 			order = __ffs(index);
30 		while (index + (1UL << order) - 1 > limit)
31 			order--;
32 		err = ra_alloc_folio(ractl, index, mark, order, gfp);
33 		if (err)
34 			break;
35 		index += 1UL << order;
38 	if (index > limit) {
39 		ra->size += index - limit - 1;
40 		ra->async_size += index - limit - 1;
43 	read_pages(ractl);
44 	filemap_invalidate_unlock_shared(mapping);