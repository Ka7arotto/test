1 struct vm_area_struct *vma_merge(struct vma_iterator *vmi, struct mm_struct *mm,
2 			struct vm_area_struct *prev, unsigned long addr,
3 			unsigned long end, unsigned long vm_flags,
4 			struct anon_vma *anon_vma, struct file *file,
5 			pgoff_t pgoff, struct mempolicy *policy,
6 			struct vm_userfaultfd_ctx vm_userfaultfd_ctx,
7 			struct anon_vma_name *anon_name)
9 	struct vm_area_struct *curr, *next, *res;
10 	struct vm_area_struct *vma, *adjust, *remove, *remove2;
11 	struct vm_area_struct *anon_dup = NULL;
12 	struct vma_prepare vp;
13 	pgoff_t vma_pgoff;
14 	int err = 0;
15 	bool merge_prev = false;
16 	bool merge_next = false;
17 	bool vma_expanded = false;
18 	unsigned long vma_start = addr;
19 	unsigned long vma_end = end;
20 	pgoff_t pglen = (end - addr) >> PAGE_SHIFT;
21 	long adj_start = 0;
27 	if (vm_flags & VM_SPECIAL)
28 		return NULL;
31 	curr = find_vma_intersection(mm, prev ? prev->vm_end : 0, end);
33 	if (!curr ||			/* cases 1 - 4 */
34 	    end == curr->vm_end)	/* cases 6 - 8, adjacent VMA */
35 		next = vma_lookup(mm, end);
36 	else
37 		next = NULL;		/* case 5 */
39 	if (prev) {
40 		vma_start = prev->vm_start;
41 		vma_pgoff = prev->vm_pgoff;
44 		if (addr == prev->vm_end && mpol_equal(vma_policy(prev), policy)
45 		    && can_vma_merge_after(prev, vm_flags, anon_vma, file,
46 					   pgoff, vm_userfaultfd_ctx, anon_name)) {
47 			merge_prev = true;
48 			vma_prev(vmi);
53 	if (next && mpol_equal(policy, vma_policy(next)) &&
54 	    can_vma_merge_before(next, vm_flags, anon_vma, file, pgoff+pglen,
55 				 vm_userfaultfd_ctx, anon_name)) {
56 		merge_next = true;
60 	VM_WARN_ON(prev && addr <= prev->vm_start);
61 	VM_WARN_ON(curr && (addr != curr->vm_start || end > curr->vm_end));

187 static int userfaultfd_release(struct inode *inode, struct file *file)
189 	struct userfaultfd_ctx *ctx = file->private_data;
190 	struct mm_struct *mm = ctx->mm;
191 	struct vm_area_struct *vma, *prev;
193 	struct userfaultfd_wake_range range = { .len = 0, };
194 	unsigned long new_flags;
195 	VMA_ITERATOR(vmi, mm, 0);
197 	WRITE_ONCE(ctx->released, true);
199 	if (!mmget_not_zero(mm))
200 		goto wakeup;
210 	mmap_write_lock(mm);
211 	prev = NULL;
212 	for_each_vma(vmi, vma) {
213 		cond_resched();
214 		BUG_ON(!!vma->vm_userfaultfd_ctx.ctx ^
215 		       !!(vma->vm_flags & __VM_UFFD_FLAGS));
216 		if (vma->vm_userfaultfd_ctx.ctx != ctx) {
217 			prev = vma;
218 			continue;
220 		new_flags = vma->vm_flags & ~__VM_UFFD_FLAGS;
221 		prev = vma_merge(&vmi, mm, prev, vma->vm_start, vma->vm_end,
