,raw_predictions,correctly_predicted,ground_truths
0,<S2SV_ModStart> ( unsigned int ) gsm -> len == 0 ) gsm -> state = GSM_DATA ; break ; <S2SV_ModEnd>,0,<S2SV_ModStart> >= MAX_MRU ) { gsm -> bad_size ++ ; gsm -> state = GSM_SEARCH ; } else if ( gsm -> count >= gsm -> len ) { gsm -> state = GSM_FCS ; } <S2SV_ModEnd>
1,<S2SV_ModStart> ( unsigned int ) c ; <S2SV_ModEnd>,0,<S2SV_ModStart> >= MAX_MRU ) { gsm -> bad_size ++ ; gsm -> state = GSM_SEARCH ; } else if ( gsm -> count >= gsm -> len ) { gsm -> state = GSM_FCS ; } <S2SV_ModEnd>
2,<S2SV_ModStart> ( unsigned int ) gsm -> len == 0 ) gsm -> state = GSM_DATA ; <S2SV_ModEnd>,0,<S2SV_ModStart> >= MAX_MRU ) { gsm -> bad_size ++ ; gsm -> state = GSM_SEARCH ; } else if ( gsm -> count >= gsm -> len ) { gsm -> state = GSM_FCS ; } <S2SV_ModEnd>
3,<S2SV_ModStart> ( unsigned int ) gsm -> len == 0 ) gsm -> state = GSM_SOF ; <S2SV_ModEnd>,0,<S2SV_ModStart> >= MAX_MRU ) { gsm -> bad_size ++ ; gsm -> state = GSM_SEARCH ; } else if ( gsm -> count >= gsm -> len ) { gsm -> state = GSM_FCS ; } <S2SV_ModEnd>
4,<S2SV_ModStart> ( unsigned int ) gsm -> len == 0 ) { gsm -> state = GSM_DATA ; break ; } <S2SV_ModEnd>,0,<S2SV_ModStart> >= MAX_MRU ) { gsm -> bad_size ++ ; gsm -> state = GSM_SEARCH ; } else if ( gsm -> count >= gsm -> len ) { gsm -> state = GSM_FCS ; } <S2SV_ModEnd>
5,<S2SV_ModStart> ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; qeth_free_cq ( card ) ; if ( atomic_xchg ( & card -> qdio. state, QETH_QDIO_UNINITIALIZED ) == QETH_QDIO_UNINITIALIZED ) return ; <S2SV_ModEnd>"
6,<S2SV_ModStart> if ( card == NULL ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; qeth_free_cq ( card ) ; if ( atomic_xchg ( & card -> qdio. state, QETH_QDIO_UNINITIALIZED ) == QETH_QDIO_UNINITIALIZED ) return ; <S2SV_ModEnd>"
7,<S2SV_ModStart> if ( card -> qdio. in_q == NULL ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; qeth_free_cq ( card ) ; if ( atomic_xchg ( & card -> qdio. state, QETH_QDIO_UNINITIALIZED ) == QETH_QDIO_UNINITIALIZED ) return ; <S2SV_ModEnd>"
8,<S2SV_ModStart> if ( card == NULL ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; qeth_free_cq ( card ) ; if ( atomic_xchg ( & card -> qdio. state, QETH_QDIO_UNINITIALIZED ) == QETH_QDIO_UNINITIALIZED ) return ; <S2SV_ModEnd>"
9,<S2SV_ModStart> = { } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; qeth_free_cq ( card ) ; if ( atomic_xchg ( & card -> qdio. state, QETH_QDIO_UNINITIALIZED ) == QETH_QDIO_UNINITIALIZED ) return ; <S2SV_ModEnd>"
10,<S2SV_ModStart> if (! stream ) goto fail ; <S2SV_ModEnd>,0,"<S2SV_ModStart> size_t used = 0 ; BYTE * pConcatenated = NULL ; wStream * stream = Stream_StaticConstInit ( & sbuffer, pSrcData, SrcSize ) ; WINPR_ASSERT ( zgfx ) ; WINPR_ASSERT ( stream ) ; WINPR_ASSERT ( ppDstData ) ; WINPR_ASSERT ( pDstSize ) ; * ppDstData = NULL ; * pDstSize = 0 ; if (! Stream_CheckAndLogRequiredLength ( TAG, stream, 1 ) ) goto fail ; Stream_Read_UINT8 ( stream, descriptor ) ; /* descriptor (1 byte) */ if ( descriptor == ZGFX_SEGMENTED_SINGLE ) { if (! zgfx_decompress_segment ( zgfx, stream, Stream_GetRemainingLength ( stream ) ) ) goto fail ; if ( zgfx -> OutputCount > 0 ) { if (! zgfx_append ( zgfx, & pConcatenated, zgfx -> OutputCount, & used ) ) goto fail ; if ( used!= zgfx -> OutputCount ) goto fail ; * ppDstData = pConcatenated ;"
11,<S2SV_ModStart> if ( stream == NULL ) goto fail ; <S2SV_ModEnd>,0,"<S2SV_ModStart> size_t used = 0 ; BYTE * pConcatenated = NULL ; wStream * stream = Stream_StaticConstInit ( & sbuffer, pSrcData, SrcSize ) ; WINPR_ASSERT ( zgfx ) ; WINPR_ASSERT ( stream ) ; WINPR_ASSERT ( ppDstData ) ; WINPR_ASSERT ( pDstSize ) ; * ppDstData = NULL ; * pDstSize = 0 ; if (! Stream_CheckAndLogRequiredLength ( TAG, stream, 1 ) ) goto fail ; Stream_Read_UINT8 ( stream, descriptor ) ; /* descriptor (1 byte) */ if ( descriptor == ZGFX_SEGMENTED_SINGLE ) { if (! zgfx_decompress_segment ( zgfx, stream, Stream_GetRemainingLength ( stream ) ) ) goto fail ; if ( zgfx -> OutputCount > 0 ) { if (! zgfx_append ( zgfx, & pConcatenated, zgfx -> OutputCount, & used ) ) goto fail ; if ( used!= zgfx -> OutputCount ) goto fail ; * ppDstData = pConcatenated ;"
12,<S2SV_ModStart> if ( stream == NULL ) return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> size_t used = 0 ; BYTE * pConcatenated = NULL ; wStream * stream = Stream_StaticConstInit ( & sbuffer, pSrcData, SrcSize ) ; WINPR_ASSERT ( zgfx ) ; WINPR_ASSERT ( stream ) ; WINPR_ASSERT ( ppDstData ) ; WINPR_ASSERT ( pDstSize ) ; * ppDstData = NULL ; * pDstSize = 0 ; if (! Stream_CheckAndLogRequiredLength ( TAG, stream, 1 ) ) goto fail ; Stream_Read_UINT8 ( stream, descriptor ) ; /* descriptor (1 byte) */ if ( descriptor == ZGFX_SEGMENTED_SINGLE ) { if (! zgfx_decompress_segment ( zgfx, stream, Stream_GetRemainingLength ( stream ) ) ) goto fail ; if ( zgfx -> OutputCount > 0 ) { if (! zgfx_append ( zgfx, & pConcatenated, zgfx -> OutputCount, & used ) ) goto fail ; if ( used!= zgfx -> OutputCount ) goto fail ; * ppDstData = pConcatenated ;"
13,<S2SV_ModStart> if ( stream == NULL ) { return - 1 ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> size_t used = 0 ; BYTE * pConcatenated = NULL ; wStream * stream = Stream_StaticConstInit ( & sbuffer, pSrcData, SrcSize ) ; WINPR_ASSERT ( zgfx ) ; WINPR_ASSERT ( stream ) ; WINPR_ASSERT ( ppDstData ) ; WINPR_ASSERT ( pDstSize ) ; * ppDstData = NULL ; * pDstSize = 0 ; if (! Stream_CheckAndLogRequiredLength ( TAG, stream, 1 ) ) goto fail ; Stream_Read_UINT8 ( stream, descriptor ) ; /* descriptor (1 byte) */ if ( descriptor == ZGFX_SEGMENTED_SINGLE ) { if (! zgfx_decompress_segment ( zgfx, stream, Stream_GetRemainingLength ( stream ) ) ) goto fail ; if ( zgfx -> OutputCount > 0 ) { if (! zgfx_append ( zgfx, & pConcatenated, zgfx -> OutputCount, & used ) ) goto fail ; if ( used!= zgfx -> OutputCount ) goto fail ; * ppDstData = pConcatenated ;"
14,<S2SV_ModStart> if (! stream ) return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> size_t used = 0 ; BYTE * pConcatenated = NULL ; wStream * stream = Stream_StaticConstInit ( & sbuffer, pSrcData, SrcSize ) ; WINPR_ASSERT ( zgfx ) ; WINPR_ASSERT ( stream ) ; WINPR_ASSERT ( ppDstData ) ; WINPR_ASSERT ( pDstSize ) ; * ppDstData = NULL ; * pDstSize = 0 ; if (! Stream_CheckAndLogRequiredLength ( TAG, stream, 1 ) ) goto fail ; Stream_Read_UINT8 ( stream, descriptor ) ; /* descriptor (1 byte) */ if ( descriptor == ZGFX_SEGMENTED_SINGLE ) { if (! zgfx_decompress_segment ( zgfx, stream, Stream_GetRemainingLength ( stream ) ) ) goto fail ; if ( zgfx -> OutputCount > 0 ) { if (! zgfx_append ( zgfx, & pConcatenated, zgfx -> OutputCount, & used ) ) goto fail ; if ( used!= zgfx -> OutputCount ) goto fail ; * ppDstData = pConcatenated ;"
15,"<S2SV_ModStart> ; uint64_t start, len ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, end ; struct inode * inode = bdev -> bd_inode ; int err ; if (! ( mode & BLK_OPEN_WRITE ) ) return - EBADF ; if (! bdev_max_discard_sectors ( bdev ) ) return - EOPNOTSUPP ; if ( copy_from_user ( range, ( void __user * ) arg, sizeof ( range ) ) ) return - EFAULT ; start = range [ 0 ] ; len = range [ 1 ] ; if ( start & 511 ) return - EINVAL ; if ( len & 511 ) return - EINVAL ; if ( check_add_overflow ( start, len, & end ) || end > bdev_nr_bytes ( bdev ) ) return - EINVAL ; <S2SV_ModEnd>"
16,<S2SV_ModStart> ; uint64_t start ; uint64_t len ; <S2SV_ModEnd>,0,"<S2SV_ModStart>, end ; struct inode * inode = bdev -> bd_inode ; int err ; if (! ( mode & BLK_OPEN_WRITE ) ) return - EBADF ; if (! bdev_max_discard_sectors ( bdev ) ) return - EOPNOTSUPP ; if ( copy_from_user ( range, ( void __user * ) arg, sizeof ( range ) ) ) return - EFAULT ; start = range [ 0 ] ; len = range [ 1 ] ; if ( start & 511 ) return - EINVAL ; if ( len & 511 ) return - EINVAL ; if ( check_add_overflow ( start, len, & end ) || end > bdev_nr_bytes ( bdev ) ) return - EINVAL ; <S2SV_ModEnd>"
17,"<S2SV_ModStart> = { 0, 0 } <S2SV_ModEnd>",0,"<S2SV_ModStart>, end ; struct inode * inode = bdev -> bd_inode ; int err ; if (! ( mode & BLK_OPEN_WRITE ) ) return - EBADF ; if (! bdev_max_discard_sectors ( bdev ) ) return - EOPNOTSUPP ; if ( copy_from_user ( range, ( void __user * ) arg, sizeof ( range ) ) ) return - EFAULT ; start = range [ 0 ] ; len = range [ 1 ] ; if ( start & 511 ) return - EINVAL ; if ( len & 511 ) return - EINVAL ; if ( check_add_overflow ( start, len, & end ) || end > bdev_nr_bytes ( bdev ) ) return - EINVAL ; <S2SV_ModEnd>"
18,<S2SV_ModStart> if (! range ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart>, end ; struct inode * inode = bdev -> bd_inode ; int err ; if (! ( mode & BLK_OPEN_WRITE ) ) return - EBADF ; if (! bdev_max_discard_sectors ( bdev ) ) return - EOPNOTSUPP ; if ( copy_from_user ( range, ( void __user * ) arg, sizeof ( range ) ) ) return - EFAULT ; start = range [ 0 ] ; len = range [ 1 ] ; if ( start & 511 ) return - EINVAL ; if ( len & 511 ) return - EINVAL ; if ( check_add_overflow ( start, len, & end ) || end > bdev_nr_bytes ( bdev ) ) return - EINVAL ; <S2SV_ModEnd>"
19,"<S2SV_ModStart> = { 0, 0, LLONG_MAX ; } <S2SV_ModEnd>",0,"<S2SV_ModStart>, end ; struct inode * inode = bdev -> bd_inode ; int err ; if (! ( mode & BLK_OPEN_WRITE ) ) return - EBADF ; if (! bdev_max_discard_sectors ( bdev ) ) return - EOPNOTSUPP ; if ( copy_from_user ( range, ( void __user * ) arg, sizeof ( range ) ) ) return - EFAULT ; start = range [ 0 ] ; len = range [ 1 ] ; if ( start & 511 ) return - EINVAL ; if ( len & 511 ) return - EINVAL ; if ( check_add_overflow ( start, len, & end ) || end > bdev_nr_bytes ( bdev ) ) return - EINVAL ; <S2SV_ModEnd>"
20,<S2SV_ModStart> if ( pdata == NULL ) { return ; } <S2SV_ModEnd>,0,"static void hv_uio_cleanup ( struct hv_device * dev, struct hv_uio_private_data * pdata ) { if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; if (! pdata -> send_gpadl. decrypted ) vfree ( pdata -> send_buf ) ; } if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; if (! pdata -> recv_gpadl. decrypted ) vfree ( pdata -> recv_buf ) ; <S2SV_ModEnd>"
21,"<S2SV_ModStart> if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; <S2SV_ModEnd>",0,"static void hv_uio_cleanup ( struct hv_device * dev, struct hv_uio_private_data * pdata ) { if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; if (! pdata -> send_gpadl. decrypted ) vfree ( pdata -> send_buf ) ; } if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; if (! pdata -> recv_gpadl. decrypted ) vfree ( pdata -> recv_buf ) ; <S2SV_ModEnd>"
22,"<S2SV_ModStart> if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; vfree ( pdata -> send_buf ) ; <S2SV_ModEnd>",0,"static void hv_uio_cleanup ( struct hv_device * dev, struct hv_uio_private_data * pdata ) { if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; if (! pdata -> send_gpadl. decrypted ) vfree ( pdata -> send_buf ) ; } if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; if (! pdata -> recv_gpadl. decrypted ) vfree ( pdata -> recv_buf ) ; <S2SV_ModEnd>"
23,"<S2SV_ModStart> if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; <S2SV_ModEnd>",0,"static void hv_uio_cleanup ( struct hv_device * dev, struct hv_uio_private_data * pdata ) { if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; if (! pdata -> send_gpadl. decrypted ) vfree ( pdata -> send_buf ) ; } if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; if (! pdata -> recv_gpadl. decrypted ) vfree ( pdata -> recv_buf ) ; <S2SV_ModEnd>"
24,"<S2SV_ModStart> if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; vfree ( pdata -> send_buf ) ; <S2SV_ModEnd>",0,"static void hv_uio_cleanup ( struct hv_device * dev, struct hv_uio_private_data * pdata ) { if ( pdata -> send_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> send_gpadl ) ; if (! pdata -> send_gpadl. decrypted ) vfree ( pdata -> send_buf ) ; } if ( pdata -> recv_gpadl. gpadl_handle ) { vmbus_teardown_gpadl ( dev -> channel, & pdata -> recv_gpadl ) ; if (! pdata -> recv_gpadl. decrypted ) vfree ( pdata -> recv_buf ) ; <S2SV_ModEnd>"
25,<S2SV_ModStart> if (! lookup ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct inet6_dev * idev = ip6_dst_idev ( & rt -> dst ) ; if (! idev ) goto again ; err = fib6_rule_saddr ( net, rule, flags, flp6, idev -> dev ) ; <S2SV_ModEnd>"
26,<S2SV_ModStart> if (! lookup ) { err = - EINVAL ; goto discard_pkt ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct inet6_dev * idev = ip6_dst_idev ( & rt -> dst ) ; if (! idev ) goto again ; err = fib6_rule_saddr ( net, rule, flags, flp6, idev -> dev ) ; <S2SV_ModEnd>"
27,<S2SV_ModStart> if (! tb_id ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct inet6_dev * idev = ip6_dst_idev ( & rt -> dst ) ; if (! idev ) goto again ; err = fib6_rule_saddr ( net, rule, flags, flp6, idev -> dev ) ; <S2SV_ModEnd>"
28,<S2SV_ModStart> if (! table ) { err = - ENOENT ; goto discard_pkt ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct inet6_dev * idev = ip6_dst_idev ( & rt -> dst ) ; if (! idev ) goto again ; err = fib6_rule_saddr ( net, rule, flags, flp6, idev -> dev ) ; <S2SV_ModEnd>"
29,<S2SV_ModStart> if (! table ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct inet6_dev * idev = ip6_dst_idev ( & rt -> dst ) ; if (! idev ) goto again ; err = fib6_rule_saddr ( net, rule, flags, flp6, idev -> dev ) ; <S2SV_ModEnd>"
30,"<S2SV_ModStart> if (! boot_ghcb ) sev_es_terminate ( SEV_TERM_SET_GEN, GHCB_SEV_ES_GEN_REQ ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, exit_code ) ; if ( result!= ES_OK ) goto finish ; result = vc_check_opcode_bytes ( & ctxt, exit_code ) ; if ( result!= ES_OK ) goto finish ; switch ( exit_code ) { case SVM_EXIT_RDTSC : case SVM_EXIT_RDTSCP : result = vc_handle_rdtsc ( boot_ghcb, & ctxt, exit_code ) ; break ; case SVM_EXIT_IOIO : result = vc_handle_ioio ( boot_ghcb, & ctxt ) ; break ; case SVM_EXIT_CPUID : result = vc_handle_cpuid ( boot_ghcb, & ctxt ) ; break ; default : <S2SV_ModEnd>"
31,"<S2SV_ModStart> if (! ctxt ) sev_es_terminate ( SEV_TERM_SET_GEN, GHCB_SEV_ES_GEN_REQ ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, exit_code ) ; if ( result!= ES_OK ) goto finish ; result = vc_check_opcode_bytes ( & ctxt, exit_code ) ; if ( result!= ES_OK ) goto finish ; switch ( exit_code ) { case SVM_EXIT_RDTSC : case SVM_EXIT_RDTSCP : result = vc_handle_rdtsc ( boot_ghcb, & ctxt, exit_code ) ; break ; case SVM_EXIT_IOIO : result = vc_handle_ioio ( boot_ghcb, & ctxt ) ; break ; case SVM_EXIT_CPUID : result = vc_handle_cpuid ( boot_ghcb, & ctxt ) ; break ; default : <S2SV_ModEnd>"
32,"<S2SV_ModStart> if (! boot_ghcb ) do_boot_stage2_vc ( regs, exit_code ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, exit_code ) ; if ( result!= ES_OK ) goto finish ; result = vc_check_opcode_bytes ( & ctxt, exit_code ) ; if ( result!= ES_OK ) goto finish ; switch ( exit_code ) { case SVM_EXIT_RDTSC : case SVM_EXIT_RDTSCP : result = vc_handle_rdtsc ( boot_ghcb, & ctxt, exit_code ) ; break ; case SVM_EXIT_IOIO : result = vc_handle_ioio ( boot_ghcb, & ctxt ) ; break ; case SVM_EXIT_CPUID : result = vc_handle_cpuid ( boot_ghcb, & ctxt ) ; break ; default : <S2SV_ModEnd>"
33,<S2SV_ModStart> if ( ctxt == NULL ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart>, exit_code ) ; if ( result!= ES_OK ) goto finish ; result = vc_check_opcode_bytes ( & ctxt, exit_code ) ; if ( result!= ES_OK ) goto finish ; switch ( exit_code ) { case SVM_EXIT_RDTSC : case SVM_EXIT_RDTSCP : result = vc_handle_rdtsc ( boot_ghcb, & ctxt, exit_code ) ; break ; case SVM_EXIT_IOIO : result = vc_handle_ioio ( boot_ghcb, & ctxt ) ; break ; case SVM_EXIT_CPUID : result = vc_handle_cpuid ( boot_ghcb, & ctxt ) ; break ; default : <S2SV_ModEnd>"
34,"<S2SV_ModStart> if (! ctxt ) sev_es_terminate ( SEV_TERM_SET_GEN, GHCB_SEV_ES_GENER_REQ ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, exit_code ) ; if ( result!= ES_OK ) goto finish ; result = vc_check_opcode_bytes ( & ctxt, exit_code ) ; if ( result!= ES_OK ) goto finish ; switch ( exit_code ) { case SVM_EXIT_RDTSC : case SVM_EXIT_RDTSCP : result = vc_handle_rdtsc ( boot_ghcb, & ctxt, exit_code ) ; break ; case SVM_EXIT_IOIO : result = vc_handle_ioio ( boot_ghcb, & ctxt ) ; break ; case SVM_EXIT_CPUID : result = vc_handle_cpuid ( boot_ghcb, & ctxt ) ; break ; default : <S2SV_ModEnd>"
35,<S2SV_ModStart> if (! n_rules ) return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! tmp_rule ) continue ; <S2SV_ModEnd>
36,<S2SV_ModStart> if (! coalesce -> rules ) return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! tmp_rule ) continue ; <S2SV_ModEnd>
37,<S2SV_ModStart> if (! coalesce -> n_rules ) return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! tmp_rule ) continue ; <S2SV_ModEnd>
38,<S2SV_ModStart> if ( n_rules < 0 ) return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! tmp_rule ) continue ; <S2SV_ModEnd>
39,<S2SV_ModStart> kfree ( tmp_rule ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! tmp_rule ) continue ; <S2SV_ModEnd>
40,<S2SV_ModStart> if ( new_order < 0 ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> unsigned int nofs ; int err = 0 ; gfp_t gfp = readahead_gfp_mask ( mapping ) ; if (! mapping_large_folio_support ( mapping ) || ra -> size < 4 ) goto fallback ; limit = min ( limit, index + ra -> size - 1 ) ; if ( new_order < MAX_PAGECACHE_ORDER ) { new_order += 2 ; new_order = min_t ( unsigned int, MAX_PAGECACHE_ORDER, new_order ) ; new_order = min_t ( unsigned int, new_order, ilog2 ( ra -> size ) ) ; } /* See comment in page_cache_ra_unbounded() */ nofs = memalloc_nofs_save ( ) ; filemap_invalidate_lock_shared ( mapping ) ; while ( index <= limit ) { unsigned int order = new_order ; /* Align with smaller pages if needed */ if ( index & ( ( 1UL << order ) - 1 ) ) order = __ffs ( index ) ; /* Don't allocate pages past EOF */ while ( index + ( 1UL << order ) - 1 > limit ) order -- ; err ="
41,<S2SV_ModStart> unsigned int order = new_order ; <S2SV_ModEnd>,0,"<S2SV_ModStart> unsigned int nofs ; int err = 0 ; gfp_t gfp = readahead_gfp_mask ( mapping ) ; if (! mapping_large_folio_support ( mapping ) || ra -> size < 4 ) goto fallback ; limit = min ( limit, index + ra -> size - 1 ) ; if ( new_order < MAX_PAGECACHE_ORDER ) { new_order += 2 ; new_order = min_t ( unsigned int, MAX_PAGECACHE_ORDER, new_order ) ; new_order = min_t ( unsigned int, new_order, ilog2 ( ra -> size ) ) ; } /* See comment in page_cache_ra_unbounded() */ nofs = memalloc_nofs_save ( ) ; filemap_invalidate_lock_shared ( mapping ) ; while ( index <= limit ) { unsigned int order = new_order ; /* Align with smaller pages if needed */ if ( index & ( ( 1UL << order ) - 1 ) ) order = __ffs ( index ) ; /* Don't allocate pages past EOF */ while ( index + ( 1UL << order ) - 1 > limit ) order -- ; err ="
42,<S2SV_ModStart> if (! limit ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> unsigned int nofs ; int err = 0 ; gfp_t gfp = readahead_gfp_mask ( mapping ) ; if (! mapping_large_folio_support ( mapping ) || ra -> size < 4 ) goto fallback ; limit = min ( limit, index + ra -> size - 1 ) ; if ( new_order < MAX_PAGECACHE_ORDER ) { new_order += 2 ; new_order = min_t ( unsigned int, MAX_PAGECACHE_ORDER, new_order ) ; new_order = min_t ( unsigned int, new_order, ilog2 ( ra -> size ) ) ; } /* See comment in page_cache_ra_unbounded() */ nofs = memalloc_nofs_save ( ) ; filemap_invalidate_lock_shared ( mapping ) ; while ( index <= limit ) { unsigned int order = new_order ; /* Align with smaller pages if needed */ if ( index & ( ( 1UL << order ) - 1 ) ) order = __ffs ( index ) ; /* Don't allocate pages past EOF */ while ( index + ( 1UL << order ) - 1 > limit ) order -- ; err ="
43,<S2SV_ModStart> ( unsigned int ) limit ; <S2SV_ModEnd>,0,"<S2SV_ModStart> unsigned int nofs ; int err = 0 ; gfp_t gfp = readahead_gfp_mask ( mapping ) ; if (! mapping_large_folio_support ( mapping ) || ra -> size < 4 ) goto fallback ; limit = min ( limit, index + ra -> size - 1 ) ; if ( new_order < MAX_PAGECACHE_ORDER ) { new_order += 2 ; new_order = min_t ( unsigned int, MAX_PAGECACHE_ORDER, new_order ) ; new_order = min_t ( unsigned int, new_order, ilog2 ( ra -> size ) ) ; } /* See comment in page_cache_ra_unbounded() */ nofs = memalloc_nofs_save ( ) ; filemap_invalidate_lock_shared ( mapping ) ; while ( index <= limit ) { unsigned int order = new_order ; /* Align with smaller pages if needed */ if ( index & ( ( 1UL << order ) - 1 ) ) order = __ffs ( index ) ; /* Don't allocate pages past EOF */ while ( index + ( 1UL << order ) - 1 > limit ) order -- ; err ="
44,<S2SV_ModStart> unsigned int order ; <S2SV_ModEnd>,0,"<S2SV_ModStart> unsigned int nofs ; int err = 0 ; gfp_t gfp = readahead_gfp_mask ( mapping ) ; if (! mapping_large_folio_support ( mapping ) || ra -> size < 4 ) goto fallback ; limit = min ( limit, index + ra -> size - 1 ) ; if ( new_order < MAX_PAGECACHE_ORDER ) { new_order += 2 ; new_order = min_t ( unsigned int, MAX_PAGECACHE_ORDER, new_order ) ; new_order = min_t ( unsigned int, new_order, ilog2 ( ra -> size ) ) ; } /* See comment in page_cache_ra_unbounded() */ nofs = memalloc_nofs_save ( ) ; filemap_invalidate_lock_shared ( mapping ) ; while ( index <= limit ) { unsigned int order = new_order ; /* Align with smaller pages if needed */ if ( index & ( ( 1UL << order ) - 1 ) ) order = __ffs ( index ) ; /* Don't allocate pages past EOF */ while ( index + ( 1UL << order ) - 1 > limit ) order -- ; err ="
45,"size_t ) memset ( ( void * ) ( ( void * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>",0,"&&! freeptr_outside_object ( s ) ) memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>"
46,"size_t memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>",0,"&&! freeptr_outside_object ( s ) ) memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>"
47,"size_t ) { memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>",0,"&&! freeptr_outside_object ( s ) ) memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>"
48,"size_t ) memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>",0,"&&! freeptr_outside_object ( s ) ) memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>"
49,"size_t ) memset ( ( void * ) ( ( void * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ) ; <S2SV_ModEnd>",0,"&&! freeptr_outside_object ( s ) ) memset ( ( void * ) ( ( char * ) kasan_reset_tag ( obj ) + s -> offset ), 0, sizeof ( void * ) ) ; <S2SV_ModEnd>"
50,"<S2SV_ModStart> if ( maxIterations < 0 ) { return RedisModule_ReplyWithError ( ctx, ""Bad max iterations"" ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> CF_DEFAULT_MAX_ITERATIONS ; int mi_loc = RMUtil_ArgIndex ( ""MAXITERATIONS"", argv, argc ) ; if ( mi_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ mi_loc + 1 ], & maxIterations )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse MAXITERATIONS"" ) ; } else if ( maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS ) { return RedisModule_ReplyWithError ( ctx, ""MAXITERATIONS: value must be an integer between 1 and 65535, inclusive."" ) ; } } long long bucketSize = CF_DEFAULT_BUCKETSIZE ; int bs_loc = RMUtil_ArgIndex ( ""BUCKETSIZE"", argv, argc ) ; if ( bs_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ bs_loc + 1 ], & bucketSize )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse BUCKETSIZE"" ) ; } else if ( bucketSize <= 0 || bucketSize > CF_MAX_BUCKET"
51,"<S2SV_ModStart> if ( mi_loc == - 1 ) { return RedisModule_ReplyWithError ( ctx, ""Bad capacity"" ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> CF_DEFAULT_MAX_ITERATIONS ; int mi_loc = RMUtil_ArgIndex ( ""MAXITERATIONS"", argv, argc ) ; if ( mi_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ mi_loc + 1 ], & maxIterations )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse MAXITERATIONS"" ) ; } else if ( maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS ) { return RedisModule_ReplyWithError ( ctx, ""MAXITERATIONS: value must be an integer between 1 and 65535, inclusive."" ) ; } } long long bucketSize = CF_DEFAULT_BUCKETSIZE ; int bs_loc = RMUtil_ArgIndex ( ""BUCKETSIZE"", argv, argc ) ; if ( bs_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ bs_loc + 1 ], & bucketSize )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse BUCKETSIZE"" ) ; } else if ( bucketSize <= 0 || bucketSize > CF_MAX_BUCKET"
52,<S2SV_ModStart> if ( argc < 0 ) { return RedisModule_WrongArity ( ctx ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> CF_DEFAULT_MAX_ITERATIONS ; int mi_loc = RMUtil_ArgIndex ( ""MAXITERATIONS"", argv, argc ) ; if ( mi_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ mi_loc + 1 ], & maxIterations )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse MAXITERATIONS"" ) ; } else if ( maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS ) { return RedisModule_ReplyWithError ( ctx, ""MAXITERATIONS: value must be an integer between 1 and 65535, inclusive."" ) ; } } long long bucketSize = CF_DEFAULT_BUCKETSIZE ; int bs_loc = RMUtil_ArgIndex ( ""BUCKETSIZE"", argv, argc ) ; if ( bs_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ bs_loc + 1 ], & bucketSize )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse BUCKETSIZE"" ) ; } else if ( bucketSize <= 0 || bucketSize > CF_MAX_BUCKET"
53,"<S2SV_ModStart> if ( capacity < 0 ) { return RedisModule_ReplyWithError ( ctx, ""Bad capacity"" ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> CF_DEFAULT_MAX_ITERATIONS ; int mi_loc = RMUtil_ArgIndex ( ""MAXITERATIONS"", argv, argc ) ; if ( mi_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ mi_loc + 1 ], & maxIterations )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse MAXITERATIONS"" ) ; } else if ( maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS ) { return RedisModule_ReplyWithError ( ctx, ""MAXITERATIONS: value must be an integer between 1 and 65535, inclusive."" ) ; } } long long bucketSize = CF_DEFAULT_BUCKETSIZE ; int bs_loc = RMUtil_ArgIndex ( ""BUCKETSIZE"", argv, argc ) ; if ( bs_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ bs_loc + 1 ], & bucketSize )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse BUCKETSIZE"" ) ; } else if ( bucketSize <= 0 || bucketSize > CF_MAX_BUCKET"
54,"<S2SV_ModStart> if ( mi_loc == - 1 ) { return RedisModule_ReplyWithError ( ""Bad capacity"" ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> CF_DEFAULT_MAX_ITERATIONS ; int mi_loc = RMUtil_ArgIndex ( ""MAXITERATIONS"", argv, argc ) ; if ( mi_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ mi_loc + 1 ], & maxIterations )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse MAXITERATIONS"" ) ; } else if ( maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS ) { return RedisModule_ReplyWithError ( ctx, ""MAXITERATIONS: value must be an integer between 1 and 65535, inclusive."" ) ; } } long long bucketSize = CF_DEFAULT_BUCKETSIZE ; int bs_loc = RMUtil_ArgIndex ( ""BUCKETSIZE"", argv, argc ) ; if ( bs_loc!= - 1 ) { if ( RedisModule_StringToLongLong ( argv [ bs_loc + 1 ], & bucketSize )!= REDISMODULE_OK ) { return RedisModule_ReplyWithError ( ctx, ""Couldn't parse BUCKETSIZE"" ) ; } else if ( bucketSize <= 0 || bucketSize > CF_MAX_BUCKET"
55,"<S2SV_ModStart> if (! iter ) die ( _ ( ""unknown error"" ), iter -> relative_path ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /*
	 * Refuse copying directories by default which aren't owned by us. The
	 * code that performs either the copying or hardlinking is not prepared
	 * to handle various edge cases where an adversary may for example
	 * racily swap out files for symlinks. This can cause us to
	 * inadvertently use the wrong source file.
	 *
	 * Furthermore, even if we were prepared to handle such races safely,
	 * creating hardlinks across user boundaries is an inherently unsafe
	 * operation as the hardlinked files can be rewritten at will by the
	 * potentially-untrusted user. We thus refuse to do so by default.
	 */ die_upon_dubious_ownership ( NULL, NULL, src_repo ) ; mkdir_if_missing ( dest -> buf, 0777 ) ; iter = dir_iterator_begin ( src -> buf, DIR_ITERATOR_PEDANTIC ) ; if (! iter ) die_errno ( _ ( ""failed to start iterator over '%s'"" ), src -> buf ) ; strbuf_addch ( src, '/' ) ; src_len"
56,"<S2SV_ModStart> if (! iter ) die ( _ ( ""no iterator"" ), iter -> relative_path ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /*
	 * Refuse copying directories by default which aren't owned by us. The
	 * code that performs either the copying or hardlinking is not prepared
	 * to handle various edge cases where an adversary may for example
	 * racily swap out files for symlinks. This can cause us to
	 * inadvertently use the wrong source file.
	 *
	 * Furthermore, even if we were prepared to handle such races safely,
	 * creating hardlinks across user boundaries is an inherently unsafe
	 * operation as the hardlinked files can be rewritten at will by the
	 * potentially-untrusted user. We thus refuse to do so by default.
	 */ die_upon_dubious_ownership ( NULL, NULL, src_repo ) ; mkdir_if_missing ( dest -> buf, 0777 ) ; iter = dir_iterator_begin ( src -> buf, DIR_ITERATOR_PEDANTIC ) ; if (! iter ) die_errno ( _ ( ""failed to start iterator over '%s'"" ), src -> buf ) ; strbuf_addch ( src, '/' ) ; src_len"
57,"<S2SV_ModStart> if (! src -> len ) die ( _ ( ""unknown file type '%s'"" ), iter -> relative_path ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /*
	 * Refuse copying directories by default which aren't owned by us. The
	 * code that performs either the copying or hardlinking is not prepared
	 * to handle various edge cases where an adversary may for example
	 * racily swap out files for symlinks. This can cause us to
	 * inadvertently use the wrong source file.
	 *
	 * Furthermore, even if we were prepared to handle such races safely,
	 * creating hardlinks across user boundaries is an inherently unsafe
	 * operation as the hardlinked files can be rewritten at will by the
	 * potentially-untrusted user. We thus refuse to do so by default.
	 */ die_upon_dubious_ownership ( NULL, NULL, src_repo ) ; mkdir_if_missing ( dest -> buf, 0777 ) ; iter = dir_iterator_begin ( src -> buf, DIR_ITERATOR_PEDANTIC ) ; if (! iter ) die_errno ( _ ( ""failed to start iterator over '%s'"" ), src -> buf ) ; strbuf_addch ( src, '/' ) ; src_len"
58,"<S2SV_ModStart> if (! src -> len ) die ( _ ( ""unknown file type '%s'"" ), src -> buf ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /*
	 * Refuse copying directories by default which aren't owned by us. The
	 * code that performs either the copying or hardlinking is not prepared
	 * to handle various edge cases where an adversary may for example
	 * racily swap out files for symlinks. This can cause us to
	 * inadvertently use the wrong source file.
	 *
	 * Furthermore, even if we were prepared to handle such races safely,
	 * creating hardlinks across user boundaries is an inherently unsafe
	 * operation as the hardlinked files can be rewritten at will by the
	 * potentially-untrusted user. We thus refuse to do so by default.
	 */ die_upon_dubious_ownership ( NULL, NULL, src_repo ) ; mkdir_if_missing ( dest -> buf, 0777 ) ; iter = dir_iterator_begin ( src -> buf, DIR_ITERATOR_PEDANTIC ) ; if (! iter ) die_errno ( _ ( ""failed to start iterator over '%s'"" ), src -> buf ) ; strbuf_addch ( src, '/' ) ; src_len"
59,"<S2SV_ModStart> if (! iter ) die ( _ ( ""no iterator"" ), src -> buf ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /*
	 * Refuse copying directories by default which aren't owned by us. The
	 * code that performs either the copying or hardlinking is not prepared
	 * to handle various edge cases where an adversary may for example
	 * racily swap out files for symlinks. This can cause us to
	 * inadvertently use the wrong source file.
	 *
	 * Furthermore, even if we were prepared to handle such races safely,
	 * creating hardlinks across user boundaries is an inherently unsafe
	 * operation as the hardlinked files can be rewritten at will by the
	 * potentially-untrusted user. We thus refuse to do so by default.
	 */ die_upon_dubious_ownership ( NULL, NULL, src_repo ) ; mkdir_if_missing ( dest -> buf, 0777 ) ; iter = dir_iterator_begin ( src -> buf, DIR_ITERATOR_PEDANTIC ) ; if (! iter ) die_errno ( _ ( ""failed to start iterator over '%s'"" ), src -> buf ) ; strbuf_addch ( src, '/' ) ; src_len"
60,"<S2SV_ModStart> memset ( user_val, 0, sizeof ( user_val ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> memdup_user_nul ( buf, count ) ; <S2SV_ModEnd>"
61,<S2SV_ModStart> if ( cnt > 16 ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, count ) ; <S2SV_ModEnd>"
62,<S2SV_ModStart> if ( count < 0 ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, count ) ; <S2SV_ModEnd>"
63,<S2SV_ModStart> if ( cnt == 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, count ) ; <S2SV_ModEnd>"
64,<S2SV_ModStart> if (! cnt ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, count ) ; <S2SV_ModEnd>"
65,<S2SV_ModStart> ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; struct stat st ; struct child_process cp = CHILD_PROCESS_INIT ; const char * clone_data_path = clone_data -> path ; char * to_free = NULL ; if (! is_absolute_path ( clone_data -> path ) ) clone_data_path = to_free = xstrfmt ( ""%s/%s"", get_git_work_tree ( ), clone_data -> path ) ; if ( validate_submodule_git_dir ( sm_gitdir, clone_data -> name ) < 0 ) die ( _ ( ""refusing to create/use '%s' in another submodule's "" ""git dir"" ), sm_gitdir ) ; if (! file_exists ( sm_gitdir ) ) { if ( clone_data -> require_init &&! stat ( clone_data_path, & st ) &&! is_empty_dir ( clone_data_path ) ) die ( _ ( ""directory not empty: '%s'"" ), clone_data_path ) ; if ( safe_create_leading_directories_const ( sm_gitdir ) < 0 ) die ( _ ( ""could not create directory '%s"
66,"<S2SV_ModStart> = xstrdup ( sm_gitdir, GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> ; struct stat st ; struct child_process cp = CHILD_PROCESS_INIT ; const char * clone_data_path = clone_data -> path ; char * to_free = NULL ; if (! is_absolute_path ( clone_data -> path ) ) clone_data_path = to_free = xstrfmt ( ""%s/%s"", get_git_work_tree ( ), clone_data -> path ) ; if ( validate_submodule_git_dir ( sm_gitdir, clone_data -> name ) < 0 ) die ( _ ( ""refusing to create/use '%s' in another submodule's "" ""git dir"" ), sm_gitdir ) ; if (! file_exists ( sm_gitdir ) ) { if ( clone_data -> require_init &&! stat ( clone_data_path, & st ) &&! is_empty_dir ( clone_data_path ) ) die ( _ ( ""directory not empty: '%s'"" ), clone_data_path ) ; if ( safe_create_leading_directories_const ( sm_gitdir ) < 0 ) die ( _ ( ""could not create directory '%s"
67,"<S2SV_ModStart> if (! sm_gitdir ) die ( _ ( ""could not create directory '%s'"" ), sm_gitdir ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> ; struct stat st ; struct child_process cp = CHILD_PROCESS_INIT ; const char * clone_data_path = clone_data -> path ; char * to_free = NULL ; if (! is_absolute_path ( clone_data -> path ) ) clone_data_path = to_free = xstrfmt ( ""%s/%s"", get_git_work_tree ( ), clone_data -> path ) ; if ( validate_submodule_git_dir ( sm_gitdir, clone_data -> name ) < 0 ) die ( _ ( ""refusing to create/use '%s' in another submodule's "" ""git dir"" ), sm_gitdir ) ; if (! file_exists ( sm_gitdir ) ) { if ( clone_data -> require_init &&! stat ( clone_data_path, & st ) &&! is_empty_dir ( clone_data_path ) ) die ( _ ( ""directory not empty: '%s'"" ), clone_data_path ) ; if ( safe_create_leading_directories_const ( sm_gitdir ) < 0 ) die ( _ ( ""could not create directory '%s"
68,"<S2SV_ModStart> if (! sm_gitdir ) die ( _ ( ""unknown submodule's git dir"" ), sm_gitdir ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> ; struct stat st ; struct child_process cp = CHILD_PROCESS_INIT ; const char * clone_data_path = clone_data -> path ; char * to_free = NULL ; if (! is_absolute_path ( clone_data -> path ) ) clone_data_path = to_free = xstrfmt ( ""%s/%s"", get_git_work_tree ( ), clone_data -> path ) ; if ( validate_submodule_git_dir ( sm_gitdir, clone_data -> name ) < 0 ) die ( _ ( ""refusing to create/use '%s' in another submodule's "" ""git dir"" ), sm_gitdir ) ; if (! file_exists ( sm_gitdir ) ) { if ( clone_data -> require_init &&! stat ( clone_data_path, & st ) &&! is_empty_dir ( clone_data_path ) ) die ( _ ( ""directory not empty: '%s'"" ), clone_data_path ) ; if ( safe_create_leading_directories_const ( sm_gitdir ) < 0 ) die ( _ ( ""could not create directory '%s"
69,"<S2SV_ModStart> if (! sm_gitdir ) die ( _ ( ""unknown submodule"" ), sm_gitdir ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> ; struct stat st ; struct child_process cp = CHILD_PROCESS_INIT ; const char * clone_data_path = clone_data -> path ; char * to_free = NULL ; if (! is_absolute_path ( clone_data -> path ) ) clone_data_path = to_free = xstrfmt ( ""%s/%s"", get_git_work_tree ( ), clone_data -> path ) ; if ( validate_submodule_git_dir ( sm_gitdir, clone_data -> name ) < 0 ) die ( _ ( ""refusing to create/use '%s' in another submodule's "" ""git dir"" ), sm_gitdir ) ; if (! file_exists ( sm_gitdir ) ) { if ( clone_data -> require_init &&! stat ( clone_data_path, & st ) &&! is_empty_dir ( clone_data_path ) ) die ( _ ( ""directory not empty: '%s'"" ), clone_data_path ) ; if ( safe_create_leading_directories_const ( sm_gitdir ) < 0 ) die ( _ ( ""could not create directory '%s"
70,<S2SV_ModStart> if ( buf_entries == NULL ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> + mrioc -> reply_sz ) ; <S2SV_ModEnd>
71,<S2SV_ModStart> if (! buf_entries ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> + mrioc -> reply_sz ) ; <S2SV_ModEnd>
72,<S2SV_ModStart> if ( erbsz < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> + mrioc -> reply_sz ) ; <S2SV_ModEnd>
73,<S2SV_ModStart> = { } <S2SV_ModEnd>,0,<S2SV_ModStart> + mrioc -> reply_sz ) ; <S2SV_ModEnd>
74,<S2SV_ModStart> if ( buf_entries == NULL ) { return rval ; } <S2SV_ModEnd>,0,<S2SV_ModStart> + mrioc -> reply_sz ) ; <S2SV_ModEnd>
75,<S2SV_ModStart> if ( hdev == NULL ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ( hdev ) ; <S2SV_ModEnd>
76,<S2SV_ModStart> if (! hdev -> open ) { hci_dev_lock ( hdev ) ; msft_unregister ( hdev ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( hdev ) ; <S2SV_ModEnd>
77,"<S2SV_ModStart> kzalloc ( sizeof ( struct msft_dev ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> ( hdev ) ; <S2SV_ModEnd>
78,"<S2SV_ModStart> kzalloc ( sizeof ( hdev -> cmd ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> ( hdev ) ; <S2SV_ModEnd>
79,"<S2SV_ModStart> kzalloc ( sizeof ( hdev -> cmd_lock ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> ( hdev ) ; <S2SV_ModEnd>
80,<S2SV_ModStart> unsigned long done ; <S2SV_ModEnd>,0,<S2SV_ModStart> complete = NULL ; message -> context = NULL ; <S2SV_ModEnd>
81,"<S2SV_ModStart> kzalloc ( sizeof ( * message ), GFP_NOIO ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> complete = NULL ; message -> context = NULL ; <S2SV_ModEnd>
82,"<S2SV_ModStart> kzalloc ( sizeof ( struct spi_message ), GFP_NOIO ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> complete = NULL ; message -> context = NULL ; <S2SV_ModEnd>
83,"<S2SV_ModStart> kzalloc ( sizeof ( * ctlr ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> complete = NULL ; message -> context = NULL ; <S2SV_ModEnd>
84,"<S2SV_ModStart> kzalloc ( sizeof ( * message ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> complete = NULL ; message -> context = NULL ; <S2SV_ModEnd>
85,<S2SV_ModStart> kfree ( nvdev -> chan_table ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! nvdev -> recv_buf_gpadl_handle. decrypted ) vfree ( nvdev -> recv_buf ) ; if (! nvdev -> send_buf_gpadl_handle. decrypted ) vfree ( nvdev -> send_buf ) ; <S2SV_ModEnd>
86,<S2SV_ModStart> if ( nvdev == NULL ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if (! nvdev -> recv_buf_gpadl_handle. decrypted ) vfree ( nvdev -> recv_buf ) ; if (! nvdev -> send_buf_gpadl_handle. decrypted ) vfree ( nvdev -> send_buf ) ; <S2SV_ModEnd>
87,<S2SV_ModStart> kfree ( nvdev -> channel_table ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! nvdev -> recv_buf_gpadl_handle. decrypted ) vfree ( nvdev -> recv_buf ) ; if (! nvdev -> send_buf_gpadl_handle. decrypted ) vfree ( nvdev -> send_buf ) ; <S2SV_ModEnd>
88,<S2SV_ModStart> if (! nvdev ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if (! nvdev -> recv_buf_gpadl_handle. decrypted ) vfree ( nvdev -> recv_buf ) ; if (! nvdev -> send_buf_gpadl_handle. decrypted ) vfree ( nvdev -> send_buf ) ; <S2SV_ModEnd>
89,<S2SV_ModStart> if (! head ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if (! nvdev -> recv_buf_gpadl_handle. decrypted ) vfree ( nvdev -> recv_buf ) ; if (! nvdev -> send_buf_gpadl_handle. decrypted ) vfree ( nvdev -> send_buf ) ; <S2SV_ModEnd>
90,"<S2SV_ModStart> memset ( edl, 0, sizeof ( * edl ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> * build_label ; char cmd ; int build_lbl_len, err = 0 ; bt_dev_dbg ( hdev, ""QCA read fw build info"" ) ; cmd = EDL_GET_BUILD_INFO_CMD ; skb = __hci_cmd_sync_ev ( hdev, EDL_PATCH_CMD_OPCODE, EDL_PATCH_CMD_LEN, & cmd, 0, HCI_INIT_TIMEOUT ) ; if ( IS_ERR ( skb ) ) { err = PTR_ERR ( skb ) ; bt_dev_err ( hdev, ""Reading QCA fw build info failed (%d)"", err ) ; return err ; } if ( skb -> len < sizeof ( * edl ) ) { err = - EILSEQ ; goto out ; } edl = ( struct edl_event_hdr * ) ( skb -> data ) ; if (! edl ) { bt_dev_err ( hdev, ""QCA read fw build info with no header"" ) ; err = - EILSEQ ; goto out ; } if ( edl -> cresp!= EDL_CMD_REQ_RES"
91,"<S2SV_ModStart> memset ( build_label, 0, sizeof ( build_label ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> * build_label ; char cmd ; int build_lbl_len, err = 0 ; bt_dev_dbg ( hdev, ""QCA read fw build info"" ) ; cmd = EDL_GET_BUILD_INFO_CMD ; skb = __hci_cmd_sync_ev ( hdev, EDL_PATCH_CMD_OPCODE, EDL_PATCH_CMD_LEN, & cmd, 0, HCI_INIT_TIMEOUT ) ; if ( IS_ERR ( skb ) ) { err = PTR_ERR ( skb ) ; bt_dev_err ( hdev, ""Reading QCA fw build info failed (%d)"", err ) ; return err ; } if ( skb -> len < sizeof ( * edl ) ) { err = - EILSEQ ; goto out ; } edl = ( struct edl_event_hdr * ) ( skb -> data ) ; if (! edl ) { bt_dev_err ( hdev, ""QCA read fw build info with no header"" ) ; err = - EILSEQ ; goto out ; } if ( edl -> cresp!= EDL_CMD_REQ_RES"
92,<S2SV_ModStart> if (! edl ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> * build_label ; char cmd ; int build_lbl_len, err = 0 ; bt_dev_dbg ( hdev, ""QCA read fw build info"" ) ; cmd = EDL_GET_BUILD_INFO_CMD ; skb = __hci_cmd_sync_ev ( hdev, EDL_PATCH_CMD_OPCODE, EDL_PATCH_CMD_LEN, & cmd, 0, HCI_INIT_TIMEOUT ) ; if ( IS_ERR ( skb ) ) { err = PTR_ERR ( skb ) ; bt_dev_err ( hdev, ""Reading QCA fw build info failed (%d)"", err ) ; return err ; } if ( skb -> len < sizeof ( * edl ) ) { err = - EILSEQ ; goto out ; } edl = ( struct edl_event_hdr * ) ( skb -> data ) ; if (! edl ) { bt_dev_err ( hdev, ""QCA read fw build info with no header"" ) ; err = - EILSEQ ; goto out ; } if ( edl -> cresp!= EDL_CMD_REQ_RES"
93,<S2SV_ModStart> if (! qca_fw_build_ver_len ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> * build_label ; char cmd ; int build_lbl_len, err = 0 ; bt_dev_dbg ( hdev, ""QCA read fw build info"" ) ; cmd = EDL_GET_BUILD_INFO_CMD ; skb = __hci_cmd_sync_ev ( hdev, EDL_PATCH_CMD_OPCODE, EDL_PATCH_CMD_LEN, & cmd, 0, HCI_INIT_TIMEOUT ) ; if ( IS_ERR ( skb ) ) { err = PTR_ERR ( skb ) ; bt_dev_err ( hdev, ""Reading QCA fw build info failed (%d)"", err ) ; return err ; } if ( skb -> len < sizeof ( * edl ) ) { err = - EILSEQ ; goto out ; } edl = ( struct edl_event_hdr * ) ( skb -> data ) ; if (! edl ) { bt_dev_err ( hdev, ""QCA read fw build info with no header"" ) ; err = - EILSEQ ; goto out ; } if ( edl -> cresp!= EDL_CMD_REQ_RES"
94,<S2SV_ModStart> if (! skb ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> * build_label ; char cmd ; int build_lbl_len, err = 0 ; bt_dev_dbg ( hdev, ""QCA read fw build info"" ) ; cmd = EDL_GET_BUILD_INFO_CMD ; skb = __hci_cmd_sync_ev ( hdev, EDL_PATCH_CMD_OPCODE, EDL_PATCH_CMD_LEN, & cmd, 0, HCI_INIT_TIMEOUT ) ; if ( IS_ERR ( skb ) ) { err = PTR_ERR ( skb ) ; bt_dev_err ( hdev, ""Reading QCA fw build info failed (%d)"", err ) ; return err ; } if ( skb -> len < sizeof ( * edl ) ) { err = - EILSEQ ; goto out ; } edl = ( struct edl_event_hdr * ) ( skb -> data ) ; if (! edl ) { bt_dev_err ( hdev, ""QCA read fw build info with no header"" ) ; err = - EILSEQ ; goto out ; } if ( edl -> cresp!= EDL_CMD_REQ_RES"
95,<S2SV_ModStart> if (! mas. index ) { return - ENOENT ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> - mas. index + 1 ], ( ( mas. last - max ) * sizeof ( unsigned long ) ), map -> alloc_flags ) ; <S2SV_ModEnd>"
96,<S2SV_ModStart> if (! mas. index ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> - mas. index + 1 ], ( ( mas. last - max ) * sizeof ( unsigned long ) ), map -> alloc_flags ) ; <S2SV_ModEnd>"
97,<S2SV_ModStart> if (! lower ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> - mas. index + 1 ], ( ( mas. last - max ) * sizeof ( unsigned long ) ), map -> alloc_flags ) ; <S2SV_ModEnd>"
98,<S2SV_ModStart> if (! lower ) { lower = NULL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> - mas. index + 1 ], ( ( mas. last - max ) * sizeof ( unsigned long ) ), map -> alloc_flags ) ; <S2SV_ModEnd>"
99,<S2SV_ModStart> && mas. index > 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> - mas. index + 1 ], ( ( mas. last - max ) * sizeof ( unsigned long ) ), map -> alloc_flags ) ; <S2SV_ModEnd>"
100,<S2SV_ModStart> if ( info == NULL ) return FALSE ; <S2SV_ModEnd>,0,<S2SV_ModStart> WINPR_ASSERT ( info ) ; if (! info -> domain ||! info -> username ) return FALSE ; <S2SV_ModEnd>
101,<S2SV_ModStart> if (! info ) return FALSE ; <S2SV_ModEnd>,0,<S2SV_ModStart> WINPR_ASSERT ( info ) ; if (! info -> domain ||! info -> username ) return FALSE ; <S2SV_ModEnd>
102,<S2SV_ModStart> if ( len == 0 ) return FALSE ; <S2SV_ModEnd>,0,<S2SV_ModStart> WINPR_ASSERT ( info ) ; if (! info -> domain ||! info -> username ) return FALSE ; <S2SV_ModEnd>
103,<S2SV_ModStart> if (! info -> domain ) return FALSE ; <S2SV_ModEnd>,0,<S2SV_ModStart> WINPR_ASSERT ( info ) ; if (! info -> domain ||! info -> username ) return FALSE ; <S2SV_ModEnd>
104,<S2SV_ModStart> if ( info == NULL ) { return FALSE ; } <S2SV_ModEnd>,0,<S2SV_ModStart> WINPR_ASSERT ( info ) ; if (! info -> domain ||! info -> username ) return FALSE ; <S2SV_ModEnd>
105,<S2SV_ModStart> if ( unlikely ( map == NULL ) ) goto err ; <S2SV_ModEnd>,0,", u32 flags ) { struct bpf_redirect_info * ri = this_cpu_ptr ( & bpf_redirect_info ) ; struct bpf_map * map ; int err ; switch ( map_type ) { case BPF_MAP_TYPE_DEVMAP : fallthrough ; case BPF_MAP_TYPE_DEVMAP_HASH : if ( unlikely ( flags & BPF_F_BROADCAST ) ) { map = READ_ONCE ( ri -> map ) ; /* The map pointer is cleared when the map is being torn
			 * down by bpf_clear_redirect_map()
			 */ if ( unlikely (! map ) ) { err = - ENOENT ; break ; } WRITE_ONCE ( ri -> map, NULL ) ; err = dev_map_redirect_multi ( dev, skb, xdp_prog, map, flags & BPF_F_EXCLUDE_INGRESS ) ; <S2SV_ModEnd>"
106,<S2SV_ModStart> if ( unlikely ( ri -> map == NULL ) ) { err = - EINVAL ; <S2SV_ModEnd>,0,", u32 flags ) { struct bpf_redirect_info * ri = this_cpu_ptr ( & bpf_redirect_info ) ; struct bpf_map * map ; int err ; switch ( map_type ) { case BPF_MAP_TYPE_DEVMAP : fallthrough ; case BPF_MAP_TYPE_DEVMAP_HASH : if ( unlikely ( flags & BPF_F_BROADCAST ) ) { map = READ_ONCE ( ri -> map ) ; /* The map pointer is cleared when the map is being torn
			 * down by bpf_clear_redirect_map()
			 */ if ( unlikely (! map ) ) { err = - ENOENT ; break ; } WRITE_ONCE ( ri -> map, NULL ) ; err = dev_map_redirect_multi ( dev, skb, xdp_prog, map, flags & BPF_F_EXCLUDE_INGRESS ) ; <S2SV_ModEnd>"
107,<S2SV_ModStart> if ( unlikely ( map == NULL ) ) { err = - ENOENT ; <S2SV_ModEnd>,0,", u32 flags ) { struct bpf_redirect_info * ri = this_cpu_ptr ( & bpf_redirect_info ) ; struct bpf_map * map ; int err ; switch ( map_type ) { case BPF_MAP_TYPE_DEVMAP : fallthrough ; case BPF_MAP_TYPE_DEVMAP_HASH : if ( unlikely ( flags & BPF_F_BROADCAST ) ) { map = READ_ONCE ( ri -> map ) ; /* The map pointer is cleared when the map is being torn
			 * down by bpf_clear_redirect_map()
			 */ if ( unlikely (! map ) ) { err = - ENOENT ; break ; } WRITE_ONCE ( ri -> map, NULL ) ; err = dev_map_redirect_multi ( dev, skb, xdp_prog, map, flags & BPF_F_EXCLUDE_INGRESS ) ; <S2SV_ModEnd>"
108,<S2SV_ModStart> if ( unlikely (! skb ) ) goto err ; <S2SV_ModEnd>,0,", u32 flags ) { struct bpf_redirect_info * ri = this_cpu_ptr ( & bpf_redirect_info ) ; struct bpf_map * map ; int err ; switch ( map_type ) { case BPF_MAP_TYPE_DEVMAP : fallthrough ; case BPF_MAP_TYPE_DEVMAP_HASH : if ( unlikely ( flags & BPF_F_BROADCAST ) ) { map = READ_ONCE ( ri -> map ) ; /* The map pointer is cleared when the map is being torn
			 * down by bpf_clear_redirect_map()
			 */ if ( unlikely (! map ) ) { err = - ENOENT ; break ; } WRITE_ONCE ( ri -> map, NULL ) ; err = dev_map_redirect_multi ( dev, skb, xdp_prog, map, flags & BPF_F_EXCLUDE_INGRESS ) ; <S2SV_ModEnd>"
109,<S2SV_ModStart> if ( unlikely (! fwd ) ) goto err ; <S2SV_ModEnd>,0,", u32 flags ) { struct bpf_redirect_info * ri = this_cpu_ptr ( & bpf_redirect_info ) ; struct bpf_map * map ; int err ; switch ( map_type ) { case BPF_MAP_TYPE_DEVMAP : fallthrough ; case BPF_MAP_TYPE_DEVMAP_HASH : if ( unlikely ( flags & BPF_F_BROADCAST ) ) { map = READ_ONCE ( ri -> map ) ; /* The map pointer is cleared when the map is being torn
			 * down by bpf_clear_redirect_map()
			 */ if ( unlikely (! map ) ) { err = - ENOENT ; break ; } WRITE_ONCE ( ri -> map, NULL ) ; err = dev_map_redirect_multi ( dev, skb, xdp_prog, map, flags & BPF_F_EXCLUDE_INGRESS ) ; <S2SV_ModEnd>"
110,"<S2SV_ModStart> if ( app_reply -> elem_count!= 0 ) { ql_dbg ( ql_dbg_async, vha, 0x911c, ""%s app did not indicate number of ports to return\n"", __func__ ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> >= app_req. num_ports ) break ; <S2SV_ModEnd>
111,"<S2SV_ModStart> if ( app_reply -> elem_count!= 0 ) { ql_dbg ( ql_dbg_async, vha, 0x911a, ""%s app did not indicate number of ports to return\n"", __func__ ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> >= app_req. num_ports ) break ; <S2SV_ModEnd>
112,"<S2SV_ModStart> if ( app_reply -> elem_count!= 0 ) { ql_dbg ( ql_dbg_async, vha, 0x911c, ""%s app did not indicate number of ports to return\n"", __func__ ) ; } <S2SV_ModEnd>",0,<S2SV_ModStart> >= app_req. num_ports ) break ; <S2SV_ModEnd>
113,"<S2SV_ModStart> if ( app_reply -> elem_count!= 0 ) { ql_dbg ( ql_dbg_async, vha, 0x911d, ""%s app did not indicate number of ports to return\n"", __func__ ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> >= app_req. num_ports ) break ; <S2SV_ModEnd>
114,"<S2SV_ModStart> if ( app_reply -> elem_count!= 0 ) { ql_dbg ( ql_dbg_async, vha, 0x912c, ""%s app did not indicate number of ports to return\n"", __func__ ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> >= app_req. num_ports ) break ; <S2SV_ModEnd>
115,<S2SV_ModStart> if (! edl ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb -> len < 3 ) { err = - EILSEQ ; goto out ; } <S2SV_ModEnd>
116,<S2SV_ModStart> && edl -> data [ 0 ] == 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb -> len < 3 ) { err = - EILSEQ ; goto out ; } <S2SV_ModEnd>
117,<S2SV_ModStart> if (! edl ) { err = - EINVAL ; goto out ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb -> len < 3 ) { err = - EILSEQ ; goto out ; } <S2SV_ModEnd>
118,<S2SV_ModStart> if (! edl ) { return - ENODEV ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb -> len < 3 ) { err = - EILSEQ ; goto out ; } <S2SV_ModEnd>
119,<S2SV_ModStart> if (! edl ) { return - ENOMEM ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb -> len < 3 ) { err = - EILSEQ ; goto out ; } <S2SV_ModEnd>
120,"<S2SV_ModStart> ; s64 delay, tdelta ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, shift ; s64 vover, vover_pct ; u32 hwa ; lockdep_assert_held ( & iocg -> waitq. lock ) ; /*
	 * If the delay is set by another CPU, we may be in the past. No need to
	 * change anything if so. This avoids decay calculation underflow.
	 */ if ( time_before64 ( now -> now, iocg -> delay_at ) ) return false ; /* calculate the current delay in effect - 1/2 every second */ tdelta = now -> now - iocg -> delay_at ; shift = div64_u64 ( tdelta, USEC_PER_SEC ) ; if ( iocg -> delay && shift < BITS_PER_LONG ) delay = iocg -> delay >> shift ; <S2SV_ModEnd>"
121,"<S2SV_ModStart> ; s64 tdelta, delay ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, shift ; s64 vover, vover_pct ; u32 hwa ; lockdep_assert_held ( & iocg -> waitq. lock ) ; /*
	 * If the delay is set by another CPU, we may be in the past. No need to
	 * change anything if so. This avoids decay calculation underflow.
	 */ if ( time_before64 ( now -> now, iocg -> delay_at ) ) return false ; /* calculate the current delay in effect - 1/2 every second */ tdelta = now -> now - iocg -> delay_at ; shift = div64_u64 ( tdelta, USEC_PER_SEC ) ; if ( iocg -> delay && shift < BITS_PER_LONG ) delay = iocg -> delay >> shift ; <S2SV_ModEnd>"
122,"<S2SV_ModStart> unsigned long tdelta, delay ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, shift ; s64 vover, vover_pct ; u32 hwa ; lockdep_assert_held ( & iocg -> waitq. lock ) ; /*
	 * If the delay is set by another CPU, we may be in the past. No need to
	 * change anything if so. This avoids decay calculation underflow.
	 */ if ( time_before64 ( now -> now, iocg -> delay_at ) ) return false ; /* calculate the current delay in effect - 1/2 every second */ tdelta = now -> now - iocg -> delay_at ; shift = div64_u64 ( tdelta, USEC_PER_SEC ) ; if ( iocg -> delay && shift < BITS_PER_LONG ) delay = iocg -> delay >> shift ; <S2SV_ModEnd>"
123,"<S2SV_ModStart> ; u64 tdelta, delay ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, shift ; s64 vover, vover_pct ; u32 hwa ; lockdep_assert_held ( & iocg -> waitq. lock ) ; /*
	 * If the delay is set by another CPU, we may be in the past. No need to
	 * change anything if so. This avoids decay calculation underflow.
	 */ if ( time_before64 ( now -> now, iocg -> delay_at ) ) return false ; /* calculate the current delay in effect - 1/2 every second */ tdelta = now -> now - iocg -> delay_at ; shift = div64_u64 ( tdelta, USEC_PER_SEC ) ; if ( iocg -> delay && shift < BITS_PER_LONG ) delay = iocg -> delay >> shift ; <S2SV_ModEnd>"
124,"<S2SV_ModStart> unsigned long delay, tdelta ; <S2SV_ModEnd>",0,"<S2SV_ModStart>, shift ; s64 vover, vover_pct ; u32 hwa ; lockdep_assert_held ( & iocg -> waitq. lock ) ; /*
	 * If the delay is set by another CPU, we may be in the past. No need to
	 * change anything if so. This avoids decay calculation underflow.
	 */ if ( time_before64 ( now -> now, iocg -> delay_at ) ) return false ; /* calculate the current delay in effect - 1/2 every second */ tdelta = now -> now - iocg -> delay_at ; shift = div64_u64 ( tdelta, USEC_PER_SEC ) ; if ( iocg -> delay && shift < BITS_PER_LONG ) delay = iocg -> delay >> shift ; <S2SV_ModEnd>"
125,<S2SV_ModStart> if ( keyring == NULL ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( prep -> expiry!= TIME64_MAX ) key_set_expiry ( key, prep -> expiry ) ; <S2SV_ModEnd>"
126,<S2SV_ModStart> if ( keyring == NULL ) { return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( prep -> expiry!= TIME64_MAX ) key_set_expiry ( key, prep -> expiry ) ; <S2SV_ModEnd>"
127,"<S2SV_ModStart> keyring && keyring -> type -> instantiate ( keyring, prep ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> if ( prep -> expiry!= TIME64_MAX ) key_set_expiry ( key, prep -> expiry ) ; <S2SV_ModEnd>"
128,"<S2SV_ModStart> keyring && keyring -> type -> instantiate ( key, prep ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> if ( prep -> expiry!= TIME64_MAX ) key_set_expiry ( key, prep -> expiry ) ; <S2SV_ModEnd>"
129,<S2SV_ModStart> if ( keyring == NULL ) { return - ENOKEY ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( prep -> expiry!= TIME64_MAX ) key_set_expiry ( key, prep -> expiry ) ; <S2SV_ModEnd>"
130,"<S2SV_ModStart> cpumask_clear_cpu ( p -> wake_cpu, pool -> attrs -> __pod_cpumask ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> int wake_cpu = cpumask_any_and_distribute ( pool -> attrs -> __pod_cpumask, cpu_online_mask ) ; if ( wake_cpu < nr_cpu_ids ) { p -> wake_cpu = wake_cpu ; get_work_pwq ( work ) -> stats [ PWQ_STAT_REPATRIATED ] ++ ; } } <S2SV_ModEnd>"
131,<S2SV_ModStart> unsigned long cost = cpumask_any ( pool -> attrs -> __pod_cpumask ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> int wake_cpu = cpumask_any_and_distribute ( pool -> attrs -> __pod_cpumask, cpu_online_mask ) ; if ( wake_cpu < nr_cpu_ids ) { p -> wake_cpu = wake_cpu ; get_work_pwq ( work ) -> stats [ PWQ_STAT_REPATRIATED ] ++ ; } } <S2SV_ModEnd>"
132,<S2SV_ModStart> if (! pool -> wake_cpu ) { return false ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> int wake_cpu = cpumask_any_and_distribute ( pool -> attrs -> __pod_cpumask, cpu_online_mask ) ; if ( wake_cpu < nr_cpu_ids ) { p -> wake_cpu = wake_cpu ; get_work_pwq ( work ) -> stats [ PWQ_STAT_REPATRIATED ] ++ ; } } <S2SV_ModEnd>"
133,"<S2SV_ModStart> cpumask_clear_cpu ( p -> wake_cpu, pool -> attrs -> num_online_cpus ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> int wake_cpu = cpumask_any_and_distribute ( pool -> attrs -> __pod_cpumask, cpu_online_mask ) ; if ( wake_cpu < nr_cpu_ids ) { p -> wake_cpu = wake_cpu ; get_work_pwq ( work ) -> stats [ PWQ_STAT_REPATRIATED ] ++ ; } } <S2SV_ModEnd>"
134,<S2SV_ModStart> if (! pool -> worklist ) return false ; <S2SV_ModEnd>,0,"<S2SV_ModStart> int wake_cpu = cpumask_any_and_distribute ( pool -> attrs -> __pod_cpumask, cpu_online_mask ) ; if ( wake_cpu < nr_cpu_ids ) { p -> wake_cpu = wake_cpu ; get_work_pwq ( work ) -> stats [ PWQ_STAT_REPATRIATED ] ++ ; } } <S2SV_ModEnd>"
135,<S2SV_ModStart> unsigned long end = jiffies + msecs_to_jiffies ( 20 ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long cur, end = jiffies + timeout ; qdev = container_of ( fence -> lock, struct qxl_device, release_lock ) ; if (! wait_event_timeout ( qdev -> release_event, ( dma_fence_is_signaled ( fence ) || ( qxl_io_notify_oom ( qdev ), 0 ) ), timeout ) ) return 0 ; cur = jiffies ; <S2SV_ModEnd>"
136,<S2SV_ModStart> ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long cur, end = jiffies + timeout ; qdev = container_of ( fence -> lock, struct qxl_device, release_lock ) ; if (! wait_event_timeout ( qdev -> release_event, ( dma_fence_is_signaled ( fence ) || ( qxl_io_notify_oom ( qdev ), 0 ) ), timeout ) ) return 0 ; cur = jiffies ; <S2SV_ModEnd>"
137,<S2SV_ModStart> if ( count == 0 ) { return 0 ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long cur, end = jiffies + timeout ; qdev = container_of ( fence -> lock, struct qxl_device, release_lock ) ; if (! wait_event_timeout ( qdev -> release_event, ( dma_fence_is_signaled ( fence ) || ( qxl_io_notify_oom ( qdev ), 0 ) ), timeout ) ) return 0 ; cur = jiffies ; <S2SV_ModEnd>"
138,<S2SV_ModStart> if ( count < 0 ) return 0 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long cur, end = jiffies + timeout ; qdev = container_of ( fence -> lock, struct qxl_device, release_lock ) ; if (! wait_event_timeout ( qdev -> release_event, ( dma_fence_is_signaled ( fence ) || ( qxl_io_notify_oom ( qdev ), 0 ) ), timeout ) ) return 0 ; cur = jiffies ; <S2SV_ModEnd>"
139,<S2SV_ModStart> unsigned long end = jiffies + msecs_to_jiffies ( 50 ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long cur, end = jiffies + timeout ; qdev = container_of ( fence -> lock, struct qxl_device, release_lock ) ; if (! wait_event_timeout ( qdev -> release_event, ( dma_fence_is_signaled ( fence ) || ( qxl_io_notify_oom ( qdev ), 0 ) ), timeout ) ) return 0 ; cur = jiffies ; <S2SV_ModEnd>"
140,<S2SV_ModStart> if ( cdev == NULL ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> blocking_notifier_chain_unregister ( & gdev -> device_notifier, & cdev -> device_unregistered_nb ) ; blocking_notifier_chain_unregister ( & gdev -> line_state_notifier, & cdev -> lineinfo_changed_nb ) ; bitmap_free ( cdev -> watched_lines ) ; <S2SV_ModEnd>"
141,<S2SV_ModStart> if (! cdev ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> blocking_notifier_chain_unregister ( & gdev -> device_notifier, & cdev -> device_unregistered_nb ) ; blocking_notifier_chain_unregister ( & gdev -> line_state_notifier, & cdev -> lineinfo_changed_nb ) ; bitmap_free ( cdev -> watched_lines ) ; <S2SV_ModEnd>"
142,<S2SV_ModStart> if ( cdev == NULL ) { return - ENODEV ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> blocking_notifier_chain_unregister ( & gdev -> device_notifier, & cdev -> device_unregistered_nb ) ; blocking_notifier_chain_unregister ( & gdev -> line_state_notifier, & cdev -> lineinfo_changed_nb ) ; bitmap_free ( cdev -> watched_lines ) ; <S2SV_ModEnd>"
143,<S2SV_ModStart> kfree ( cdev -> watched_lines ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> blocking_notifier_chain_unregister ( & gdev -> device_notifier, & cdev -> device_unregistered_nb ) ; blocking_notifier_chain_unregister ( & gdev -> line_state_notifier, & cdev -> lineinfo_changed_nb ) ; bitmap_free ( cdev -> watched_lines ) ; <S2SV_ModEnd>"
144,<S2SV_ModStart> kfree ( cdev -> line_info ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> blocking_notifier_chain_unregister ( & gdev -> device_notifier, & cdev -> device_unregistered_nb ) ; blocking_notifier_chain_unregister ( & gdev -> line_state_notifier, & cdev -> lineinfo_changed_nb ) ; bitmap_free ( cdev -> watched_lines ) ; <S2SV_ModEnd>"
145,"<S2SV_ModStart> if ( sha_handle == NULL ) { ESP_LOGE ( TAG, ""bootloader_mmap(0x%x, 0x%x) failed"", load_addr, data_len ) ; return ESP_FAIL ; } <S2SV_ModEnd>",0,"process_segment ( int index, uint32_t flash_addr, esp_image_segment_header_t * header, bool silent, bool do_load, bootloader_sha256_handle_t sha_handle, uint32_t * checksum, esp_image_metadata_t * metadata ) { esp_err_t err ; /* read segment header */ err = bootloader_flash_read ( flash_addr, header, sizeof ( esp_image_segment_header_t ), true ) ; if ( err!= ESP_OK ) { ESP_LOGE ( TAG, ""bootloader_flash_read failed at 0x%08x"", flash_addr ) ; return err ; } if ( sha_handle!= NULL ) { bootloader_sha256_data ( sha_handle, header, sizeof ( esp_image_segment_header_t ) ) ; } intptr_t load_addr = header -> load_addr ; uint32_t data_len = header -> data_len ; uint32_t data_addr = flash_addr + sizeof ( esp_image_segment_header_t ) ; ESP_LOGV"
146,"<S2SV_ModStart> memset ( ram_obfs_value, 0, sizeof ( ram_obfs_value ) ) ; <S2SV_ModEnd>",0,"process_segment ( int index, uint32_t flash_addr, esp_image_segment_header_t * header, bool silent, bool do_load, bootloader_sha256_handle_t sha_handle, uint32_t * checksum, esp_image_metadata_t * metadata ) { esp_err_t err ; /* read segment header */ err = bootloader_flash_read ( flash_addr, header, sizeof ( esp_image_segment_header_t ), true ) ; if ( err!= ESP_OK ) { ESP_LOGE ( TAG, ""bootloader_flash_read failed at 0x%08x"", flash_addr ) ; return err ; } if ( sha_handle!= NULL ) { bootloader_sha256_data ( sha_handle, header, sizeof ( esp_image_segment_header_t ) ) ; } intptr_t load_addr = header -> load_addr ; uint32_t data_len = header -> data_len ; uint32_t data_addr = flash_addr + sizeof ( esp_image_segment_header_t ) ; ESP_LOGV"
147,"<S2SV_ModStart> if ( sha_handle == NULL ) { ESP_LOGE ( TAG, ""bootloader_mmap(0x%x, 0x%x) failed"", load_addr, data_len ) ; return ESP_OK ; } <S2SV_ModEnd>",0,"process_segment ( int index, uint32_t flash_addr, esp_image_segment_header_t * header, bool silent, bool do_load, bootloader_sha256_handle_t sha_handle, uint32_t * checksum, esp_image_metadata_t * metadata ) { esp_err_t err ; /* read segment header */ err = bootloader_flash_read ( flash_addr, header, sizeof ( esp_image_segment_header_t ), true ) ; if ( err!= ESP_OK ) { ESP_LOGE ( TAG, ""bootloader_flash_read failed at 0x%08x"", flash_addr ) ; return err ; } if ( sha_handle!= NULL ) { bootloader_sha256_data ( sha_handle, header, sizeof ( esp_image_segment_header_t ) ) ; } intptr_t load_addr = header -> load_addr ; uint32_t data_len = header -> data_len ; uint32_t data_addr = flash_addr + sizeof ( esp_image_segment_header_t ) ; ESP_LOGV"
148,"<S2SV_ModStart> if ( sha_handle == NULL ) { ESP_LOGE ( TAG, ""bootloader_munmap(0x%x, 0x%x) failed"", load_addr, data_len ) ; return ESP_FAIL ; } <S2SV_ModEnd>",0,"process_segment ( int index, uint32_t flash_addr, esp_image_segment_header_t * header, bool silent, bool do_load, bootloader_sha256_handle_t sha_handle, uint32_t * checksum, esp_image_metadata_t * metadata ) { esp_err_t err ; /* read segment header */ err = bootloader_flash_read ( flash_addr, header, sizeof ( esp_image_segment_header_t ), true ) ; if ( err!= ESP_OK ) { ESP_LOGE ( TAG, ""bootloader_flash_read failed at 0x%08x"", flash_addr ) ; return err ; } if ( sha_handle!= NULL ) { bootloader_sha256_data ( sha_handle, header, sizeof ( esp_image_segment_header_t ) ) ; } intptr_t load_addr = header -> load_addr ; uint32_t data_len = header -> data_len ; uint32_t data_addr = flash_addr + sizeof ( esp_image_segment_header_t ) ; ESP_LOGV"
149,"<S2SV_ModStart> if ( sha_handle == NULL ) { ESP_LOGE ( TAG, ""bootloader_mmap(0x%x, 0x%x) failed"", data_addr, data_len ) ; return ESP_FAIL ; } <S2SV_ModEnd>",0,"process_segment ( int index, uint32_t flash_addr, esp_image_segment_header_t * header, bool silent, bool do_load, bootloader_sha256_handle_t sha_handle, uint32_t * checksum, esp_image_metadata_t * metadata ) { esp_err_t err ; /* read segment header */ err = bootloader_flash_read ( flash_addr, header, sizeof ( esp_image_segment_header_t ), true ) ; if ( err!= ESP_OK ) { ESP_LOGE ( TAG, ""bootloader_flash_read failed at 0x%08x"", flash_addr ) ; return err ; } if ( sha_handle!= NULL ) { bootloader_sha256_data ( sha_handle, header, sizeof ( esp_image_segment_header_t ) ) ; } intptr_t load_addr = header -> load_addr ; uint32_t data_len = header -> data_len ; uint32_t data_addr = flash_addr + sizeof ( esp_image_segment_header_t ) ; ESP_LOGV"
150,"<S2SV_ModStart> if ( smh -> submessageLength < RTPSMESSAGE_DATA_MIN_LENGTH ) { EPROSIMA_LOG_INFO ( RTPS_MSG_IN, IDSTRING ""Too short submessage received, ignoring"" ) ; return false ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> const uint32_t submsg_no_payload_size = RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize ; // Prevent integer overflow of variable payload_size if ( smh -> submessageLength < submsg_no_payload_size ) { EPROSIMA_LOG_WARNING ( RTPS_MSG_IN, IDSTRING ""Serialized Payload avoided overflow "" ""("" << smh -> submessageLength << ""/"" << submsg_no_payload_size << "")"" ) ; ch. serializedPayload. data = nullptr ; ch. inline_qos. data = nullptr ; return false ; } payload_size = smh -> submessageLength - submsg_no_payload_size ; <S2SV_ModEnd>"
151,<S2SV_ModStart> if ( smh == NULL ) { return false ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> const uint32_t submsg_no_payload_size = RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize ; // Prevent integer overflow of variable payload_size if ( smh -> submessageLength < submsg_no_payload_size ) { EPROSIMA_LOG_WARNING ( RTPS_MSG_IN, IDSTRING ""Serialized Payload avoided overflow "" ""("" << smh -> submessageLength << ""/"" << submsg_no_payload_size << "")"" ) ; ch. serializedPayload. data = nullptr ; ch. inline_qos. data = nullptr ; return false ; } payload_size = smh -> submessageLength - submsg_no_payload_size ; <S2SV_ModEnd>"
152,"<S2SV_ModStart> if ( smh -> submessageLength < RTPSMESSAGE_DATA_MIN_LENGTH ) { EPROSIMA_LOG_WARNING ( RTPS_MSG_IN, IDSTRING ""Too short submessage received, ignoring"" ) ; return false ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> const uint32_t submsg_no_payload_size = RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize ; // Prevent integer overflow of variable payload_size if ( smh -> submessageLength < submsg_no_payload_size ) { EPROSIMA_LOG_WARNING ( RTPS_MSG_IN, IDSTRING ""Serialized Payload avoided overflow "" ""("" << smh -> submessageLength << ""/"" << submsg_no_payload_size << "")"" ) ; ch. serializedPayload. data = nullptr ; ch. inline_qos. data = nullptr ; return false ; } payload_size = smh -> submessageLength - submsg_no_payload_size ; <S2SV_ModEnd>"
153,<S2SV_ModStart> if (! smh -> submessageLength ) { return false ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> const uint32_t submsg_no_payload_size = RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize ; // Prevent integer overflow of variable payload_size if ( smh -> submessageLength < submsg_no_payload_size ) { EPROSIMA_LOG_WARNING ( RTPS_MSG_IN, IDSTRING ""Serialized Payload avoided overflow "" ""("" << smh -> submessageLength << ""/"" << submsg_no_payload_size << "")"" ) ; ch. serializedPayload. data = nullptr ; ch. inline_qos. data = nullptr ; return false ; } payload_size = smh -> submessageLength - submsg_no_payload_size ; <S2SV_ModEnd>"
154,"<S2SV_ModStart> if ( smh -> submessageLength < RTPSMESSAGE_DATA_MIN_LENGTH ) { EPROSIMA_LOG_INFO ( RTPS_MSG_IN, IDSTRING ""Too short submessage received, ignoring"" ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> const uint32_t submsg_no_payload_size = RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize ; // Prevent integer overflow of variable payload_size if ( smh -> submessageLength < submsg_no_payload_size ) { EPROSIMA_LOG_WARNING ( RTPS_MSG_IN, IDSTRING ""Serialized Payload avoided overflow "" ""("" << smh -> submessageLength << ""/"" << submsg_no_payload_size << "")"" ) ; ch. serializedPayload. data = nullptr ; ch. inline_qos. data = nullptr ; return false ; } payload_size = smh -> submessageLength - submsg_no_payload_size ; <S2SV_ModEnd>"
155,<S2SV_ModStart> if ( ret < 0 ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long flags ; if ( io_data -> read && ret > 0 ) { kthread_use_mm ( io_data -> mm ) ; ret = ffs_copy_to_iter ( io_data -> buf, ret, & io_data -> data ) ; kthread_unuse_mm ( io_data -> mm ) ; } io_data -> kiocb -> ki_complete ( io_data -> kiocb, ret, ret ) ; if ( io_data -> ffs -> ffs_eventfd &&! kiocb_has_eventfd ) eventfd_signal ( io_data -> ffs -> ffs_eventfd, 1 ) ; spin_lock_irqsave ( & io_data -> ffs -> eps_lock, flags ) ; usb_ep_free_request ( io_data -> ep, io_data -> req ) ; io_data -> req = NULL ; spin_unlock_irqrestore ( & io_data -> ffs -> eps_lock, flags ) ; <S2SV_ModEnd>"
156,<S2SV_ModStart> if ( io_data -> buf == NULL ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long flags ; if ( io_data -> read && ret > 0 ) { kthread_use_mm ( io_data -> mm ) ; ret = ffs_copy_to_iter ( io_data -> buf, ret, & io_data -> data ) ; kthread_unuse_mm ( io_data -> mm ) ; } io_data -> kiocb -> ki_complete ( io_data -> kiocb, ret, ret ) ; if ( io_data -> ffs -> ffs_eventfd &&! kiocb_has_eventfd ) eventfd_signal ( io_data -> ffs -> ffs_eventfd, 1 ) ; spin_lock_irqsave ( & io_data -> ffs -> eps_lock, flags ) ; usb_ep_free_request ( io_data -> ep, io_data -> req ) ; io_data -> req = NULL ; spin_unlock_irqrestore ( & io_data -> ffs -> eps_lock, flags ) ; <S2SV_ModEnd>"
157,<S2SV_ModStart> if ( io_data -> read == 0 ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long flags ; if ( io_data -> read && ret > 0 ) { kthread_use_mm ( io_data -> mm ) ; ret = ffs_copy_to_iter ( io_data -> buf, ret, & io_data -> data ) ; kthread_unuse_mm ( io_data -> mm ) ; } io_data -> kiocb -> ki_complete ( io_data -> kiocb, ret, ret ) ; if ( io_data -> ffs -> ffs_eventfd &&! kiocb_has_eventfd ) eventfd_signal ( io_data -> ffs -> ffs_eventfd, 1 ) ; spin_lock_irqsave ( & io_data -> ffs -> eps_lock, flags ) ; usb_ep_free_request ( io_data -> ep, io_data -> req ) ; io_data -> req = NULL ; spin_unlock_irqrestore ( & io_data -> ffs -> eps_lock, flags ) ; <S2SV_ModEnd>"
158,<S2SV_ModStart> if ( ret <= 0 ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long flags ; if ( io_data -> read && ret > 0 ) { kthread_use_mm ( io_data -> mm ) ; ret = ffs_copy_to_iter ( io_data -> buf, ret, & io_data -> data ) ; kthread_unuse_mm ( io_data -> mm ) ; } io_data -> kiocb -> ki_complete ( io_data -> kiocb, ret, ret ) ; if ( io_data -> ffs -> ffs_eventfd &&! kiocb_has_eventfd ) eventfd_signal ( io_data -> ffs -> ffs_eventfd, 1 ) ; spin_lock_irqsave ( & io_data -> ffs -> eps_lock, flags ) ; usb_ep_free_request ( io_data -> ep, io_data -> req ) ; io_data -> req = NULL ; spin_unlock_irqrestore ( & io_data -> ffs -> eps_lock, flags ) ; <S2SV_ModEnd>"
159,<S2SV_ModStart> kfree ( io_data -> buf ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; unsigned long flags ; if ( io_data -> read && ret > 0 ) { kthread_use_mm ( io_data -> mm ) ; ret = ffs_copy_to_iter ( io_data -> buf, ret, & io_data -> data ) ; kthread_unuse_mm ( io_data -> mm ) ; } io_data -> kiocb -> ki_complete ( io_data -> kiocb, ret, ret ) ; if ( io_data -> ffs -> ffs_eventfd &&! kiocb_has_eventfd ) eventfd_signal ( io_data -> ffs -> ffs_eventfd, 1 ) ; spin_lock_irqsave ( & io_data -> ffs -> eps_lock, flags ) ; usb_ep_free_request ( io_data -> ep, io_data -> req ) ; io_data -> req = NULL ; spin_unlock_irqrestore ( & io_data -> ffs -> eps_lock, flags ) ; <S2SV_ModEnd>"
160,<S2SV_ModStart> if ( ng == NULL ) { return NULL ; } <S2SV_ModEnd>,0,"unsigned int gen_ptrs = READ_ONCE ( max_gen_ptrs ) ; unsigned int generic_size ; struct net_generic * ng ; generic_size = offsetof ( struct net_generic, ptr [ gen_ptrs ] ) ; ng = kzalloc ( generic_size, GFP_KERNEL ) ; if ( ng ) ng -> s. len = gen_ptrs ; <S2SV_ModEnd>"
161,size_t generic_size ; <S2SV_ModEnd>,0,"unsigned int gen_ptrs = READ_ONCE ( max_gen_ptrs ) ; unsigned int generic_size ; struct net_generic * ng ; generic_size = offsetof ( struct net_generic, ptr [ gen_ptrs ] ) ; ng = kzalloc ( generic_size, GFP_KERNEL ) ; if ( ng ) ng -> s. len = gen_ptrs ; <S2SV_ModEnd>"
162,size_t generic_size ; struct net_generic * ng ; <S2SV_ModEnd>,0,"unsigned int gen_ptrs = READ_ONCE ( max_gen_ptrs ) ; unsigned int generic_size ; struct net_generic * ng ; generic_size = offsetof ( struct net_generic, ptr [ gen_ptrs ] ) ; ng = kzalloc ( generic_size, GFP_KERNEL ) ; if ( ng ) ng -> s. len = gen_ptrs ; <S2SV_ModEnd>"
163,size_t generic_size ) { struct net_generic * ng ; <S2SV_ModEnd>,0,"unsigned int gen_ptrs = READ_ONCE ( max_gen_ptrs ) ; unsigned int generic_size ; struct net_generic * ng ; generic_size = offsetof ( struct net_generic, ptr [ gen_ptrs ] ) ; ng = kzalloc ( generic_size, GFP_KERNEL ) ; if ( ng ) ng -> s. len = gen_ptrs ; <S2SV_ModEnd>"
164,size_t generic_size = sizeof ( struct net_generic ) ; <S2SV_ModEnd>,0,"unsigned int gen_ptrs = READ_ONCE ( max_gen_ptrs ) ; unsigned int generic_size ; struct net_generic * ng ; generic_size = offsetof ( struct net_generic, ptr [ gen_ptrs ] ) ; ng = kzalloc ( generic_size, GFP_KERNEL ) ; if ( ng ) ng -> s. len = gen_ptrs ; <S2SV_ModEnd>"
165,<S2SV_ModStart> if ( nn == NULL ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! rpc_proc_register ( net, & nn -> rpcstats ) ) { nfs_clients_exit ( net ) ; return - ENOMEM ; } return nfs_fs_proc_net_init ( net ) ; } <S2SV_ModEnd>"
166,<S2SV_ModStart> if ( nn == NULL ) { return - 1 ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! rpc_proc_register ( net, & nn -> rpcstats ) ) { nfs_clients_exit ( net ) ; return - ENOMEM ; } return nfs_fs_proc_net_init ( net ) ; } <S2SV_ModEnd>"
167,<S2SV_ModStart> if ( nn == NULL ) { return - ENOENT ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! rpc_proc_register ( net, & nn -> rpcstats ) ) { nfs_clients_exit ( net ) ; return - ENOMEM ; } return nfs_fs_proc_net_init ( net ) ; } <S2SV_ModEnd>"
168,<S2SV_ModStart> if ( nn == NULL ) { return - ENOMEM ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! rpc_proc_register ( net, & nn -> rpcstats ) ) { nfs_clients_exit ( net ) ; return - ENOMEM ; } return nfs_fs_proc_net_init ( net ) ; } <S2SV_ModEnd>"
169,<S2SV_ModStart> if ( nn == NULL ) { return - ENODEV ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! rpc_proc_register ( net, & nn -> rpcstats ) ) { nfs_clients_exit ( net ) ; return - ENOMEM ; } return nfs_fs_proc_net_init ( net ) ; } <S2SV_ModEnd>"
170,<S2SV_ModStart> if (! errorFlag. good ( ) ) errorFlag = EC_EndOfStream ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
171,<S2SV_ModStart> if ( errorFlag == NULL ) errorFlag = EC_Unknown ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
172,<S2SV_ModStart> if (! errorFlag ) { errorFlag = EC_Unknown ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
173,<S2SV_ModStart> if ( readStream == NULL ) errorFlag = EC_Unknown ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
174,<S2SV_ModStart> if (! errorFlag. good ( ) ) errorFlag = EC_Unknown ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
175,<S2SV_ModStart> if ( len == 0 ) { goto error_remove_tracker ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Update the packet length to the largest known data offset. */ len = MAX ( len, frag -> offset + frag -> data_len ) ; <S2SV_ModEnd>"
176,<S2SV_ModStart> if ( len == 0 ) { return NULL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Update the packet length to the largest known data offset. */ len = MAX ( len, frag -> offset + frag -> data_len ) ; <S2SV_ModEnd>"
177,<S2SV_ModStart> if ( frag == NULL ) { goto error_remove_tracker ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Update the packet length to the largest known data offset. */ len = MAX ( len, frag -> offset + frag -> data_len ) ; <S2SV_ModEnd>"
178,<S2SV_ModStart> if ( len < 0 ) { goto error_remove_tracker ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Update the packet length to the largest known data offset. */ len = MAX ( len, frag -> offset + frag -> data_len ) ; <S2SV_ModEnd>"
179,<S2SV_ModStart> if ( len == 0 ) { return NULL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Update the packet length to the largest known data offset. */ len = MAX ( len, frag -> offset + frag -> data_len ) ; <S2SV_ModEnd>"
180,"<S2SV_ModStart> if (! test_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ) return ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && test_bit ( EXTENT_BUFFER_DIRTY, & eb -> bflags ) ) { set_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ; <S2SV_ModEnd>"
181,"<S2SV_ModStart> if (! test_and_clear_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ) return ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && test_bit ( EXTENT_BUFFER_DIRTY, & eb -> bflags ) ) { set_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ; <S2SV_ModEnd>"
182,"<S2SV_ModStart> &&!test_bit( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ) return ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && test_bit ( EXTENT_BUFFER_DIRTY, & eb -> bflags ) ) { set_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ; <S2SV_ModEnd>"
183,<S2SV_ModStart> if (! eb -> len ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> && test_bit ( EXTENT_BUFFER_DIRTY, & eb -> bflags ) ) { set_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ; <S2SV_ModEnd>"
184,<S2SV_ModStart> if ( eb -> len == 0 ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> && test_bit ( EXTENT_BUFFER_DIRTY, & eb -> bflags ) ) { set_bit ( EXTENT_BUFFER_ZONED_ZEROOUT, & eb -> bflags ) ; <S2SV_ModEnd>"
185,"<S2SV_ModStart> ( reg & OHCI1394_NodeID_idValid ) == 0 ) { ohci_notice ( ohci, ""malconfigured bus\n"" ) ; return ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> param_debug & OHCI_PARAM_DEBUG_BUSRESETS ) reg_write ( ohci, OHCI1394_IntMaskSet, OHCI1394_busReset ) ; if ( ohci -> quirks & QUIRK_RESET_PACKET ) ohci -> request_generation = generation ; <S2SV_ModEnd>"
186,"<S2SV_ModStart> ( reg & OHCI1394_NodeID_busNumber ) == 0 ) { ohci_notice ( ohci, ""malconfigured bus\n"" ) ; return ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> param_debug & OHCI_PARAM_DEBUG_BUSRESETS ) reg_write ( ohci, OHCI1394_IntMaskSet, OHCI1394_busReset ) ; if ( ohci -> quirks & QUIRK_RESET_PACKET ) ohci -> request_generation = generation ; <S2SV_ModEnd>"
187,"<S2SV_ModStart> ( reg & OHCI1394_NodeID_reset ) == 0 ) ) { ohci_notice ( ohci, ""malconfigured bus\n"" ) ; return ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> param_debug & OHCI_PARAM_DEBUG_BUSRESETS ) reg_write ( ohci, OHCI1394_IntMaskSet, OHCI1394_busReset ) ; if ( ohci -> quirks & QUIRK_RESET_PACKET ) ohci -> request_generation = generation ; <S2SV_ModEnd>"
188,"<S2SV_ModStart> ( reg & OHCI1394_NodeID_idInvalid ) ) { ohci_notice ( ohci, ""malconfigured bus\n"" ) ; return ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> param_debug & OHCI_PARAM_DEBUG_BUSRESETS ) reg_write ( ohci, OHCI1394_IntMaskSet, OHCI1394_busReset ) ; if ( ohci -> quirks & QUIRK_RESET_PACKET ) ohci -> request_generation = generation ; <S2SV_ModEnd>"
189,"<S2SV_ModStart> ( reg & OHCI1394_NodeID_idInvalid ) ) { ohci_notice ( ohci, ""node ID not valid, new bus reset in progress\n"" ) ; return ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> param_debug & OHCI_PARAM_DEBUG_BUSRESETS ) reg_write ( ohci, OHCI1394_IntMaskSet, OHCI1394_busReset ) ; if ( ohci -> quirks & QUIRK_RESET_PACKET ) ohci -> request_generation = generation ; <S2SV_ModEnd>"
190,<S2SV_ModStart> if ( i == sizeof ( buf ) ) { ret = - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> bufsize && ( pg - page < len ) && * pg!= '\0' && * pg!= '\n' ) buf [ i ++ ] = * pg ++ ; if ( i == bufsize ) { ret = - EINVAL ; <S2SV_ModEnd>
191,<S2SV_ModStart> if ( i >= bufsize ) return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> bufsize && ( pg - page < len ) && * pg!= '\0' && * pg!= '\n' ) buf [ i ++ ] = * pg ++ ; if ( i == bufsize ) { ret = - EINVAL ; <S2SV_ModEnd>
192,<S2SV_ModStart> if ( i >= bufsize ) { return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> bufsize && ( pg - page < len ) && * pg!= '\0' && * pg!= '\n' ) buf [ i ++ ] = * pg ++ ; if ( i == bufsize ) { ret = - EINVAL ; <S2SV_ModEnd>
193,<S2SV_ModStart> if ( i == sizeof ( buf ) ) break ; <S2SV_ModEnd>,0,<S2SV_ModStart> bufsize && ( pg - page < len ) && * pg!= '\0' && * pg!= '\n' ) buf [ i ++ ] = * pg ++ ; if ( i == bufsize ) { ret = - EINVAL ; <S2SV_ModEnd>
194,<S2SV_ModStart> if ( i >= bufsize ) break ; <S2SV_ModEnd>,0,<S2SV_ModStart> bufsize && ( pg - page < len ) && * pg!= '\0' && * pg!= '\n' ) buf [ i ++ ] = * pg ++ ; if ( i == bufsize ) { ret = - EINVAL ; <S2SV_ModEnd>
195,<S2SV_ModStart> if (! abs_vpay ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /*
	 * make sure that nobody messed with @iocg. Check iocg->pd.online
	 * to avoid warn when removing blkcg or disk.
	 */ WARN_ON_ONCE ( list_empty ( & iocg -> active_list ) && iocg -> pd. online ) ; <S2SV_ModEnd>"
196,<S2SV_ModStart> if (! abs_vpay ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /*
	 * make sure that nobody messed with @iocg. Check iocg->pd.online
	 * to avoid warn when removing blkcg or disk.
	 */ WARN_ON_ONCE ( list_empty ( & iocg -> active_list ) && iocg -> pd. online ) ; <S2SV_ModEnd>"
197,<S2SV_ModStart> if (! iocg -> abs_vdebt ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /*
	 * make sure that nobody messed with @iocg. Check iocg->pd.online
	 * to avoid warn when removing blkcg or disk.
	 */ WARN_ON_ONCE ( list_empty ( & iocg -> active_list ) && iocg -> pd. online ) ; <S2SV_ModEnd>"
198,"<S2SV_ModStart> min ( abs_vpay, iocg -> abs_vdebt ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /*
	 * make sure that nobody messed with @iocg. Check iocg->pd.online
	 * to avoid warn when removing blkcg or disk.
	 */ WARN_ON_ONCE ( list_empty ( & iocg -> active_list ) && iocg -> pd. online ) ; <S2SV_ModEnd>"
199,<S2SV_ModStart> if (! iocg -> abs_vdebt ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /*
	 * make sure that nobody messed with @iocg. Check iocg->pd.online
	 * to avoid warn when removing blkcg or disk.
	 */ WARN_ON_ONCE ( list_empty ( & iocg -> active_list ) && iocg -> pd. online ) ; <S2SV_ModEnd>"
200,<S2SV_ModStart> if (! dir ) { return - ENOENT ; } <S2SV_ModEnd>,0,<S2SV_ModStart> dput ( dir ) ; <S2SV_ModEnd>
201,"<S2SV_ModStart> snprintf ( unit, sizeof ( unit ), "" "", dd -> unit ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> dput ( dir ) ; <S2SV_ModEnd>
202,<S2SV_ModStart> kfree ( dir ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> dput ( dir ) ; <S2SV_ModEnd>
203,"<S2SV_ModStart> snprintf ( unit, sizeof ( unit ), ""%u"", dd -> unit ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> dput ( dir ) ; <S2SV_ModEnd>
204,<S2SV_ModStart> if (! dir ) { return 0 ; } <S2SV_ModEnd>,0,<S2SV_ModStart> dput ( dir ) ; <S2SV_ModEnd>
205,<S2SV_ModStart> if ( neigh == NULL ) { return - ENOENT ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> out_rt ; neigh = dst_neigh_lookup ( & rt -> dst, & fl4. daddr ) ; if (! neigh ) goto out_rt ; memcpy ( nexthop_mac, neigh -> ha, ETH_ALEN ) ; * uses_gateway = rt -> rt_uses_gateway ; neigh_release ( neigh ) ; ip_rt_put ( rt ) ; return 0 ; out_rt : ip_rt_put ( rt ) ; <S2SV_ModEnd>"
206,<S2SV_ModStart> if (! neigh ) { return - ENOENT ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> out_rt ; neigh = dst_neigh_lookup ( & rt -> dst, & fl4. daddr ) ; if (! neigh ) goto out_rt ; memcpy ( nexthop_mac, neigh -> ha, ETH_ALEN ) ; * uses_gateway = rt -> rt_uses_gateway ; neigh_release ( neigh ) ; ip_rt_put ( rt ) ; return 0 ; out_rt : ip_rt_put ( rt ) ; <S2SV_ModEnd>"
207,<S2SV_ModStart> if (! neigh ) goto out ; <S2SV_ModEnd>,0,"<S2SV_ModStart> out_rt ; neigh = dst_neigh_lookup ( & rt -> dst, & fl4. daddr ) ; if (! neigh ) goto out_rt ; memcpy ( nexthop_mac, neigh -> ha, ETH_ALEN ) ; * uses_gateway = rt -> rt_uses_gateway ; neigh_release ( neigh ) ; ip_rt_put ( rt ) ; return 0 ; out_rt : ip_rt_put ( rt ) ; <S2SV_ModEnd>"
208,<S2SV_ModStart> if ( neigh == NULL ) goto out ; <S2SV_ModEnd>,0,"<S2SV_ModStart> out_rt ; neigh = dst_neigh_lookup ( & rt -> dst, & fl4. daddr ) ; if (! neigh ) goto out_rt ; memcpy ( nexthop_mac, neigh -> ha, ETH_ALEN ) ; * uses_gateway = rt -> rt_uses_gateway ; neigh_release ( neigh ) ; ip_rt_put ( rt ) ; return 0 ; out_rt : ip_rt_put ( rt ) ; <S2SV_ModEnd>"
209,<S2SV_ModStart> if (! neigh ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> out_rt ; neigh = dst_neigh_lookup ( & rt -> dst, & fl4. daddr ) ; if (! neigh ) goto out_rt ; memcpy ( nexthop_mac, neigh -> ha, ETH_ALEN ) ; * uses_gateway = rt -> rt_uses_gateway ; neigh_release ( neigh ) ; ip_rt_put ( rt ) ; return 0 ; out_rt : ip_rt_put ( rt ) ; <S2SV_ModEnd>"
210,<S2SV_ModStart> if (! is_swap_pte ( ptent ) ) { ptent = pte_swp_mkuffd_wp ( ptent ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> old_pte ) ; <S2SV_ModEnd>
211,<S2SV_ModStart> if (! pte_present ( ptent ) ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> old_pte ) ; <S2SV_ModEnd>
212,<S2SV_ModStart> if (! ptent ) { BUG ( ) ; } <S2SV_ModEnd>,0,<S2SV_ModStart> old_pte ) ; <S2SV_ModEnd>
213,<S2SV_ModStart> if (! ptent ) { kfree ( old_pte ) ; } <S2SV_ModEnd>,0,<S2SV_ModStart> old_pte ) ; <S2SV_ModEnd>
214,<S2SV_ModStart> if (! is_swap_pte ( ptent ) ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> old_pte ) ; <S2SV_ModEnd>
215,<S2SV_ModStart> ( unsigned long ) vma -> vm_flags & __VM_UFFD_FLAGS ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Reset ptes for the whole vma range if wr-protected */ if ( userfaultfd_wp ( vma ) ) uffd_wp_range ( vma, vma -> vm_start, vma -> vm_end - vma -> vm_start, false ) ; <S2SV_ModEnd>"
216,<S2SV_ModStart> ( unsigned long ) vma -> vm_flags & ~ __VM_UFFD_FLAGS ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Reset ptes for the whole vma range if wr-protected */ if ( userfaultfd_wp ( vma ) ) uffd_wp_range ( vma, vma -> vm_start, vma -> vm_end - vma -> vm_start, false ) ; <S2SV_ModEnd>"
217,<S2SV_ModStart> && vma -> vm_flags & __VM_UFFD_FLAGS ) { continue ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Reset ptes for the whole vma range if wr-protected */ if ( userfaultfd_wp ( vma ) ) uffd_wp_range ( vma, vma -> vm_start, vma -> vm_end - vma -> vm_start, false ) ; <S2SV_ModEnd>"
218,<S2SV_ModStart> ( unsigned long ) vma -> vm_flags & __VM_UFFD_FLAGS ) { new_flags = 0 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Reset ptes for the whole vma range if wr-protected */ if ( userfaultfd_wp ( vma ) ) uffd_wp_range ( vma, vma -> vm_start, vma -> vm_end - vma -> vm_start, false ) ; <S2SV_ModEnd>"
219,<S2SV_ModStart> ( unsigned long ) vma -> vm_flags & __VM_UFFD_FLAGS ) ) { continue ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Reset ptes for the whole vma range if wr-protected */ if ( userfaultfd_wp ( vma ) ) uffd_wp_range ( vma, vma -> vm_start, vma -> vm_end - vma -> vm_start, false ) ; <S2SV_ModEnd>"
220,<S2SV_ModStart> if (! inode -> i_data ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! is_bad_inode ( inode ) ) { truncate_inode_pages_final ( & inode -> i_data ) ; version = cpu_to_le32 ( v9inode -> qid. version ) ; netfs_clear_inode_writeback ( inode, & version ) ; clear_inode ( inode ) ; filemap_fdatawrite ( & inode -> i_data ) ; # ifdef CONFIG_9P_FSCACHE if ( v9fs_inode_cookie ( v9inode ) ) fscache_relinquish_cookie ( v9fs_inode_cookie ( v9inode ), false ) ; # endif } else clear_inode ( inode ) ; } <S2SV_ModEnd>"
221,<S2SV_ModStart> if ( inode -> i_data. size == 0 ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! is_bad_inode ( inode ) ) { truncate_inode_pages_final ( & inode -> i_data ) ; version = cpu_to_le32 ( v9inode -> qid. version ) ; netfs_clear_inode_writeback ( inode, & version ) ; clear_inode ( inode ) ; filemap_fdatawrite ( & inode -> i_data ) ; # ifdef CONFIG_9P_FSCACHE if ( v9fs_inode_cookie ( v9inode ) ) fscache_relinquish_cookie ( v9fs_inode_cookie ( v9inode ), false ) ; # endif } else clear_inode ( inode ) ; } <S2SV_ModEnd>"
222,<S2SV_ModStart> if (! inode -> i_data ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! is_bad_inode ( inode ) ) { truncate_inode_pages_final ( & inode -> i_data ) ; version = cpu_to_le32 ( v9inode -> qid. version ) ; netfs_clear_inode_writeback ( inode, & version ) ; clear_inode ( inode ) ; filemap_fdatawrite ( & inode -> i_data ) ; # ifdef CONFIG_9P_FSCACHE if ( v9fs_inode_cookie ( v9inode ) ) fscache_relinquish_cookie ( v9fs_inode_cookie ( v9inode ), false ) ; # endif } else clear_inode ( inode ) ; } <S2SV_ModEnd>"
223,<S2SV_ModStart> if (! inode -> i_data. size ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! is_bad_inode ( inode ) ) { truncate_inode_pages_final ( & inode -> i_data ) ; version = cpu_to_le32 ( v9inode -> qid. version ) ; netfs_clear_inode_writeback ( inode, & version ) ; clear_inode ( inode ) ; filemap_fdatawrite ( & inode -> i_data ) ; # ifdef CONFIG_9P_FSCACHE if ( v9fs_inode_cookie ( v9inode ) ) fscache_relinquish_cookie ( v9fs_inode_cookie ( v9inode ), false ) ; # endif } else clear_inode ( inode ) ; } <S2SV_ModEnd>"
224,<S2SV_ModStart> if (! inode -> i_data. size ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if (! is_bad_inode ( inode ) ) { truncate_inode_pages_final ( & inode -> i_data ) ; version = cpu_to_le32 ( v9inode -> qid. version ) ; netfs_clear_inode_writeback ( inode, & version ) ; clear_inode ( inode ) ; filemap_fdatawrite ( & inode -> i_data ) ; # ifdef CONFIG_9P_FSCACHE if ( v9fs_inode_cookie ( v9inode ) ) fscache_relinquish_cookie ( v9fs_inode_cookie ( v9inode ), false ) ; # endif } else clear_inode ( inode ) ; } <S2SV_ModEnd>"
225,<S2SV_ModStart> if ( shared_args_p -> header. status_flags & VM_FRAME_CTX_SHARED_NON_ARROW_FUNC ) { ret_value = ecma_raise_type_error ( ECMA_ERR_CLASS_CONSTRUCTOR_REQUIRES_NEW ) ; <S2SV_ModEnd>,0,ECMA_CHECK_STACK_USAGE ( ) ; <S2SV_ModEnd>
226,<S2SV_ModStart> if ( shared_args_p -> header. status_flags & VM_FRAME_CTX_SHARED_NON_ARROW_FUNC ) { ret_value = ecma_raise_type_error ( ECMA_ERR_INVALID_PARAMETER ) ; <S2SV_ModEnd>,0,ECMA_CHECK_STACK_USAGE ( ) ; <S2SV_ModEnd>
227,<S2SV_ModStart> if ( JERRY_CONTEXT ( shared_args_p -> header. status_flags & VM_FRAME_CTX_SHARED_NON_ARROW_FUNC ) ) { ret_value = ecma_raise_type_error ( ECMA_ERR_INVALID_PARAMETER ) ; <S2SV_ModEnd>,0,ECMA_CHECK_STACK_USAGE ( ) ; <S2SV_ModEnd>
228,<S2SV_ModStart> if ( shared_args_p -> header. status_flags & VM_FRAME_CTX_SHARED_NON_ARROW_FUNC ) { return ecma_raise_type_error ( ECMA_ERR_INVALID_PARAMETER ) ; <S2SV_ModEnd>,0,ECMA_CHECK_STACK_USAGE ( ) ; <S2SV_ModEnd>
229,<S2SV_ModStart> if ( shared_args_p -> header. status_flags & VM_FRAME_CTX_SHARED_NON_ARROW_FUNC ) { return ecma_raise_type_error ( ECMA_ERR_INVALID_PARAMETER ) ; } <S2SV_ModEnd>,0,ECMA_CHECK_STACK_USAGE ( ) ; <S2SV_ModEnd>
230,<S2SV_ModStart> if ( skb == NULL ) { return NULL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl4 -> flowi4_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp_type = fl4 -> fl4_icmp_type ; <S2SV_ModEnd>
231,<S2SV_ModStart> if (! skb_shinfo ( skb ) -> frag_list ) goto out ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl4 -> flowi4_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp_type = fl4 -> fl4_icmp_type ; <S2SV_ModEnd>
232,<S2SV_ModStart> if (! skb_shinfo ( skb ) -> frag_list ) break ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl4 -> flowi4_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp_type = fl4 -> fl4_icmp_type ; <S2SV_ModEnd>
233,<S2SV_ModStart> if ( unlikely ( skb == NULL ) ) { return NULL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl4 -> flowi4_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp_type = fl4 -> fl4_icmp_type ; <S2SV_ModEnd>
234,<S2SV_ModStart> if (! skb -> next ) { return NULL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl4 -> flowi4_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp_type = fl4 -> fl4_icmp_type ; <S2SV_ModEnd>
235,"<S2SV_ModStart> if ( unlikely (! idev -> cnf. disable_ipv6 ) ) { return NF_HOOK_COND ( NFPROTO_IPV6, NF_INET_POST_ROUTING, net, sk, sk, skb, indev, ip6_finish_output,! ( IP6CB ( skb ) -> flags & IP6SKB_REROUTED ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>! idev || READ_ONCE ( idev -> cnf. disable_ipv6 ) ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>"
236,"<S2SV_ModStart> if ( unlikely (! idev -> cnf. disable_ipv6 ) ) { return NF_HOOK_COND ( NFPROTO_IPV6, NF_INET_PRE_ROUTING, net, sk, sk, skb, indev, ip6_finish_output,! ( IP6CB ( skb ) -> flags & IP6SKB_REROUTED ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>! idev || READ_ONCE ( idev -> cnf. disable_ipv6 ) ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>"
237,"<S2SV_ModStart> if ( unlikely (! idev ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>! idev || READ_ONCE ( idev -> cnf. disable_ipv6 ) ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>"
238,"<S2SV_ModStart> if ( unlikely (! idev || idev -> cnf. disable_ipv6 ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>! idev || READ_ONCE ( idev -> cnf. disable_ipv6 ) ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>"
239,"<S2SV_ModStart> if ( unlikely ( idev &&! idev -> cnf. disable_ipv6 ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart>! idev || READ_ONCE ( idev -> cnf. disable_ipv6 ) ) ) { IP6_INC_STATS ( net, idev, IPSTATS_MIB_OUTDISCARDS ) ; <S2SV_ModEnd>"
240,<S2SV_ModStart> if (! ctx -> internal -> hw_type -> frames_init ) return AVERROR ( ENOSYS ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> return ret ; } if ( ctx -> internal -> pool_internal &&! ctx -> pool ) ctx -> pool = ctx -> internal -> pool_internal ; /* preallocate the frames in the pool, if requested */ if ( ctx -> initial_pool_size > 0 ) { ret = hwframe_pool_prealloc ( ref ) ; if ( ret < 0 ) return ret ; } return 0 ; } int av_hwframe_transfer_get_formats ( AVBufferRef * hwframe_ref, enum AVHWFrameTransferDirection dir, enum AVPixelFormat * * formats, int flags ) { AVHWFramesContext * ctx = ( AVHWFramesContext * ) hwframe_ref -> data ; if (! ctx -> internal -> hw_type -> transfer_get_formats ) return AVERROR ( ENOSYS ) ; return ctx -> internal -> hw_type -> transfer_get_formats ( ctx, dir, formats ) ; <S2SV_ModEnd>"
241,<S2SV_ModStart> if (! ctx -> internal -> hw_type -> pix_fmts ) { return AVERROR ( EINVAL ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> return ret ; } if ( ctx -> internal -> pool_internal &&! ctx -> pool ) ctx -> pool = ctx -> internal -> pool_internal ; /* preallocate the frames in the pool, if requested */ if ( ctx -> initial_pool_size > 0 ) { ret = hwframe_pool_prealloc ( ref ) ; if ( ret < 0 ) return ret ; } return 0 ; } int av_hwframe_transfer_get_formats ( AVBufferRef * hwframe_ref, enum AVHWFrameTransferDirection dir, enum AVPixelFormat * * formats, int flags ) { AVHWFramesContext * ctx = ( AVHWFramesContext * ) hwframe_ref -> data ; if (! ctx -> internal -> hw_type -> transfer_get_formats ) return AVERROR ( ENOSYS ) ; return ctx -> internal -> hw_type -> transfer_get_formats ( ctx, dir, formats ) ; <S2SV_ModEnd>"
242,<S2SV_ModStart> if (! ctx -> internal -> hw_type -> pix_fmts ) return AVERROR ( EINVAL ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> return ret ; } if ( ctx -> internal -> pool_internal &&! ctx -> pool ) ctx -> pool = ctx -> internal -> pool_internal ; /* preallocate the frames in the pool, if requested */ if ( ctx -> initial_pool_size > 0 ) { ret = hwframe_pool_prealloc ( ref ) ; if ( ret < 0 ) return ret ; } return 0 ; } int av_hwframe_transfer_get_formats ( AVBufferRef * hwframe_ref, enum AVHWFrameTransferDirection dir, enum AVPixelFormat * * formats, int flags ) { AVHWFramesContext * ctx = ( AVHWFramesContext * ) hwframe_ref -> data ; if (! ctx -> internal -> hw_type -> transfer_get_formats ) return AVERROR ( ENOSYS ) ; return ctx -> internal -> hw_type -> transfer_get_formats ( ctx, dir, formats ) ; <S2SV_ModEnd>"
243,<S2SV_ModStart> if (! ctx -> internal -> hw_type -> frames_init ) return AVERROR ( EINVAL ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> return ret ; } if ( ctx -> internal -> pool_internal &&! ctx -> pool ) ctx -> pool = ctx -> internal -> pool_internal ; /* preallocate the frames in the pool, if requested */ if ( ctx -> initial_pool_size > 0 ) { ret = hwframe_pool_prealloc ( ref ) ; if ( ret < 0 ) return ret ; } return 0 ; } int av_hwframe_transfer_get_formats ( AVBufferRef * hwframe_ref, enum AVHWFrameTransferDirection dir, enum AVPixelFormat * * formats, int flags ) { AVHWFramesContext * ctx = ( AVHWFramesContext * ) hwframe_ref -> data ; if (! ctx -> internal -> hw_type -> transfer_get_formats ) return AVERROR ( ENOSYS ) ; return ctx -> internal -> hw_type -> transfer_get_formats ( ctx, dir, formats ) ; <S2SV_ModEnd>"
244,<S2SV_ModStart> if (! ctx -> internal -> hw_type -> frames_init ) { return AVERROR ( ENOSYS ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> return ret ; } if ( ctx -> internal -> pool_internal &&! ctx -> pool ) ctx -> pool = ctx -> internal -> pool_internal ; /* preallocate the frames in the pool, if requested */ if ( ctx -> initial_pool_size > 0 ) { ret = hwframe_pool_prealloc ( ref ) ; if ( ret < 0 ) return ret ; } return 0 ; } int av_hwframe_transfer_get_formats ( AVBufferRef * hwframe_ref, enum AVHWFrameTransferDirection dir, enum AVPixelFormat * * formats, int flags ) { AVHWFramesContext * ctx = ( AVHWFramesContext * ) hwframe_ref -> data ; if (! ctx -> internal -> hw_type -> transfer_get_formats ) return AVERROR ( ENOSYS ) ; return ctx -> internal -> hw_type -> transfer_get_formats ( ctx, dir, formats ) ; <S2SV_ModEnd>"
245,<S2SV_ModStart> if (! quirk_mask ) return false ; <S2SV_ModEnd>,0,<S2SV_ModStart> fwnode_handle_put ( link ) ; <S2SV_ModEnd>
246,<S2SV_ModStart> if ( quirk_mask == 0 ) { return false ; } <S2SV_ModEnd>,0,<S2SV_ModStart> fwnode_handle_put ( link ) ; <S2SV_ModEnd>
247,<S2SV_ModStart> if ( quirk_mask == 0 ) return false ; <S2SV_ModEnd>,0,<S2SV_ModStart> fwnode_handle_put ( link ) ; <S2SV_ModEnd>
248,<S2SV_ModStart> if ( quirk_mask == 0 ) { return true ; } <S2SV_ModEnd>,0,<S2SV_ModStart> fwnode_handle_put ( link ) ; <S2SV_ModEnd>
249,<S2SV_ModStart> if ( quirk_mask == 0 ) return true ; <S2SV_ModEnd>,0,<S2SV_ModStart> fwnode_handle_put ( link ) ; <S2SV_ModEnd>
250,"<S2SV_ModStart> unsigned int rc = test_run ( home, ""23-http09-multiple.t"", cfg, & connp ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> <S2SV_ModEnd>
251,"<S2SV_ModStart> unsigned int rc = test_run ( home, ""23-http09.t"", cfg, & connp ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> <S2SV_ModEnd>
252,<S2SV_ModStart> if ( connp == NULL ) { return rc ; } <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
253,<S2SV_ModStart> if ( connp == NULL ) { return 0 ; } <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
254,<S2SV_ModStart> if ( connp == NULL ) { return ( 0 ) ; } <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
255,<S2SV_ModStart> if ( buffer == NULL ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, lbuf ) ; <S2SV_ModEnd>"
256,<S2SV_ModStart> if (! lbuf ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, lbuf ) ; <S2SV_ModEnd>"
257,<S2SV_ModStart> if (! buffer ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, lbuf ) ; <S2SV_ModEnd>"
258,<S2SV_ModStart> if (! buffer ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, lbuf ) ; <S2SV_ModEnd>"
259,<S2SV_ModStart> if ( unlikely ( buffer == NULL ) ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, lbuf ) ; <S2SV_ModEnd>"
260,<S2SV_ModStart> if (! n ) return NULL ; <S2SV_ModEnd>,0,"int head_copy_len, head_copy_off ; struct sk_buff * n ; int oldheadroom ; if ( WARN_ON_ONCE ( skb_shinfo ( skb ) -> gso_type & SKB_GSO_FRAGLIST ) ) return NULL ; oldheadroom = skb_headroom ( skb ) ; n = __alloc_skb ( newheadroom + skb -> len + newtailroom, gfp_mask, skb_alloc_rx_flag ( skb ), NUMA_NO_NODE ) ; <S2SV_ModEnd>"
261,<extra_id_0>int oldheadroom = skb_headroom ( skb ) ; <S2SV_ModEnd>,0,"int head_copy_len, head_copy_off ; struct sk_buff * n ; int oldheadroom ; if ( WARN_ON_ONCE ( skb_shinfo ( skb ) -> gso_type & SKB_GSO_FRAGLIST ) ) return NULL ; oldheadroom = skb_headroom ( skb ) ; n = __alloc_skb ( newheadroom + skb -> len + newtailroom, gfp_mask, skb_alloc_rx_flag ( skb ), NUMA_NO_NODE ) ; <S2SV_ModEnd>"
262,<S2SV_ModStart> if (! skb ) return NULL ; <S2SV_ModEnd>,0,"int head_copy_len, head_copy_off ; struct sk_buff * n ; int oldheadroom ; if ( WARN_ON_ONCE ( skb_shinfo ( skb ) -> gso_type & SKB_GSO_FRAGLIST ) ) return NULL ; oldheadroom = skb_headroom ( skb ) ; n = __alloc_skb ( newheadroom + skb -> len + newtailroom, gfp_mask, skb_alloc_rx_flag ( skb ), NUMA_NO_NODE ) ; <S2SV_ModEnd>"
263,"<S2SV_ModStart> unsigned int oldheadroom, head_copy_off ; <S2SV_ModEnd>",0,"int head_copy_len, head_copy_off ; struct sk_buff * n ; int oldheadroom ; if ( WARN_ON_ONCE ( skb_shinfo ( skb ) -> gso_type & SKB_GSO_FRAGLIST ) ) return NULL ; oldheadroom = skb_headroom ( skb ) ; n = __alloc_skb ( newheadroom + skb -> len + newtailroom, gfp_mask, skb_alloc_rx_flag ( skb ), NUMA_NO_NODE ) ; <S2SV_ModEnd>"
264,<S2SV_ModStart> if ( newheadroom < 0 ) return NULL ; <S2SV_ModEnd>,0,"int head_copy_len, head_copy_off ; struct sk_buff * n ; int oldheadroom ; if ( WARN_ON_ONCE ( skb_shinfo ( skb ) -> gso_type & SKB_GSO_FRAGLIST ) ) return NULL ; oldheadroom = skb_headroom ( skb ) ; n = __alloc_skb ( newheadroom + skb -> len + newtailroom, gfp_mask, skb_alloc_rx_flag ( skb ), NUMA_NO_NODE ) ; <S2SV_ModEnd>"
265,<S2SV_ModStart> if (! frag ) goto err ; <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb_has_frag_list ( frag ) && __skb_linearize ( frag ) ) goto err ; * buf = NULL ; <S2SV_ModEnd>
266,<S2SV_ModStart>! skb_has_frag_list ( frag ) ) goto err ; <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb_has_frag_list ( frag ) && __skb_linearize ( frag ) ) goto err ; * buf = NULL ; <S2SV_ModEnd>
267,<S2SV_ModStart> &&! skb_has_frag_list ( frag ) ) goto err ; <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb_has_frag_list ( frag ) && __skb_linearize ( frag ) ) goto err ; * buf = NULL ; <S2SV_ModEnd>
268,<S2SV_ModStart> if ( frag == NULL ) goto err ; <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb_has_frag_list ( frag ) && __skb_linearize ( frag ) ) goto err ; * buf = NULL ; <S2SV_ModEnd>
269,<S2SV_ModStart> if (! frag ) return 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> if ( skb_has_frag_list ( frag ) && __skb_linearize ( frag ) ) goto err ; * buf = NULL ; <S2SV_ModEnd>
270,<S2SV_ModStart> if (! vmbus_connection. int_page ) { ret = - ENOMEM ; goto cleanup ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> { /*
		 * If set_memory_decrypted() fails, the encryption state
		 * of the memory is unknown. So leak the memory instead
		 * of risking returning decrypted memory to the free list.
		 * For simplicity, always handle both pages the same.
		 */ vmbus_connection. monitor_pages [ 0 ] = NULL ; vmbus_connection. monitor_pages [ 1 ] = NULL ; goto cleanup ; } <S2SV_ModEnd>"
271,"<S2SV_ModStart> kzalloc ( sizeof ( struct vmbus_channel_msginfo ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> { /*
		 * If set_memory_decrypted() fails, the encryption state
		 * of the memory is unknown. So leak the memory instead
		 * of risking returning decrypted memory to the free list.
		 * For simplicity, always handle both pages the same.
		 */ vmbus_connection. monitor_pages [ 0 ] = NULL ; vmbus_connection. monitor_pages [ 1 ] = NULL ; goto cleanup ; } <S2SV_ModEnd>"
272,<S2SV_ModStart> unsigned long ) ( unsigned long ) vmbus_connection. recv_int_page ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { /*
		 * If set_memory_decrypted() fails, the encryption state
		 * of the memory is unknown. So leak the memory instead
		 * of risking returning decrypted memory to the free list.
		 * For simplicity, always handle both pages the same.
		 */ vmbus_connection. monitor_pages [ 0 ] = NULL ; vmbus_connection. monitor_pages [ 1 ] = NULL ; goto cleanup ; } <S2SV_ModEnd>"
273,<S2SV_ModStart> unsigned long ) ( unsigned long ) vmbus_connection. int_page ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { /*
		 * If set_memory_decrypted() fails, the encryption state
		 * of the memory is unknown. So leak the memory instead
		 * of risking returning decrypted memory to the free list.
		 * For simplicity, always handle both pages the same.
		 */ vmbus_connection. monitor_pages [ 0 ] = NULL ; vmbus_connection. monitor_pages [ 1 ] = NULL ; goto cleanup ; } <S2SV_ModEnd>"
274,<S2SV_ModStart> unsigned long ) vmbus_connection. int_page ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { /*
		 * If set_memory_decrypted() fails, the encryption state
		 * of the memory is unknown. So leak the memory instead
		 * of risking returning decrypted memory to the free list.
		 * For simplicity, always handle both pages the same.
		 */ vmbus_connection. monitor_pages [ 0 ] = NULL ; vmbus_connection. monitor_pages [ 1 ] = NULL ; goto cleanup ; } <S2SV_ModEnd>"
275,<S2SV_ModStart> if ( count < 0 ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buffer, count ) ; if ( IS_ERR ( cmd_buf ) ) return - ENOMEM ; <S2SV_ModEnd>"
276,<S2SV_ModStart> if ( count < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buffer, count ) ; if ( IS_ERR ( cmd_buf ) ) return - ENOMEM ; <S2SV_ModEnd>"
277,<S2SV_ModStart> if (! count ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buffer, count ) ; if ( IS_ERR ( cmd_buf ) ) return - ENOMEM ; <S2SV_ModEnd>"
278,<S2SV_ModStart> if ( count < 0 ) return PTR_ERR ( cmd_buf ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buffer, count ) ; if ( IS_ERR ( cmd_buf ) ) return - ENOMEM ; <S2SV_ModEnd>"
279,<S2SV_ModStart> if ( count < 0 ) { return PTR_ERR ( cmd_buf ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buffer, count ) ; if ( IS_ERR ( cmd_buf ) ) return - ENOMEM ; <S2SV_ModEnd>"
280,"<S2SV_ModStart> unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; <S2SV_ModEnd>",0,"u64 eflags ; int ret ; u64 active_edflags = READ_ONCE ( line -> edflags ) ; unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; if ( ( active_edflags == edflags ) && ( READ_ONCE ( line -> debounce_period_us ) == debounce_period_us ) ) return 0 ; /* sw debounced and still will be...*/ if ( debounce_period_us && READ_ONCE ( line -> sw_debounced ) ) { line_set_debounce_period ( line, debounce_period_us ) ; /*
		 * ensure event fifo is initialised if edge detection
		 * is now enabled.
		 */ eflags = edflags & GPIO_V2_LINE_EDGE_FLAGS ; if ( eflags &&! kfifo_initialized ( & line -> req -> events ) ) { ret = kfifo_alloc ( & line -> req -> events, line -> req -> event_buffer_size, GFP_KERNEL ) ; if ( ret ) return ret ; } <S2SV_ModEnd>"
281,size_t active_edflags = READ_ONCE ( line -> edflags ) ; <S2SV_ModEnd>,0,"u64 eflags ; int ret ; u64 active_edflags = READ_ONCE ( line -> edflags ) ; unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; if ( ( active_edflags == edflags ) && ( READ_ONCE ( line -> debounce_period_us ) == debounce_period_us ) ) return 0 ; /* sw debounced and still will be...*/ if ( debounce_period_us && READ_ONCE ( line -> sw_debounced ) ) { line_set_debounce_period ( line, debounce_period_us ) ; /*
		 * ensure event fifo is initialised if edge detection
		 * is now enabled.
		 */ eflags = edflags & GPIO_V2_LINE_EDGE_FLAGS ; if ( eflags &&! kfifo_initialized ( & line -> req -> events ) ) { ret = kfifo_alloc ( & line -> req -> events, line -> req -> event_buffer_size, GFP_KERNEL ) ; if ( ret ) return ret ; } <S2SV_ModEnd>"
282,"<extra_id_0>unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; <S2SV_ModEnd>",0,"u64 eflags ; int ret ; u64 active_edflags = READ_ONCE ( line -> edflags ) ; unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; if ( ( active_edflags == edflags ) && ( READ_ONCE ( line -> debounce_period_us ) == debounce_period_us ) ) return 0 ; /* sw debounced and still will be...*/ if ( debounce_period_us && READ_ONCE ( line -> sw_debounced ) ) { line_set_debounce_period ( line, debounce_period_us ) ; /*
		 * ensure event fifo is initialised if edge detection
		 * is now enabled.
		 */ eflags = edflags & GPIO_V2_LINE_EDGE_FLAGS ; if ( eflags &&! kfifo_initialized ( & line -> req -> events ) ) { ret = kfifo_alloc ( & line -> req -> events, line -> req -> event_buffer_size, GFP_KERNEL ) ; if ( ret ) return ret ; } <S2SV_ModEnd>"
283,uint32_t active_edflags = READ_ONCE ( line -> edflags ) ; <S2SV_ModEnd>,0,"u64 eflags ; int ret ; u64 active_edflags = READ_ONCE ( line -> edflags ) ; unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; if ( ( active_edflags == edflags ) && ( READ_ONCE ( line -> debounce_period_us ) == debounce_period_us ) ) return 0 ; /* sw debounced and still will be...*/ if ( debounce_period_us && READ_ONCE ( line -> sw_debounced ) ) { line_set_debounce_period ( line, debounce_period_us ) ; /*
		 * ensure event fifo is initialised if edge detection
		 * is now enabled.
		 */ eflags = edflags & GPIO_V2_LINE_EDGE_FLAGS ; if ( eflags &&! kfifo_initialized ( & line -> req -> events ) ) { ret = kfifo_alloc ( & line -> req -> events, line -> req -> event_buffer_size, GFP_KERNEL ) ; if ( ret ) return ret ; } <S2SV_ModEnd>"
284,<S2SV_ModStart> unsigned int debounce_period_us = GPIO_V2_LINE_FLAG_EVENT_CLOCK_HTE ; <S2SV_ModEnd>,0,"u64 eflags ; int ret ; u64 active_edflags = READ_ONCE ( line -> edflags ) ; unsigned int debounce_period_us = gpio_v2_line_config_debounce_period ( lc, line_idx ) ; if ( ( active_edflags == edflags ) && ( READ_ONCE ( line -> debounce_period_us ) == debounce_period_us ) ) return 0 ; /* sw debounced and still will be...*/ if ( debounce_period_us && READ_ONCE ( line -> sw_debounced ) ) { line_set_debounce_period ( line, debounce_period_us ) ; /*
		 * ensure event fifo is initialised if edge detection
		 * is now enabled.
		 */ eflags = edflags & GPIO_V2_LINE_EDGE_FLAGS ; if ( eflags &&! kfifo_initialized ( & line -> req -> events ) ) { ret = kfifo_alloc ( & line -> req -> events, line -> req -> event_buffer_size, GFP_KERNEL ) ; if ( ret ) return ret ; } <S2SV_ModEnd>"
285,<S2SV_ModStart> ( map_ofs < 0 ) || ( map_ofs >= SZ_2M ) ) return - ENOMEM ; <S2SV_ModEnd>,0,"<S2SV_ModStart> u64 ) ( level - 1 ) * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level, u64, entry | flags ) ; } /* Write PDE's that point to our BO. */ for ( i = 0 ; i < num_entries - num_level ; i ++ ) { entry = vm -> pt_ops -> pde_encode_bo ( bo, ( u64 ) i * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE + ( i + 1 ) * 8, u64, entry ) ; } /* Set up a 1GiB NULL mapping at 255GiB offset. */ level = 2 ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level + 255 * 8, u64, vm -> pt_ops -> pte_encode_addr ( xe, 0, pat_index, level, IS_DGFX ("
286,<S2SV_ModStart> ( map_ofs < 0 ) || ( map_ofs >= SZ_2M ) ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> u64 ) ( level - 1 ) * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level, u64, entry | flags ) ; } /* Write PDE's that point to our BO. */ for ( i = 0 ; i < num_entries - num_level ; i ++ ) { entry = vm -> pt_ops -> pde_encode_bo ( bo, ( u64 ) i * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE + ( i + 1 ) * 8, u64, entry ) ; } /* Set up a 1GiB NULL mapping at 255GiB offset. */ level = 2 ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level + 255 * 8, u64, vm -> pt_ops -> pte_encode_addr ( xe, 0, pat_index, level, IS_DGFX ("
287,<S2SV_ModStart> ( map_ofs < 0 ) || ( map_ofs >= SZ_4K ) ) return - ENOMEM ; <S2SV_ModEnd>,0,"<S2SV_ModStart> u64 ) ( level - 1 ) * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level, u64, entry | flags ) ; } /* Write PDE's that point to our BO. */ for ( i = 0 ; i < num_entries - num_level ; i ++ ) { entry = vm -> pt_ops -> pde_encode_bo ( bo, ( u64 ) i * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE + ( i + 1 ) * 8, u64, entry ) ; } /* Set up a 1GiB NULL mapping at 255GiB offset. */ level = 2 ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level + 255 * 8, u64, vm -> pt_ops -> pte_encode_addr ( xe, 0, pat_index, level, IS_DGFX ("
288,"<S2SV_ModStart> memset ( batch, 0, SZ_4K ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> u64 ) ( level - 1 ) * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level, u64, entry | flags ) ; } /* Write PDE's that point to our BO. */ for ( i = 0 ; i < num_entries - num_level ; i ++ ) { entry = vm -> pt_ops -> pde_encode_bo ( bo, ( u64 ) i * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE + ( i + 1 ) * 8, u64, entry ) ; } /* Set up a 1GiB NULL mapping at 255GiB offset. */ level = 2 ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level + 255 * 8, u64, vm -> pt_ops -> pte_encode_addr ( xe, 0, pat_index, level, IS_DGFX ("
289,<S2SV_ModStart> ( map_ofs < 0 ) || ( map_ofs >= SZ_2M / XE_PAGE_SIZE ) ) ) return - ENOMEM ; <S2SV_ModEnd>,0,"<S2SV_ModStart> u64 ) ( level - 1 ) * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level, u64, entry | flags ) ; } /* Write PDE's that point to our BO. */ for ( i = 0 ; i < num_entries - num_level ; i ++ ) { entry = vm -> pt_ops -> pde_encode_bo ( bo, ( u64 ) i * XE_PAGE_SIZE, pat_index ) ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE + ( i + 1 ) * 8, u64, entry ) ; } /* Set up a 1GiB NULL mapping at 255GiB offset. */ level = 2 ; xe_map_wr ( xe, & bo -> vmap, map_ofs + XE_PAGE_SIZE * level + 255 * 8, u64, vm -> pt_ops -> pte_encode_addr ( xe, 0, pat_index, level, IS_DGFX ("
290,"<S2SV_ModStart> ( source_id == SOC15_INTSRC_SQ_INTERRUPT_MSG ) || source_id == SOC15_INTSRC_CP_END_OF_PIPE ) kfd_signal_event_interrupt ( pasid, context_id0, 32 ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && KFD_DBG_EC_TYPE_IS_PACKET ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ) ) { kfd_set_dbg_ev_from_interrupt ( dev, pasid, KFD_DEBUG_DOORBELL_ID ( context_id0 ), KFD_EC_MASK ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ), NULL, 0 ) ; <S2SV_ModEnd>"
291,"<S2SV_ModStart> if ( source_id == SOC15_INTSRC_SQ_INTERRUPT_MSG ) kfd_signal_event_interrupt ( pasid, context_id0, 32 ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && KFD_DBG_EC_TYPE_IS_PACKET ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ) ) { kfd_set_dbg_ev_from_interrupt ( dev, pasid, KFD_DEBUG_DOORBELL_ID ( context_id0 ), KFD_EC_MASK ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ), NULL, 0 ) ; <S2SV_ModEnd>"
292,"<S2SV_ModStart> ( source_id == SOC15_INTSRC_SQ_INTERRUPT_MSG ) ) kfd_signal_event_interrupt ( pasid, context_id0, 32 ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && KFD_DBG_EC_TYPE_IS_PACKET ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ) ) { kfd_set_dbg_ev_from_interrupt ( dev, pasid, KFD_DEBUG_DOORBELL_ID ( context_id0 ), KFD_EC_MASK ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ), NULL, 0 ) ; <S2SV_ModEnd>"
293,"<S2SV_ModStart> ( context_id0 == 0 ) || ( context_id1 == 0 ) ) kfd_signal_event_interrupt ( pasid, context_id0, 32 ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && KFD_DBG_EC_TYPE_IS_PACKET ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ) ) { kfd_set_dbg_ev_from_interrupt ( dev, pasid, KFD_DEBUG_DOORBELL_ID ( context_id0 ), KFD_EC_MASK ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ), NULL, 0 ) ; <S2SV_ModEnd>"
294,"<S2SV_ModStart> ( source_id == SOC15_INTSRC_SQ_INTERRUPT_MSG ) || source_id == SOC15_INTSRC_CP_END_OF_PIPE ) kfd_signal_event_interrupt ( pasid, context_id1, 32 ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> && KFD_DBG_EC_TYPE_IS_PACKET ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ) ) { kfd_set_dbg_ev_from_interrupt ( dev, pasid, KFD_DEBUG_DOORBELL_ID ( context_id0 ), KFD_EC_MASK ( KFD_DEBUG_CP_BAD_OP_ECODE ( context_id0 ) ), NULL, 0 ) ; <S2SV_ModEnd>"
295,<S2SV_ModStart> le16_to_cpu ( ev -> bis [ i ] ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! bis ) continue ; <S2SV_ModEnd>
296,"<S2SV_ModStart> memset ( bis, 0, sizeof ( bis ) ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> if (! bis ) continue ; <S2SV_ModEnd>
297,<S2SV_ModStart> le16_to_cpu ( ev -> bis [ 0 ] ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> if (! bis ) continue ; <S2SV_ModEnd>
298,"<S2SV_ModStart> memset ( bis, 0, sizeof ( * bis ) ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> if (! bis ) continue ; <S2SV_ModEnd>
299,<S2SV_ModStart> if (! bis ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> if (! bis ) continue ; <S2SV_ModEnd>
300,<S2SV_ModStart> if (! kfd -> nodes ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; if (! kfd -> init_complete ) return ; /* for runtime suspend, skip locking kfd */ if (! run_pm ) { mutex_lock ( & kfd_processes_mutex ) ; /* For first KFD device suspend all the KFD processes */ if ( ++ kfd_locked == 1 ) kfd_suspend_all_processes ( ) ; mutex_unlock ( & kfd_processes_mutex ) ; <S2SV_ModEnd>"
301,<S2SV_ModStart> if ( count < 0 ) { return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; if (! kfd -> init_complete ) return ; /* for runtime suspend, skip locking kfd */ if (! run_pm ) { mutex_lock ( & kfd_processes_mutex ) ; /* For first KFD device suspend all the KFD processes */ if ( ++ kfd_locked == 1 ) kfd_suspend_all_processes ( ) ; mutex_unlock ( & kfd_processes_mutex ) ; <S2SV_ModEnd>"
302,<S2SV_ModStart> if ( count == 0 ) { return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; if (! kfd -> init_complete ) return ; /* for runtime suspend, skip locking kfd */ if (! run_pm ) { mutex_lock ( & kfd_processes_mutex ) ; /* For first KFD device suspend all the KFD processes */ if ( ++ kfd_locked == 1 ) kfd_suspend_all_processes ( ) ; mutex_unlock ( & kfd_processes_mutex ) ; <S2SV_ModEnd>"
303,<S2SV_ModStart> if ( count == 0 ) kgd2kfd_suspend_all_processes ( ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; if (! kfd -> init_complete ) return ; /* for runtime suspend, skip locking kfd */ if (! run_pm ) { mutex_lock ( & kfd_processes_mutex ) ; /* For first KFD device suspend all the KFD processes */ if ( ++ kfd_locked == 1 ) kfd_suspend_all_processes ( ) ; mutex_unlock ( & kfd_processes_mutex ) ; <S2SV_ModEnd>"
304,<S2SV_ModStart> if ( count < 0 ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; if (! kfd -> init_complete ) return ; /* for runtime suspend, skip locking kfd */ if (! run_pm ) { mutex_lock ( & kfd_processes_mutex ) ; /* For first KFD device suspend all the KFD processes */ if ( ++ kfd_locked == 1 ) kfd_suspend_all_processes ( ) ; mutex_unlock ( & kfd_processes_mutex ) ; <S2SV_ModEnd>"
305,<S2SV_ModStart> if ( modep -> altmodes == 0 ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ; if (! port -> partner ) return ; <S2SV_ModEnd>
306,<S2SV_ModStart> if (! modep -> altmodes ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ; if (! port -> partner ) return ; <S2SV_ModEnd>
307,<S2SV_ModStart> if (! modep -> altmodes ) return ; <S2SV_ModEnd>,0,<S2SV_ModStart> ; if (! port -> partner ) return ; <S2SV_ModEnd>
308,<S2SV_ModStart> if ( modep -> altmodes < 0 ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ; if (! port -> partner ) return ; <S2SV_ModEnd>
309,<S2SV_ModStart> if (! modep ) { return ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ; if (! port -> partner ) return ; <S2SV_ModEnd>
310,<S2SV_ModStart> if ( len == 0 ) { return ( NULL ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( must_quote ( * p ) ) { len += 3 ; /* open quote + char + close quote */ } else { /*
				 * Allow space for the escape char.
				 */ len += esclen ; } } } if ( use_quotes ) { if ( have_quotes ) /*
			 * We can't quote a string that contains quotes.
			 */ return ( NULL ) ; len = slen + 3 ; } /*
	 * Allocate and construct the new string.
	 */ newstr = np = ( char * ) ecalloc ( len, sizeof ( char ) ) ; if ( use_quotes ) { SNPRINTF4 ( newstr, len, ""%c%.*s%c"", openquote, ( int ) slen, s, closequote ) ; } else { constant char * es = s + slen ; while ( s < es ) { if (! metachar ( * s ) ) { * np ++ = * s ++ ; } else if ( must_quote ( * s ) ) { /* Surround the char with quotes. */ * np ++ = openquote ; * np ++ = * s ++ ; * np ++ = closequote ; }"
311,<S2SV_ModStart> if ( len < 0 ) { return ( NULL ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( must_quote ( * p ) ) { len += 3 ; /* open quote + char + close quote */ } else { /*
				 * Allow space for the escape char.
				 */ len += esclen ; } } } if ( use_quotes ) { if ( have_quotes ) /*
			 * We can't quote a string that contains quotes.
			 */ return ( NULL ) ; len = slen + 3 ; } /*
	 * Allocate and construct the new string.
	 */ newstr = np = ( char * ) ecalloc ( len, sizeof ( char ) ) ; if ( use_quotes ) { SNPRINTF4 ( newstr, len, ""%c%.*s%c"", openquote, ( int ) slen, s, closequote ) ; } else { constant char * es = s + slen ; while ( s < es ) { if (! metachar ( * s ) ) { * np ++ = * s ++ ; } else if ( must_quote ( * s ) ) { /* Surround the char with quotes. */ * np ++ = openquote ; * np ++ = * s ++ ; * np ++ = closequote ; }"
312,<S2SV_ModStart> if ( len <= 0 ) { return ( NULL ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( must_quote ( * p ) ) { len += 3 ; /* open quote + char + close quote */ } else { /*
				 * Allow space for the escape char.
				 */ len += esclen ; } } } if ( use_quotes ) { if ( have_quotes ) /*
			 * We can't quote a string that contains quotes.
			 */ return ( NULL ) ; len = slen + 3 ; } /*
	 * Allocate and construct the new string.
	 */ newstr = np = ( char * ) ecalloc ( len, sizeof ( char ) ) ; if ( use_quotes ) { SNPRINTF4 ( newstr, len, ""%c%.*s%c"", openquote, ( int ) slen, s, closequote ) ; } else { constant char * es = s + slen ; while ( s < es ) { if (! metachar ( * s ) ) { * np ++ = * s ++ ; } else if ( must_quote ( * s ) ) { /* Surround the char with quotes. */ * np ++ = openquote ; * np ++ = * s ++ ; * np ++ = closequote ; }"
313,<S2SV_ModStart> if ( len == 0 ) { return ( NULL ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( must_quote ( * p ) ) { len += 3 ; /* open quote + char + close quote */ } else { /*
				 * Allow space for the escape char.
				 */ len += esclen ; } } } if ( use_quotes ) { if ( have_quotes ) /*
			 * We can't quote a string that contains quotes.
			 */ return ( NULL ) ; len = slen + 3 ; } /*
	 * Allocate and construct the new string.
	 */ newstr = np = ( char * ) ecalloc ( len, sizeof ( char ) ) ; if ( use_quotes ) { SNPRINTF4 ( newstr, len, ""%c%.*s%c"", openquote, ( int ) slen, s, closequote ) ; } else { constant char * es = s + slen ; while ( s < es ) { if (! metachar ( * s ) ) { * np ++ = * s ++ ; } else if ( must_quote ( * s ) ) { /* Surround the char with quotes. */ * np ++ = openquote ; * np ++ = * s ++ ; * np ++ = closequote ; }"
314,<S2SV_ModStart> if ( len < 0 ) { return ( NULL ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( must_quote ( * p ) ) { len += 3 ; /* open quote + char + close quote */ } else { /*
				 * Allow space for the escape char.
				 */ len += esclen ; } } } if ( use_quotes ) { if ( have_quotes ) /*
			 * We can't quote a string that contains quotes.
			 */ return ( NULL ) ; len = slen + 3 ; } /*
	 * Allocate and construct the new string.
	 */ newstr = np = ( char * ) ecalloc ( len, sizeof ( char ) ) ; if ( use_quotes ) { SNPRINTF4 ( newstr, len, ""%c%.*s%c"", openquote, ( int ) slen, s, closequote ) ; } else { constant char * es = s + slen ; while ( s < es ) { if (! metachar ( * s ) ) { * np ++ = * s ++ ; } else if ( must_quote ( * s ) ) { /* Surround the char with quotes. */ * np ++ = openquote ; * np ++ = * s ++ ; * np ++ = closequote ; }"
315,<S2SV_ModStart> if (! errorFlag. good ( ) ) errorFlag = EC_EndOfStream ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
316,<S2SV_ModStart> if ( errorFlag == NULL ) errorFlag = EC_Unknown ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
317,<S2SV_ModStart> if (! errorFlag ) { errorFlag = EC_Unknown ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
318,<S2SV_ModStart> if ( readStream == NULL ) errorFlag = EC_Unknown ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
319,<S2SV_ModStart> if (! errorFlag. good ( ) ) errorFlag = EC_Unknown ; <S2SV_ModEnd>,0,"<S2SV_ModStart> else { errorFlag = EC_InvalidStream ; // incomplete dataset read from stream DCMDATA_ERROR ( ""DcmElement: "" << getTagName ( ) << "" "" << getTag ( ) << "" larger ("" << getLengthField ( ) << "") than remaining bytes ("" << getTransferredBytes ( ) << "") in file, premature end of stream"" ) ; } <S2SV_ModEnd>"
320,<S2SV_ModStart> if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) return <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank>,0,"<S2SV_ModStart> inet_twsk_hashdance() sets sk_refcnt after putting twsk
		 * and releasing the bucket lock.
		 */ if ( unlikely (! refcount_inc_not_zero ( & sktw -> sk_refcnt ) ) ) return 0 ; /* In case of repair and re-using TIME-WAIT sockets we still
		 * want to be sure that it is safe as above but honor the
		 * sequence numbers and time stamps set as part of the repair
		 * process.
		 *
		 * Without this check re-using a TIME-WAIT socket with TCP
		 * repair would accumulate a -1 on the repair assigned
		 * sequence number. The first time it is reused the sequence
		 * is -1, the second time -2, etc. This fixes that issue
		 * without appearing to create any others.
		 */ if ( likely (! tp -> repair ) ) { u32 seq = tcptw -> tw_snd_nxt + 65535 + 2 ; if (! seq ) seq = 1 ; WRITE_ONCE ( tp -> write_seq, seq ) ; tp -> rx_opt. ts_"
321,<S2SV_ModStart> if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) return <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank>,0,"<S2SV_ModStart> inet_twsk_hashdance() sets sk_refcnt after putting twsk
		 * and releasing the bucket lock.
		 */ if ( unlikely (! refcount_inc_not_zero ( & sktw -> sk_refcnt ) ) ) return 0 ; /* In case of repair and re-using TIME-WAIT sockets we still
		 * want to be sure that it is safe as above but honor the
		 * sequence numbers and time stamps set as part of the repair
		 * process.
		 *
		 * Without this check re-using a TIME-WAIT socket with TCP
		 * repair would accumulate a -1 on the repair assigned
		 * sequence number. The first time it is reused the sequence
		 * is -1, the second time -2, etc. This fixes that issue
		 * without appearing to create any others.
		 */ if ( likely (! tp -> repair ) ) { u32 seq = tcptw -> tw_snd_nxt + 65535 + 2 ; if (! seq ) seq = 1 ; WRITE_ONCE ( tp -> write_seq, seq ) ; tp -> rx_opt. ts_"
322,<S2SV_ModStart> if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) { if ( inet_addr_loopback ( & tw -> tw_v4_daddr ) || ipv4_addr_v4mapped_loopback ( & tw -> tw_v4_daddr ) ) loopback = true ; } else { if (! loopback ) { if (! inet_addr_loopback ( & tw -> tw_rcv,0,"<S2SV_ModStart> inet_twsk_hashdance() sets sk_refcnt after putting twsk
		 * and releasing the bucket lock.
		 */ if ( unlikely (! refcount_inc_not_zero ( & sktw -> sk_refcnt ) ) ) return 0 ; /* In case of repair and re-using TIME-WAIT sockets we still
		 * want to be sure that it is safe as above but honor the
		 * sequence numbers and time stamps set as part of the repair
		 * process.
		 *
		 * Without this check re-using a TIME-WAIT socket with TCP
		 * repair would accumulate a -1 on the repair assigned
		 * sequence number. The first time it is reused the sequence
		 * is -1, the second time -2, etc. This fixes that issue
		 * without appearing to create any others.
		 */ if ( likely (! tp -> repair ) ) { u32 seq = tcptw -> tw_snd_nxt + 65535 + 2 ; if (! seq ) seq = 1 ; WRITE_ONCE ( tp -> write_seq, seq ) ; tp -> rx_opt. ts_"
323,<S2SV_ModStart> if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) return <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank>  : <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank> <S2SV_blank>,0,"<S2SV_ModStart> inet_twsk_hashdance() sets sk_refcnt after putting twsk
		 * and releasing the bucket lock.
		 */ if ( unlikely (! refcount_inc_not_zero ( & sktw -> sk_refcnt ) ) ) return 0 ; /* In case of repair and re-using TIME-WAIT sockets we still
		 * want to be sure that it is safe as above but honor the
		 * sequence numbers and time stamps set as part of the repair
		 * process.
		 *
		 * Without this check re-using a TIME-WAIT socket with TCP
		 * repair would accumulate a -1 on the repair assigned
		 * sequence number. The first time it is reused the sequence
		 * is -1, the second time -2, etc. This fixes that issue
		 * without appearing to create any others.
		 */ if ( likely (! tp -> repair ) ) { u32 seq = tcptw -> tw_snd_nxt + 65535 + 2 ; if (! seq ) seq = 1 ; WRITE_ONCE ( tp -> write_seq, seq ) ; tp -> rx_opt. ts_"
324,<S2SV_ModStart> if ( tw -> tw_state == TCP_TW_IDLE ) { if ( tw -> tw_state == TCP_TW_IDLE ) { if ( inet_addr_loopback ( & tw -> tw_v4_daddr ) || ipv4_addr_v4mapped_loopback ( & tw -> tw_v4_daddr ) ) loopback = true ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> inet_twsk_hashdance() sets sk_refcnt after putting twsk
		 * and releasing the bucket lock.
		 */ if ( unlikely (! refcount_inc_not_zero ( & sktw -> sk_refcnt ) ) ) return 0 ; /* In case of repair and re-using TIME-WAIT sockets we still
		 * want to be sure that it is safe as above but honor the
		 * sequence numbers and time stamps set as part of the repair
		 * process.
		 *
		 * Without this check re-using a TIME-WAIT socket with TCP
		 * repair would accumulate a -1 on the repair assigned
		 * sequence number. The first time it is reused the sequence
		 * is -1, the second time -2, etc. This fixes that issue
		 * without appearing to create any others.
		 */ if ( likely (! tp -> repair ) ) { u32 seq = tcptw -> tw_snd_nxt + 65535 + 2 ; if (! seq ) seq = 1 ; WRITE_ONCE ( tp -> write_seq, seq ) ; tp -> rx_opt. ts_"
325,"<S2SV_ModStart> kzalloc ( sizeof ( * hdev ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> /* Firmware command queue initialize */ ret = hclge_comm_cmd_queue_init ( hdev -> pdev, & hdev -> hw. hw ) ; if ( ret ) goto err_pci_uninit ; /* Firmware command initialize */ ret = hclge_comm_cmd_init ( hdev -> ae_dev, & hdev -> hw. hw, & hdev -> fw_version, true, hdev -> reset_pending ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_clear_hw_resource ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_get_cap ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_query_dev_specs ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""failed to query dev specifications, ret = %d.\n"", ret ) ; goto err_cmd_uninit ; } ret = hclge_configure ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""Configure dev error, ret = %"
326,<S2SV_ModStart> if (! hdev ) return - ENODEV ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Firmware command queue initialize */ ret = hclge_comm_cmd_queue_init ( hdev -> pdev, & hdev -> hw. hw ) ; if ( ret ) goto err_pci_uninit ; /* Firmware command initialize */ ret = hclge_comm_cmd_init ( hdev -> ae_dev, & hdev -> hw. hw, & hdev -> fw_version, true, hdev -> reset_pending ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_clear_hw_resource ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_get_cap ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_query_dev_specs ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""failed to query dev specifications, ret = %d.\n"", ret ) ; goto err_cmd_uninit ; } ret = hclge_configure ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""Configure dev error, ret = %"
327,<S2SV_ModStart> if (! hdev ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Firmware command queue initialize */ ret = hclge_comm_cmd_queue_init ( hdev -> pdev, & hdev -> hw. hw ) ; if ( ret ) goto err_pci_uninit ; /* Firmware command initialize */ ret = hclge_comm_cmd_init ( hdev -> ae_dev, & hdev -> hw. hw, & hdev -> fw_version, true, hdev -> reset_pending ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_clear_hw_resource ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_get_cap ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_query_dev_specs ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""failed to query dev specifications, ret = %d.\n"", ret ) ; goto err_cmd_uninit ; } ret = hclge_configure ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""Configure dev error, ret = %"
328,<S2SV_ModStart> if (! hdev ) return - ENOENT ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Firmware command queue initialize */ ret = hclge_comm_cmd_queue_init ( hdev -> pdev, & hdev -> hw. hw ) ; if ( ret ) goto err_pci_uninit ; /* Firmware command initialize */ ret = hclge_comm_cmd_init ( hdev -> ae_dev, & hdev -> hw. hw, & hdev -> fw_version, true, hdev -> reset_pending ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_clear_hw_resource ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_get_cap ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_query_dev_specs ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""failed to query dev specifications, ret = %d.\n"", ret ) ; goto err_cmd_uninit ; } ret = hclge_configure ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""Configure dev error, ret = %"
329,<S2SV_ModStart> if (! hdev ) goto err_no_dev ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Firmware command queue initialize */ ret = hclge_comm_cmd_queue_init ( hdev -> pdev, & hdev -> hw. hw ) ; if ( ret ) goto err_pci_uninit ; /* Firmware command initialize */ ret = hclge_comm_cmd_init ( hdev -> ae_dev, & hdev -> hw. hw, & hdev -> fw_version, true, hdev -> reset_pending ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_clear_hw_resource ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_get_cap ( hdev ) ; if ( ret ) goto err_cmd_uninit ; ret = hclge_query_dev_specs ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""failed to query dev specifications, ret = %d.\n"", ret ) ; goto err_cmd_uninit ; } ret = hclge_configure ( hdev ) ; if ( ret ) { dev_err ( & pdev -> dev, ""Configure dev error, ret = %"
330,<S2SV_ModStart> unsigned long now ; <S2SV_ModEnd>,0,"int32_t ble_hs_conn_timer ( void ) { /* If there are no timeouts configured, then there is nothing to check. */ # if MYNEWT_VAL ( BLE_L2CAP_RX_FRAG_TIMEOUT ) == 0 && BLE_HS_ATT_SVR_QUEUED_WRITE_TMO == 0 return BLE_HS_FOREVER ; # endif struct ble_hs_conn * conn ; ble_npl_time_t now = ble_npl_time_get ( ) ; int32_t next_exp_in = BLE_HS_FOREVER ; int32_t next_exp_in_new ; bool next_exp_in_updated ; int32_t time_diff ; ble_hs_lock ( ) ; /* This loop performs one of two tasks:
     * 1. Determine if any connections need to be terminated due to timeout. If
     *    so connection is disconnected.
     * 2. Otherwise, determine when the next timeout will occur.
     */ SLIST_FOREACH ( conn, & ble_hs_conns, bhc_next ) { if (! ( conn"
331,<S2SV_ModStart> if ( conn == NULL ) { return BLE_HS_FOREVER ; } <S2SV_ModEnd>,0,"int32_t ble_hs_conn_timer ( void ) { /* If there are no timeouts configured, then there is nothing to check. */ # if MYNEWT_VAL ( BLE_L2CAP_RX_FRAG_TIMEOUT ) == 0 && BLE_HS_ATT_SVR_QUEUED_WRITE_TMO == 0 return BLE_HS_FOREVER ; # endif struct ble_hs_conn * conn ; ble_npl_time_t now = ble_npl_time_get ( ) ; int32_t next_exp_in = BLE_HS_FOREVER ; int32_t next_exp_in_new ; bool next_exp_in_updated ; int32_t time_diff ; ble_hs_lock ( ) ; /* This loop performs one of two tasks:
     * 1. Determine if any connections need to be terminated due to timeout. If
     *    so connection is disconnected.
     * 2. Otherwise, determine when the next timeout will occur.
     */ SLIST_FOREACH ( conn, & ble_hs_conns, bhc_next ) { if (! ( conn"
332,<S2SV_ModStart> ( unsigned long ) conn -> bhc_flags & BLE_HS_CONN_F_TERMINATING ) { return BLE_HS_CONN_F_TERMINATING ; } <S2SV_ModEnd>,0,"int32_t ble_hs_conn_timer ( void ) { /* If there are no timeouts configured, then there is nothing to check. */ # if MYNEWT_VAL ( BLE_L2CAP_RX_FRAG_TIMEOUT ) == 0 && BLE_HS_ATT_SVR_QUEUED_WRITE_TMO == 0 return BLE_HS_FOREVER ; # endif struct ble_hs_conn * conn ; ble_npl_time_t now = ble_npl_time_get ( ) ; int32_t next_exp_in = BLE_HS_FOREVER ; int32_t next_exp_in_new ; bool next_exp_in_updated ; int32_t time_diff ; ble_hs_lock ( ) ; /* This loop performs one of two tasks:
     * 1. Determine if any connections need to be terminated due to timeout. If
     *    so connection is disconnected.
     * 2. Otherwise, determine when the next timeout will occur.
     */ SLIST_FOREACH ( conn, & ble_hs_conns, bhc_next ) { if (! ( conn"
333,<S2SV_ModStart> ( unsigned long ) conn -> bhc_flags & BLE_HS_CONN_F_TERMINATING ) ) { return BLE_HS_CONN_F_TERMINATING ; } <S2SV_ModEnd>,0,"int32_t ble_hs_conn_timer ( void ) { /* If there are no timeouts configured, then there is nothing to check. */ # if MYNEWT_VAL ( BLE_L2CAP_RX_FRAG_TIMEOUT ) == 0 && BLE_HS_ATT_SVR_QUEUED_WRITE_TMO == 0 return BLE_HS_FOREVER ; # endif struct ble_hs_conn * conn ; ble_npl_time_t now = ble_npl_time_get ( ) ; int32_t next_exp_in = BLE_HS_FOREVER ; int32_t next_exp_in_new ; bool next_exp_in_updated ; int32_t time_diff ; ble_hs_lock ( ) ; /* This loop performs one of two tasks:
     * 1. Determine if any connections need to be terminated due to timeout. If
     *    so connection is disconnected.
     * 2. Otherwise, determine when the next timeout will occur.
     */ SLIST_FOREACH ( conn, & ble_hs_conns, bhc_next ) { if (! ( conn"
334,<S2SV_ModStart> unsigned long time_diff ; <S2SV_ModEnd>,0,"int32_t ble_hs_conn_timer ( void ) { /* If there are no timeouts configured, then there is nothing to check. */ # if MYNEWT_VAL ( BLE_L2CAP_RX_FRAG_TIMEOUT ) == 0 && BLE_HS_ATT_SVR_QUEUED_WRITE_TMO == 0 return BLE_HS_FOREVER ; # endif struct ble_hs_conn * conn ; ble_npl_time_t now = ble_npl_time_get ( ) ; int32_t next_exp_in = BLE_HS_FOREVER ; int32_t next_exp_in_new ; bool next_exp_in_updated ; int32_t time_diff ; ble_hs_lock ( ) ; /* This loop performs one of two tasks:
     * 1. Determine if any connections need to be terminated due to timeout. If
     *    so connection is disconnected.
     * 2. Otherwise, determine when the next timeout will occur.
     */ SLIST_FOREACH ( conn, & ble_hs_conns, bhc_next ) { if (! ( conn"
335,<S2SV_ModStart> if ( padding == 0 ) { valid = false ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( dest_size - * decoded_bytes < ASCII_BLOCK ) return BASE64_ECODE_BUF ; /* Decode base-64 block into ascii block and move pointer */ DecodeBase64Block ( dptr, b64 ) ; dptr += numDecoded_blk ; * decoded_bytes += numDecoded_blk ; /* Reset base-64 block and index */ bbidx = 0 ; padding = 0 ; * consumed_bytes += B64_BLOCK + sp ; sp = 0 ; leading_sp = 0 ; memset ( & b64, 0, sizeof ( b64 ) ) ; } } if ( bbidx > 0 && bbidx < 4 && ( (! valid && mode == BASE64_MODE_RFC4648 ) ) ) { /* Decoded bytes for 1 or 2 base64 encoded bytes is 1 */ padding = bbidx > 1? B64_BLOCK - bbidx : 2 ; uint32_t numDecoded_blk = ASCII_BLOCK - ( padding < B64_BLOCK? padding : ASCII_BLOCK ) ; if ( dest_size < * decoded_bytes + numDecoded_blk ) { SCLogDebug ( ""Destination buffer full"" ) ; ecode = BASE"
336,<S2SV_ModStart> if ( padding == 0 ) { return BASE64_ECODE_ERR ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( dest_size - * decoded_bytes < ASCII_BLOCK ) return BASE64_ECODE_BUF ; /* Decode base-64 block into ascii block and move pointer */ DecodeBase64Block ( dptr, b64 ) ; dptr += numDecoded_blk ; * decoded_bytes += numDecoded_blk ; /* Reset base-64 block and index */ bbidx = 0 ; padding = 0 ; * consumed_bytes += B64_BLOCK + sp ; sp = 0 ; leading_sp = 0 ; memset ( & b64, 0, sizeof ( b64 ) ) ; } } if ( bbidx > 0 && bbidx < 4 && ( (! valid && mode == BASE64_MODE_RFC4648 ) ) ) { /* Decoded bytes for 1 or 2 base64 encoded bytes is 1 */ padding = bbidx > 1? B64_BLOCK - bbidx : 2 ; uint32_t numDecoded_blk = ASCII_BLOCK - ( padding < B64_BLOCK? padding : ASCII_BLOCK ) ; if ( dest_size < * decoded_bytes + numDecoded_blk ) { SCLogDebug ( ""Destination buffer full"" ) ; ecode = BASE"
337,<S2SV_ModStart> if ( padding == 0 ) { valid = false ; break ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( dest_size - * decoded_bytes < ASCII_BLOCK ) return BASE64_ECODE_BUF ; /* Decode base-64 block into ascii block and move pointer */ DecodeBase64Block ( dptr, b64 ) ; dptr += numDecoded_blk ; * decoded_bytes += numDecoded_blk ; /* Reset base-64 block and index */ bbidx = 0 ; padding = 0 ; * consumed_bytes += B64_BLOCK + sp ; sp = 0 ; leading_sp = 0 ; memset ( & b64, 0, sizeof ( b64 ) ) ; } } if ( bbidx > 0 && bbidx < 4 && ( (! valid && mode == BASE64_MODE_RFC4648 ) ) ) { /* Decoded bytes for 1 or 2 base64 encoded bytes is 1 */ padding = bbidx > 1? B64_BLOCK - bbidx : 2 ; uint32_t numDecoded_blk = ASCII_BLOCK - ( padding < B64_BLOCK? padding : ASCII_BLOCK ) ; if ( dest_size < * decoded_bytes + numDecoded_blk ) { SCLogDebug ( ""Destination buffer full"" ) ; ecode = BASE"
338,<S2SV_ModStart> if ( padding == 0 ) { return BASE64_ECODE_BAD ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( dest_size - * decoded_bytes < ASCII_BLOCK ) return BASE64_ECODE_BUF ; /* Decode base-64 block into ascii block and move pointer */ DecodeBase64Block ( dptr, b64 ) ; dptr += numDecoded_blk ; * decoded_bytes += numDecoded_blk ; /* Reset base-64 block and index */ bbidx = 0 ; padding = 0 ; * consumed_bytes += B64_BLOCK + sp ; sp = 0 ; leading_sp = 0 ; memset ( & b64, 0, sizeof ( b64 ) ) ; } } if ( bbidx > 0 && bbidx < 4 && ( (! valid && mode == BASE64_MODE_RFC4648 ) ) ) { /* Decoded bytes for 1 or 2 base64 encoded bytes is 1 */ padding = bbidx > 1? B64_BLOCK - bbidx : 2 ; uint32_t numDecoded_blk = ASCII_BLOCK - ( padding < B64_BLOCK? padding : ASCII_BLOCK ) ; if ( dest_size < * decoded_bytes + numDecoded_blk ) { SCLogDebug ( ""Destination buffer full"" ) ; ecode = BASE"
339,<S2SV_ModStart> if ( padding > B64_BLOCK ) { ecode = BASE64_ECODE_ERR ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( dest_size - * decoded_bytes < ASCII_BLOCK ) return BASE64_ECODE_BUF ; /* Decode base-64 block into ascii block and move pointer */ DecodeBase64Block ( dptr, b64 ) ; dptr += numDecoded_blk ; * decoded_bytes += numDecoded_blk ; /* Reset base-64 block and index */ bbidx = 0 ; padding = 0 ; * consumed_bytes += B64_BLOCK + sp ; sp = 0 ; leading_sp = 0 ; memset ( & b64, 0, sizeof ( b64 ) ) ; } } if ( bbidx > 0 && bbidx < 4 && ( (! valid && mode == BASE64_MODE_RFC4648 ) ) ) { /* Decoded bytes for 1 or 2 base64 encoded bytes is 1 */ padding = bbidx > 1? B64_BLOCK - bbidx : 2 ; uint32_t numDecoded_blk = ASCII_BLOCK - ( padding < B64_BLOCK? padding : ASCII_BLOCK ) ; if ( dest_size < * decoded_bytes + numDecoded_blk ) { SCLogDebug ( ""Destination buffer full"" ) ; ecode = BASE"
340,"<S2SV_ModStart> if (! utf8_len ) { redirection_free_data ( pData, NULL ) ; return FALSE ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> / sizeof ( WCHAR ), & utf8_len ) ; <S2SV_ModEnd>"
341,"<S2SV_ModStart> if (! utf8_len ) { redirection_free_data ( pData, NULL ) ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> / sizeof ( WCHAR ), & utf8_len ) ; <S2SV_ModEnd>"
342,"<S2SV_ModStart> if (! utf8_len ) goto fail ; memset ( utf8, 0, sizeof ( utf8 ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> / sizeof ( WCHAR ), & utf8_len ) ; <S2SV_ModEnd>"
343,"<S2SV_ModStart> if (! utf8_len ) goto fail ; memset ( utf8, 0, utf8_len ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> / sizeof ( WCHAR ), & utf8_len ) ; <S2SV_ModEnd>"
344,"<S2SV_ModStart> if (! utf8_len ) goto fail ; memset ( wchar, 0, sizeof ( utf8 ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> / sizeof ( WCHAR ), & utf8_len ) ; <S2SV_ModEnd>"
345,<S2SV_ModStart> if ( ret ) { return ret ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> { gpadl -> decrypted = false ; return ret ; } /*
	 * Set the ""decrypted"" flag to true for the set_memory_decrypted()
	 * success case. In the failure case, the encryption state of the
	 * memory is unknown. Leave ""decrypted"" as true to ensure the
	 * memory will be leaked instead of going back on the free list.
	 */ gpadl -> decrypted = true ; ret = set_memory_decrypted ( ( unsigned long ) kbuffer, PFN_UP ( size ) ) ; if ( ret ) { dev_warn ( & channel -> device_obj -> device, ""Failed to set host visibility for new GPADL %d.\n"", ret ) ; return ret ; } init_completion ( & msginfo -> waitevent ) ; msginfo -> waiting_channel = channel ; gpadlmsg = ( struct vmbus_channel_gpadl_header * ) msginfo -> msg ; gpadlmsg -> header. msgtype = CHANNELMSG_GPADL_HEADER ; gpadlmsg -> child_relid = channel -> offermsg. child_relid ; gpadlmsg"
346,<S2SV_ModStart> if ( ret!= 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> { gpadl -> decrypted = false ; return ret ; } /*
	 * Set the ""decrypted"" flag to true for the set_memory_decrypted()
	 * success case. In the failure case, the encryption state of the
	 * memory is unknown. Leave ""decrypted"" as true to ensure the
	 * memory will be leaked instead of going back on the free list.
	 */ gpadl -> decrypted = true ; ret = set_memory_decrypted ( ( unsigned long ) kbuffer, PFN_UP ( size ) ) ; if ( ret ) { dev_warn ( & channel -> device_obj -> device, ""Failed to set host visibility for new GPADL %d.\n"", ret ) ; return ret ; } init_completion ( & msginfo -> waitevent ) ; msginfo -> waiting_channel = channel ; gpadlmsg = ( struct vmbus_channel_gpadl_header * ) msginfo -> msg ; gpadlmsg -> header. msgtype = CHANNELMSG_GPADL_HEADER ; gpadlmsg -> child_relid = channel -> offermsg. child_relid ; gpadlmsg"
347,<S2SV_ModStart> if ( ret!= 0 ) { return ret ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> { gpadl -> decrypted = false ; return ret ; } /*
	 * Set the ""decrypted"" flag to true for the set_memory_decrypted()
	 * success case. In the failure case, the encryption state of the
	 * memory is unknown. Leave ""decrypted"" as true to ensure the
	 * memory will be leaked instead of going back on the free list.
	 */ gpadl -> decrypted = true ; ret = set_memory_decrypted ( ( unsigned long ) kbuffer, PFN_UP ( size ) ) ; if ( ret ) { dev_warn ( & channel -> device_obj -> device, ""Failed to set host visibility for new GPADL %d.\n"", ret ) ; return ret ; } init_completion ( & msginfo -> waitevent ) ; msginfo -> waiting_channel = channel ; gpadlmsg = ( struct vmbus_channel_gpadl_header * ) msginfo -> msg ; gpadlmsg -> header. msgtype = CHANNELMSG_GPADL_HEADER ; gpadlmsg -> child_relid = channel -> offermsg. child_relid ; gpadlmsg"
348,<S2SV_ModStart> if ( ret < 0 ) { return ret ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> { gpadl -> decrypted = false ; return ret ; } /*
	 * Set the ""decrypted"" flag to true for the set_memory_decrypted()
	 * success case. In the failure case, the encryption state of the
	 * memory is unknown. Leave ""decrypted"" as true to ensure the
	 * memory will be leaked instead of going back on the free list.
	 */ gpadl -> decrypted = true ; ret = set_memory_decrypted ( ( unsigned long ) kbuffer, PFN_UP ( size ) ) ; if ( ret ) { dev_warn ( & channel -> device_obj -> device, ""Failed to set host visibility for new GPADL %d.\n"", ret ) ; return ret ; } init_completion ( & msginfo -> waitevent ) ; msginfo -> waiting_channel = channel ; gpadlmsg = ( struct vmbus_channel_gpadl_header * ) msginfo -> msg ; gpadlmsg -> header. msgtype = CHANNELMSG_GPADL_HEADER ; gpadlmsg -> child_relid = channel -> offermsg. child_relid ; gpadlmsg"
349,<S2SV_ModStart> if ( ret ) { return - EFAULT ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> { gpadl -> decrypted = false ; return ret ; } /*
	 * Set the ""decrypted"" flag to true for the set_memory_decrypted()
	 * success case. In the failure case, the encryption state of the
	 * memory is unknown. Leave ""decrypted"" as true to ensure the
	 * memory will be leaked instead of going back on the free list.
	 */ gpadl -> decrypted = true ; ret = set_memory_decrypted ( ( unsigned long ) kbuffer, PFN_UP ( size ) ) ; if ( ret ) { dev_warn ( & channel -> device_obj -> device, ""Failed to set host visibility for new GPADL %d.\n"", ret ) ; return ret ; } init_completion ( & msginfo -> waitevent ) ; msginfo -> waiting_channel = channel ; gpadlmsg = ( struct vmbus_channel_gpadl_header * ) msginfo -> msg ; gpadlmsg -> header. msgtype = CHANNELMSG_GPADL_HEADER ; gpadlmsg -> child_relid = channel -> offermsg. child_relid ; gpadlmsg"
350,<S2SV_ModStart> kfree ( propname ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { ret = - ENOMEM ; goto err ; } prop = of_find_property ( np, propname, & size ) ; kfree ( propname ) ; if (! prop ) { if ( state == 0 ) { ret = - ENODEV ; goto err ; <S2SV_ModEnd>"
351,<S2SV_ModStart> kfree ( statename ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { ret = - ENOMEM ; goto err ; } prop = of_find_property ( np, propname, & size ) ; kfree ( propname ) ; if (! prop ) { if ( state == 0 ) { ret = - ENODEV ; goto err ; <S2SV_ModEnd>"
352,<S2SV_ModStart> if (! propname ) { return - ENODEV ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { ret = - ENOMEM ; goto err ; } prop = of_find_property ( np, propname, & size ) ; kfree ( propname ) ; if (! prop ) { if ( state == 0 ) { ret = - ENODEV ; goto err ; <S2SV_ModEnd>"
353,<S2SV_ModStart> if (! propname ) { return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { ret = - ENOMEM ; goto err ; } prop = of_find_property ( np, propname, & size ) ; kfree ( propname ) ; if (! prop ) { if ( state == 0 ) { ret = - ENODEV ; goto err ; <S2SV_ModEnd>"
354,<S2SV_ModStart> if (! propname ) return - ENODEV ; <S2SV_ModEnd>,0,"<S2SV_ModStart> { ret = - ENOMEM ; goto err ; } prop = of_find_property ( np, propname, & size ) ; kfree ( propname ) ; if (! prop ) { if ( state == 0 ) { ret = - ENODEV ; goto err ; <S2SV_ModEnd>"
355,<S2SV_ModStart> kfree ( pool ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> INIT_LIST_HEAD_RCU ( & mem -> pools ) ; <S2SV_ModEnd>
356,<S2SV_ModStart> if (! nslabs ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> INIT_LIST_HEAD_RCU ( & mem -> pools ) ; <S2SV_ModEnd>
357,<S2SV_ModStart> if ( nslabs == 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> INIT_LIST_HEAD_RCU ( & mem -> pools ) ; <S2SV_ModEnd>
358,<S2SV_ModStart> unsigned long nslabs = nareas << IO_TLB_SHIFT ; <S2SV_ModEnd>,0,<S2SV_ModStart> INIT_LIST_HEAD_RCU ( & mem -> pools ) ; <S2SV_ModEnd>
359,<S2SV_ModStart> unsigned long nslabs = nslabs << IO_TLB_SHIFT ; <S2SV_ModEnd>,0,<S2SV_ModStart> INIT_LIST_HEAD_RCU ( & mem -> pools ) ; <S2SV_ModEnd>
360,"<S2SV_ModStart> if ( checktype == OSSL_KEYMGMT_VALIDATE_STRICT_CHECK ) return ossl_ffc_params_simple_validate ( dsa -> libctx, & dsa -> params, FFC_PARAM_TYPE_DSA, ret ) ; <S2SV_ModEnd>",0,"static int dsa_precheck_params ( const DSA * dsa, int * ret ) { if ( dsa -> params. p == NULL || dsa -> params. q == NULL ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_FFC_PARAMETERS ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. p ) > OPENSSL_DSA_MAX_MODULUS_BITS ) { ERR_raise ( ERR_LIB_DSA, DSA_R_MODULUS_TOO_LARGE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. q ) >= BN_num_bits ( dsa -> params. p ) ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_Q_VALUE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } return 1 ; <S2SV_ModEnd>"
361,"<S2SV_ModStart> if ( checktype == OSSL_KEYMGMT_VALIDATE_NONE ) return ossl_ffc_params_simple_validate ( dsa -> libctx, & dsa -> params, FFC_PARAM_TYPE_DSA, ret ) ; <S2SV_ModEnd>",0,"static int dsa_precheck_params ( const DSA * dsa, int * ret ) { if ( dsa -> params. p == NULL || dsa -> params. q == NULL ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_FFC_PARAMETERS ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. p ) > OPENSSL_DSA_MAX_MODULUS_BITS ) { ERR_raise ( ERR_LIB_DSA, DSA_R_MODULUS_TOO_LARGE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. q ) >= BN_num_bits ( dsa -> params. p ) ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_Q_VALUE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } return 1 ; <S2SV_ModEnd>"
362,"<S2SV_ModStart> if ( checktype == OSSL_KEYMGMT_VALIDATE_FULL_CHECK ) return ossl_ffc_params_full_validate ( dsa -> libctx, & dsa -> params, FFC_PARAM_TYPE_DSA, ret ) ; <S2SV_ModEnd>",0,"static int dsa_precheck_params ( const DSA * dsa, int * ret ) { if ( dsa -> params. p == NULL || dsa -> params. q == NULL ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_FFC_PARAMETERS ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. p ) > OPENSSL_DSA_MAX_MODULUS_BITS ) { ERR_raise ( ERR_LIB_DSA, DSA_R_MODULUS_TOO_LARGE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. q ) >= BN_num_bits ( dsa -> params. p ) ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_Q_VALUE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } return 1 ; <S2SV_ModEnd>"
363,"<S2SV_ModStart> if ( checktype == OSSL_KEYMGMT_VALIDATE_QUICK_CHECK ) return ossl_ffc_params_simple_validate ( dsa -> libctx, & dsa -> params, FFC_PARAM_TYPE_DSA, ret ) ; <S2SV_ModEnd>",0,"static int dsa_precheck_params ( const DSA * dsa, int * ret ) { if ( dsa -> params. p == NULL || dsa -> params. q == NULL ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_FFC_PARAMETERS ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. p ) > OPENSSL_DSA_MAX_MODULUS_BITS ) { ERR_raise ( ERR_LIB_DSA, DSA_R_MODULUS_TOO_LARGE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. q ) >= BN_num_bits ( dsa -> params. p ) ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_Q_VALUE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } return 1 ; <S2SV_ModEnd>"
364,"<S2SV_ModStart> if ( checktype == OSSL_KEYMGMT_VALIDATE_NORMAL_CHECK ) return ossl_ffc_params_simple_validate ( dsa -> libctx, & dsa -> params, FFC_PARAM_TYPE_DSA, ret ) ; <S2SV_ModEnd>",0,"static int dsa_precheck_params ( const DSA * dsa, int * ret ) { if ( dsa -> params. p == NULL || dsa -> params. q == NULL ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_FFC_PARAMETERS ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. p ) > OPENSSL_DSA_MAX_MODULUS_BITS ) { ERR_raise ( ERR_LIB_DSA, DSA_R_MODULUS_TOO_LARGE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } if ( BN_num_bits ( dsa -> params. q ) >= BN_num_bits ( dsa -> params. p ) ) { ERR_raise ( ERR_LIB_DSA, DSA_R_BAD_Q_VALUE ) ; * ret = FFC_CHECK_INVALID_PQ ; return 0 ; } return 1 ; <S2SV_ModEnd>"
365,<S2SV_ModStart> kfree ( pp -> name ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> err_free_name ; } index = ida_alloc ( & ida_index, GFP_KERNEL ) ; if ( index < 0 ) { pr_warn ( ""%s: failed to get index!\n"", name ) ; rc = index ; goto err_put_port ; } memset ( & ppdev_cb, 0, sizeof ( ppdev_cb ) ) ; ppdev_cb. irq_func = pp_irq ; ppdev_cb. flags = ( pp -> flags & PP_EXCL )? PARPORT_FLAG_EXCL : 0 ; ppdev_cb. private = pp ; pdev = parport_register_dev_model ( port, name, & ppdev_cb, index ) ; if (! pdev ) { pr_warn ( ""%s: failed to register device!\n"", name ) ; rc = - ENXIO ; ida_free ( & ida_index, index ) ; goto err_put_port ; } pp -> pdev = pdev ; pp -> index = index ; dev_dbg ( & pdev -> dev, ""registered pardevice\n"" ) ; err_"
366,<S2SV_ModStart> kfree ( ppdev_cb. name ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> err_free_name ; } index = ida_alloc ( & ida_index, GFP_KERNEL ) ; if ( index < 0 ) { pr_warn ( ""%s: failed to get index!\n"", name ) ; rc = index ; goto err_put_port ; } memset ( & ppdev_cb, 0, sizeof ( ppdev_cb ) ) ; ppdev_cb. irq_func = pp_irq ; ppdev_cb. flags = ( pp -> flags & PP_EXCL )? PARPORT_FLAG_EXCL : 0 ; ppdev_cb. private = pp ; pdev = parport_register_dev_model ( port, name, & ppdev_cb, index ) ; if (! pdev ) { pr_warn ( ""%s: failed to register device!\n"", name ) ; rc = - ENXIO ; ida_free ( & ida_index, index ) ; goto err_put_port ; } pp -> pdev = pdev ; pp -> index = index ; dev_dbg ( & pdev -> dev, ""registered pardevice\n"" ) ; err_"
367,<S2SV_ModStart> kfree ( ppdev_cb ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> err_free_name ; } index = ida_alloc ( & ida_index, GFP_KERNEL ) ; if ( index < 0 ) { pr_warn ( ""%s: failed to get index!\n"", name ) ; rc = index ; goto err_put_port ; } memset ( & ppdev_cb, 0, sizeof ( ppdev_cb ) ) ; ppdev_cb. irq_func = pp_irq ; ppdev_cb. flags = ( pp -> flags & PP_EXCL )? PARPORT_FLAG_EXCL : 0 ; ppdev_cb. private = pp ; pdev = parport_register_dev_model ( port, name, & ppdev_cb, index ) ; if (! pdev ) { pr_warn ( ""%s: failed to register device!\n"", name ) ; rc = - ENXIO ; ida_free ( & ida_index, index ) ; goto err_put_port ; } pp -> pdev = pdev ; pp -> index = index ; dev_dbg ( & pdev -> dev, ""registered pardevice\n"" ) ; err_"
368,<S2SV_ModStart> kfree ( & ppdev_cb ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> err_free_name ; } index = ida_alloc ( & ida_index, GFP_KERNEL ) ; if ( index < 0 ) { pr_warn ( ""%s: failed to get index!\n"", name ) ; rc = index ; goto err_put_port ; } memset ( & ppdev_cb, 0, sizeof ( ppdev_cb ) ) ; ppdev_cb. irq_func = pp_irq ; ppdev_cb. flags = ( pp -> flags & PP_EXCL )? PARPORT_FLAG_EXCL : 0 ; ppdev_cb. private = pp ; pdev = parport_register_dev_model ( port, name, & ppdev_cb, index ) ; if (! pdev ) { pr_warn ( ""%s: failed to register device!\n"", name ) ; rc = - ENXIO ; ida_free ( & ida_index, index ) ; goto err_put_port ; } pp -> pdev = pdev ; pp -> index = index ; dev_dbg ( & pdev -> dev, ""registered pardevice\n"" ) ; err_"
369,<S2SV_ModStart> kfree ( port ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> err_free_name ; } index = ida_alloc ( & ida_index, GFP_KERNEL ) ; if ( index < 0 ) { pr_warn ( ""%s: failed to get index!\n"", name ) ; rc = index ; goto err_put_port ; } memset ( & ppdev_cb, 0, sizeof ( ppdev_cb ) ) ; ppdev_cb. irq_func = pp_irq ; ppdev_cb. flags = ( pp -> flags & PP_EXCL )? PARPORT_FLAG_EXCL : 0 ; ppdev_cb. private = pp ; pdev = parport_register_dev_model ( port, name, & ppdev_cb, index ) ; if (! pdev ) { pr_warn ( ""%s: failed to register device!\n"", name ) ; rc = - ENXIO ; ida_free ( & ida_index, index ) ; goto err_put_port ; } pp -> pdev = pdev ; pp -> index = index ; dev_dbg ( & pdev -> dev, ""registered pardevice\n"" ) ; err_"
370,<S2SV_ModStart> if ( callid == NULL ) { return NULL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> Ensure the copy length does not exceed MAX_CALLID_SIZE - 1 if ( input_len > MAX_CALLID_SIZE - 1 ) { input_len = MAX_CALLID_SIZE - 1 ; } // Copy the matching part of payload strncpy ( callid, payload + pmatch [ 2 ]. rm_so, input_len ) ; <S2SV_ModEnd>"
371,"<S2SV_ModStart> if ( callid == NULL ) { return sip_get_callid ( payload, NULL ) ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> Ensure the copy length does not exceed MAX_CALLID_SIZE - 1 if ( input_len > MAX_CALLID_SIZE - 1 ) { input_len = MAX_CALLID_SIZE - 1 ; } // Copy the matching part of payload strncpy ( callid, payload + pmatch [ 2 ]. rm_so, input_len ) ; <S2SV_ModEnd>"
372,<S2SV_ModStart> if ( pmatch == NULL ) { return NULL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> Ensure the copy length does not exceed MAX_CALLID_SIZE - 1 if ( input_len > MAX_CALLID_SIZE - 1 ) { input_len = MAX_CALLID_SIZE - 1 ; } // Copy the matching part of payload strncpy ( callid, payload + pmatch [ 2 ]. rm_so, input_len ) ; <S2SV_ModEnd>"
373,<S2SV_ModStart> if ( callid == NULL ) { return sip_get_callid ( payload ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> Ensure the copy length does not exceed MAX_CALLID_SIZE - 1 if ( input_len > MAX_CALLID_SIZE - 1 ) { input_len = MAX_CALLID_SIZE - 1 ; } // Copy the matching part of payload strncpy ( callid, payload + pmatch [ 2 ]. rm_so, input_len ) ; <S2SV_ModEnd>"
374,"<S2SV_ModStart> if ( pmatch == NULL ) { return sip_get_callid ( payload, NULL ) ; } <S2SV_ModEnd>",0,"<S2SV_ModStart> Ensure the copy length does not exceed MAX_CALLID_SIZE - 1 if ( input_len > MAX_CALLID_SIZE - 1 ) { input_len = MAX_CALLID_SIZE - 1 ; } // Copy the matching part of payload strncpy ( callid, payload + pmatch [ 2 ]. rm_so, input_len ) ; <S2SV_ModEnd>"
375,<S2SV_ModStart> if ( mobile_ivalue_size_ < 0 ) { return ; <S2SV_ModEnd>,0,<S2SV_ModStart> || mobile_ivalue_size_ > ivalues -> size ( ) ) { mobile_ivalue_size_ = ivalues -> size ( ) ; <S2SV_ModEnd>
376,<S2SV_ModStart> ) { if ( mobile_ivalue_size_ < 0 ) { mobile_ivalue_size_ = ivalues -> size ( ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> || mobile_ivalue_size_ > ivalues -> size ( ) ) { mobile_ivalue_size_ = ivalues -> size ( ) ; <S2SV_ModEnd>
377,<S2SV_ModStart> if ( mobile_ivalue_size_ < 0 ) { mobile_ivalue_size_ = 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> || mobile_ivalue_size_ > ivalues -> size ( ) ) { mobile_ivalue_size_ = ivalues -> size ( ) ; <S2SV_ModEnd>
378,<S2SV_ModStart> ) { uint32_t mobile_ivalue_size_ = 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> || mobile_ivalue_size_ > ivalues -> size ( ) ) { mobile_ivalue_size_ = ivalues -> size ( ) ; <S2SV_ModEnd>
379,<S2SV_ModStart> ) { if ( mobile_ivalue_size_ < 0 ) { mobile_ivalue_size_ = 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> || mobile_ivalue_size_ > ivalues -> size ( ) ) { mobile_ivalue_size_ = ivalues -> size ( ) ; <S2SV_ModEnd>
380,<S2SV_ModStart> unsigned int nsh_len ; struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; <S2SV_ModEnd>,0,"unsigned int outer_hlen, mac_len, nsh_len ; struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; u16 mac_offset = skb -> mac_header ; __be16 outer_proto, proto ; skb_reset_network_header ( skb ) ; outer_proto = skb -> protocol ; outer_hlen = skb_mac_header_len ( skb ) ; mac_len = skb -> mac_len ; if ( unlikely (! pskb_may_pull ( skb, NSH_BASE_HDR_LEN ) ) ) goto out ; nsh_len = nsh_hdr_len ( nsh_hdr ( skb ) ) ; if ( nsh_len < NSH_BASE_HDR_LEN ) goto out ; if ( unlikely (! pskb_may_pull ( skb, nsh_len ) ) ) goto out ; proto = tun_p_to_eth_p ( nsh_hdr ( skb ) -> np ) ; if (! proto ) goto out ; __skb_pull ( skb, nsh_len ) ; skb"
381,<S2SV_ModStart> if (! nsh_len ) goto out ; <S2SV_ModEnd>,0,"unsigned int outer_hlen, mac_len, nsh_len ; struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; u16 mac_offset = skb -> mac_header ; __be16 outer_proto, proto ; skb_reset_network_header ( skb ) ; outer_proto = skb -> protocol ; outer_hlen = skb_mac_header_len ( skb ) ; mac_len = skb -> mac_len ; if ( unlikely (! pskb_may_pull ( skb, NSH_BASE_HDR_LEN ) ) ) goto out ; nsh_len = nsh_hdr_len ( nsh_hdr ( skb ) ) ; if ( nsh_len < NSH_BASE_HDR_LEN ) goto out ; if ( unlikely (! pskb_may_pull ( skb, nsh_len ) ) ) goto out ; proto = tun_p_to_eth_p ( nsh_hdr ( skb ) -> np ) ; if (! proto ) goto out ; __skb_pull ( skb, nsh_len ) ; skb"
382,"<S2SV_ModStart> unsigned int nsh_len, mac_offset = skb -> mac_header ; <S2SV_ModEnd>",0,"unsigned int outer_hlen, mac_len, nsh_len ; struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; u16 mac_offset = skb -> mac_header ; __be16 outer_proto, proto ; skb_reset_network_header ( skb ) ; outer_proto = skb -> protocol ; outer_hlen = skb_mac_header_len ( skb ) ; mac_len = skb -> mac_len ; if ( unlikely (! pskb_may_pull ( skb, NSH_BASE_HDR_LEN ) ) ) goto out ; nsh_len = nsh_hdr_len ( nsh_hdr ( skb ) ) ; if ( nsh_len < NSH_BASE_HDR_LEN ) goto out ; if ( unlikely (! pskb_may_pull ( skb, nsh_len ) ) ) goto out ; proto = tun_p_to_eth_p ( nsh_hdr ( skb ) -> np ) ; if (! proto ) goto out ; __skb_pull ( skb, nsh_len ) ; skb"
383,<S2SV_ModStart> if ( nsh_len < 0 ) { goto out ; } <S2SV_ModEnd>,0,"unsigned int outer_hlen, mac_len, nsh_len ; struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; u16 mac_offset = skb -> mac_header ; __be16 outer_proto, proto ; skb_reset_network_header ( skb ) ; outer_proto = skb -> protocol ; outer_hlen = skb_mac_header_len ( skb ) ; mac_len = skb -> mac_len ; if ( unlikely (! pskb_may_pull ( skb, NSH_BASE_HDR_LEN ) ) ) goto out ; nsh_len = nsh_hdr_len ( nsh_hdr ( skb ) ) ; if ( nsh_len < NSH_BASE_HDR_LEN ) goto out ; if ( unlikely (! pskb_may_pull ( skb, nsh_len ) ) ) goto out ; proto = tun_p_to_eth_p ( nsh_hdr ( skb ) -> np ) ; if (! proto ) goto out ; __skb_pull ( skb, nsh_len ) ; skb"
384,<S2SV_ModStart> if ( nsh_len < 0 ) goto out ; <S2SV_ModEnd>,0,"unsigned int outer_hlen, mac_len, nsh_len ; struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; u16 mac_offset = skb -> mac_header ; __be16 outer_proto, proto ; skb_reset_network_header ( skb ) ; outer_proto = skb -> protocol ; outer_hlen = skb_mac_header_len ( skb ) ; mac_len = skb -> mac_len ; if ( unlikely (! pskb_may_pull ( skb, NSH_BASE_HDR_LEN ) ) ) goto out ; nsh_len = nsh_hdr_len ( nsh_hdr ( skb ) ) ; if ( nsh_len < NSH_BASE_HDR_LEN ) goto out ; if ( unlikely (! pskb_may_pull ( skb, nsh_len ) ) ) goto out ; proto = tun_p_to_eth_p ( nsh_hdr ( skb ) -> np ) ; if (! proto ) goto out ; __skb_pull ( skb, nsh_len ) ; skb"
385,<S2SV_ModStart> if ( cpuid < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> = FIELD_GET ( KVM_DEV_ARM_VGIC_CPUID_MASK, attr -> attr ) ; reg_attr -> addr = attr -> attr & KVM_DEV_ARM_VGIC_OFFSET_MASK ; reg_attr -> vcpu = kvm_get_vcpu_by_id ( dev -> kvm, cpuid ) ; if (! reg_attr -> vcpu ) return - EINVAL ; <S2SV_ModEnd>"
386,<S2SV_ModStart> if ( cpuid < 0 ) { return KVM_EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> = FIELD_GET ( KVM_DEV_ARM_VGIC_CPUID_MASK, attr -> attr ) ; reg_attr -> addr = attr -> attr & KVM_DEV_ARM_VGIC_OFFSET_MASK ; reg_attr -> vcpu = kvm_get_vcpu_by_id ( dev -> kvm, cpuid ) ; if (! reg_attr -> vcpu ) return - EINVAL ; <S2SV_ModEnd>"
387,<S2SV_ModStart> if ( cpuid < 0 ) { return KVM_ERR_INVALIDDATA ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> = FIELD_GET ( KVM_DEV_ARM_VGIC_CPUID_MASK, attr -> attr ) ; reg_attr -> addr = attr -> attr & KVM_DEV_ARM_VGIC_OFFSET_MASK ; reg_attr -> vcpu = kvm_get_vcpu_by_id ( dev -> kvm, cpuid ) ; if (! reg_attr -> vcpu ) return - EINVAL ; <S2SV_ModEnd>"
388,<S2SV_ModStart> if ( cpuid < 0 ) { return AVERROR ( KVM_EINVAL ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> = FIELD_GET ( KVM_DEV_ARM_VGIC_CPUID_MASK, attr -> attr ) ; reg_attr -> addr = attr -> attr & KVM_DEV_ARM_VGIC_OFFSET_MASK ; reg_attr -> vcpu = kvm_get_vcpu_by_id ( dev -> kvm, cpuid ) ; if (! reg_attr -> vcpu ) return - EINVAL ; <S2SV_ModEnd>"
389,<S2SV_ModStart> if ( cpuid < 0 ) { return AVERROR ( KERN_INVALIDDATA ) ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> = FIELD_GET ( KVM_DEV_ARM_VGIC_CPUID_MASK, attr -> attr ) ; reg_attr -> addr = attr -> attr & KVM_DEV_ARM_VGIC_OFFSET_MASK ; reg_attr -> vcpu = kvm_get_vcpu_by_id ( dev -> kvm, cpuid ) ; if (! reg_attr -> vcpu ) return - EINVAL ; <S2SV_ModEnd>"
390,<S2SV_ModStart> if (! frag ) goto err ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Either the input skb ownership is transferred to headskb
	 * or the input skb is freed, clear the reference to avoid
	 * bad access on error path.
	 */ * buf = NULL ; if ( skb_try_coalesce ( head, frag, & headstolen, & delta ) ) { kfree_skb_partial ( frag, headstolen ) ; } else { tail = TIPC_SKB_CB ( head ) -> tail ; if (! skb_has_frag_list ( head ) ) skb_shinfo ( head ) -> frag_list = frag ; else tail -> next = frag ; head -> truesize += frag -> truesize ; head -> data_len += frag -> len ; head -> len += frag -> len ; TIPC_SKB_CB ( head ) -> tail = frag ; } if ( fragid == LAST_FRAGMENT ) { TIPC_SKB_CB ( head ) -> validated = 0 ; if ( unlikely (! tipc_msg_validate ( & head ) ) ) goto err ; * buf = head ; TIPC_SKB_CB ( head"
391,<S2SV_ModStart> if (! skb_has_frag ( frag ) ) goto err ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Either the input skb ownership is transferred to headskb
	 * or the input skb is freed, clear the reference to avoid
	 * bad access on error path.
	 */ * buf = NULL ; if ( skb_try_coalesce ( head, frag, & headstolen, & delta ) ) { kfree_skb_partial ( frag, headstolen ) ; } else { tail = TIPC_SKB_CB ( head ) -> tail ; if (! skb_has_frag_list ( head ) ) skb_shinfo ( head ) -> frag_list = frag ; else tail -> next = frag ; head -> truesize += frag -> truesize ; head -> data_len += frag -> len ; head -> len += frag -> len ; TIPC_SKB_CB ( head ) -> tail = frag ; } if ( fragid == LAST_FRAGMENT ) { TIPC_SKB_CB ( head ) -> validated = 0 ; if ( unlikely (! tipc_msg_validate ( & head ) ) ) goto err ; * buf = head ; TIPC_SKB_CB ( head"
392,<S2SV_ModStart> if (! skb_has_frag_list ( frag ) ) goto err ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Either the input skb ownership is transferred to headskb
	 * or the input skb is freed, clear the reference to avoid
	 * bad access on error path.
	 */ * buf = NULL ; if ( skb_try_coalesce ( head, frag, & headstolen, & delta ) ) { kfree_skb_partial ( frag, headstolen ) ; } else { tail = TIPC_SKB_CB ( head ) -> tail ; if (! skb_has_frag_list ( head ) ) skb_shinfo ( head ) -> frag_list = frag ; else tail -> next = frag ; head -> truesize += frag -> truesize ; head -> data_len += frag -> len ; head -> len += frag -> len ; TIPC_SKB_CB ( head ) -> tail = frag ; } if ( fragid == LAST_FRAGMENT ) { TIPC_SKB_CB ( head ) -> validated = 0 ; if ( unlikely (! tipc_msg_validate ( & head ) ) ) goto err ; * buf = head ; TIPC_SKB_CB ( head"
393,<S2SV_ModStart> if ( frag == NULL ) goto err ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Either the input skb ownership is transferred to headskb
	 * or the input skb is freed, clear the reference to avoid
	 * bad access on error path.
	 */ * buf = NULL ; if ( skb_try_coalesce ( head, frag, & headstolen, & delta ) ) { kfree_skb_partial ( frag, headstolen ) ; } else { tail = TIPC_SKB_CB ( head ) -> tail ; if (! skb_has_frag_list ( head ) ) skb_shinfo ( head ) -> frag_list = frag ; else tail -> next = frag ; head -> truesize += frag -> truesize ; head -> data_len += frag -> len ; head -> len += frag -> len ; TIPC_SKB_CB ( head ) -> tail = frag ; } if ( fragid == LAST_FRAGMENT ) { TIPC_SKB_CB ( head ) -> validated = 0 ; if ( unlikely (! tipc_msg_validate ( & head ) ) ) goto err ; * buf = head ; TIPC_SKB_CB ( head"
394,<S2SV_ModStart> if (! frag ) return 0 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> /* Either the input skb ownership is transferred to headskb
	 * or the input skb is freed, clear the reference to avoid
	 * bad access on error path.
	 */ * buf = NULL ; if ( skb_try_coalesce ( head, frag, & headstolen, & delta ) ) { kfree_skb_partial ( frag, headstolen ) ; } else { tail = TIPC_SKB_CB ( head ) -> tail ; if (! skb_has_frag_list ( head ) ) skb_shinfo ( head ) -> frag_list = frag ; else tail -> next = frag ; head -> truesize += frag -> truesize ; head -> data_len += frag -> len ; head -> len += frag -> len ; TIPC_SKB_CB ( head ) -> tail = frag ; } if ( fragid == LAST_FRAGMENT ) { TIPC_SKB_CB ( head ) -> validated = 0 ; if ( unlikely (! tipc_msg_validate ( & head ) ) ) goto err ; * buf = head ; TIPC_SKB_CB ( head"
395,<S2SV_ModStart> if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( DstFormat ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( nWidth == 0 ) || ( nHeight == 0 ) ) return TRUE ; if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( DstFormat ) ; <S2SV_ModEnd>
396,<S2SV_ModStart> if ( nDstStep == 0 ) nDstStep = 1 ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( nWidth == 0 ) || ( nHeight == 0 ) ) return TRUE ; if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( DstFormat ) ; <S2SV_ModEnd>
397,<S2SV_ModStart> if ( nDstStep == 0 ) nDstStep = 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( nWidth == 0 ) || ( nHeight == 0 ) ) return TRUE ; if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( DstFormat ) ; <S2SV_ModEnd>
398,<S2SV_ModStart> if ( nDstStep == 0 ) nDstStep = nWidth ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( nWidth == 0 ) || ( nHeight == 0 ) ) return TRUE ; if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( DstFormat ) ; <S2SV_ModEnd>
399,<S2SV_ModStart> if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( SrcFormat ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( nWidth == 0 ) || ( nHeight == 0 ) ) return TRUE ; if ( nDstStep == 0 ) nDstStep = nWidth * FreeRDPGetBytesPerPixel ( DstFormat ) ; <S2SV_ModEnd>
400,<S2SV_ModStart> ( phba -> fc_ratov * 3 ) + 3 ) && vport -> port_state > LPFC_VPORT_FAILED && vport -> port_state < LPFC_VPORT_READY ) { return - EAGAIN ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> ) ; /* Send the DA_ID and Fabric LOGO to cleanup Nameserver entries. */ ndlp = lpfc_findnode_did ( vport, Fabric_DID ) ; if (! ndlp ) goto skip_logo ; if ( ndlp && ndlp -> nlp_state == NLP_STE_UNMAPPED_NODE && phba -> link_state >= LPFC_LINK_UP && phba -> fc_topology!= LPFC_TOPOLOGY_LOOP ) { if ( vport -> cfg_enable_da_id ) { /* Send DA_ID and wait for a completion. */ rc = lpfc_ns_cmd ( vport, SLI_CTNS_DA_ID, 0, 0 ) ; if ( rc ) { lpfc_printf_log ( vport -> phba, KERN_WARNING, LOG_VPORT, ""1829 CT command failed to "" ""delete objects on fabric, "" ""rc %d\n"", rc ) ; } } /*
		 * If the vpi is not registered, then a valid FDISC doesn't
		 * exist and there is no need for a E"
401,"<S2SV_ModStart> kzalloc ( sizeof ( struct lpfc_nodelist ) + 3, GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> ) ; /* Send the DA_ID and Fabric LOGO to cleanup Nameserver entries. */ ndlp = lpfc_findnode_did ( vport, Fabric_DID ) ; if (! ndlp ) goto skip_logo ; if ( ndlp && ndlp -> nlp_state == NLP_STE_UNMAPPED_NODE && phba -> link_state >= LPFC_LINK_UP && phba -> fc_topology!= LPFC_TOPOLOGY_LOOP ) { if ( vport -> cfg_enable_da_id ) { /* Send DA_ID and wait for a completion. */ rc = lpfc_ns_cmd ( vport, SLI_CTNS_DA_ID, 0, 0 ) ; if ( rc ) { lpfc_printf_log ( vport -> phba, KERN_WARNING, LOG_VPORT, ""1829 CT command failed to "" ""delete objects on fabric, "" ""rc %d\n"", rc ) ; } } /*
		 * If the vpi is not registered, then a valid FDISC doesn't
		 * exist and there is no need for a E"
402,<S2SV_ModStart> ( phba -> fc_ratov * 3 ) + 3 ) && vport -> port_state > LPFC_VPORT_FAILED && vport -> port_state < LPFC_VPORT_READY ) { check_count ++ ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ) ; /* Send the DA_ID and Fabric LOGO to cleanup Nameserver entries. */ ndlp = lpfc_findnode_did ( vport, Fabric_DID ) ; if (! ndlp ) goto skip_logo ; if ( ndlp && ndlp -> nlp_state == NLP_STE_UNMAPPED_NODE && phba -> link_state >= LPFC_LINK_UP && phba -> fc_topology!= LPFC_TOPOLOGY_LOOP ) { if ( vport -> cfg_enable_da_id ) { /* Send DA_ID and wait for a completion. */ rc = lpfc_ns_cmd ( vport, SLI_CTNS_DA_ID, 0, 0 ) ; if ( rc ) { lpfc_printf_log ( vport -> phba, KERN_WARNING, LOG_VPORT, ""1829 CT command failed to "" ""delete objects on fabric, "" ""rc %d\n"", rc ) ; } } /*
		 * If the vpi is not registered, then a valid FDISC doesn't
		 * exist and there is no need for a E"
403,"<S2SV_ModStart> kzalloc ( sizeof ( lpfc_nodelist ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> ) ; /* Send the DA_ID and Fabric LOGO to cleanup Nameserver entries. */ ndlp = lpfc_findnode_did ( vport, Fabric_DID ) ; if (! ndlp ) goto skip_logo ; if ( ndlp && ndlp -> nlp_state == NLP_STE_UNMAPPED_NODE && phba -> link_state >= LPFC_LINK_UP && phba -> fc_topology!= LPFC_TOPOLOGY_LOOP ) { if ( vport -> cfg_enable_da_id ) { /* Send DA_ID and wait for a completion. */ rc = lpfc_ns_cmd ( vport, SLI_CTNS_DA_ID, 0, 0 ) ; if ( rc ) { lpfc_printf_log ( vport -> phba, KERN_WARNING, LOG_VPORT, ""1829 CT command failed to "" ""delete objects on fabric, "" ""rc %d\n"", rc ) ; } } /*
		 * If the vpi is not registered, then a valid FDISC doesn't
		 * exist and there is no need for a E"
404,<S2SV_ModStart> ( phba -> fc_ratov * 3 ) + 3 ) && vport -> port_state < LPFC_VPORT_FAILED ) { check_count ++ ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ) ; /* Send the DA_ID and Fabric LOGO to cleanup Nameserver entries. */ ndlp = lpfc_findnode_did ( vport, Fabric_DID ) ; if (! ndlp ) goto skip_logo ; if ( ndlp && ndlp -> nlp_state == NLP_STE_UNMAPPED_NODE && phba -> link_state >= LPFC_LINK_UP && phba -> fc_topology!= LPFC_TOPOLOGY_LOOP ) { if ( vport -> cfg_enable_da_id ) { /* Send DA_ID and wait for a completion. */ rc = lpfc_ns_cmd ( vport, SLI_CTNS_DA_ID, 0, 0 ) ; if ( rc ) { lpfc_printf_log ( vport -> phba, KERN_WARNING, LOG_VPORT, ""1829 CT command failed to "" ""delete objects on fabric, "" ""rc %d\n"", rc ) ; } } /*
		 * If the vpi is not registered, then a valid FDISC doesn't
		 * exist and there is no need for a E"
405,<S2SV_ModStart> if ( optlen < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; if ( opt > LLCP_MAX_RW ) { err = - EINVAL ; break ; } llcp_sock -> rw = ( u8 ) opt ; break ; case NFC_LLCP_MIUX : if ( sk -> sk_state == LLCP_CONNECTED || sk -> sk_state == LLCP_BOUND || sk -> sk_state == LLCP_LISTEN ) { err = - EINVAL ; break ; } err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; <S2SV_ModEnd>"
406,<S2SV_ModStart> if ( optlen < 0 ) { err = - EINVAL ; break ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; if ( opt > LLCP_MAX_RW ) { err = - EINVAL ; break ; } llcp_sock -> rw = ( u8 ) opt ; break ; case NFC_LLCP_MIUX : if ( sk -> sk_state == LLCP_CONNECTED || sk -> sk_state == LLCP_BOUND || sk -> sk_state == LLCP_LISTEN ) { err = - EINVAL ; break ; } err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; <S2SV_ModEnd>"
407,<S2SV_ModStart> if ( optlen!= sizeof ( u32 ) ) { err = - EINVAL ; break ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; if ( opt > LLCP_MAX_RW ) { err = - EINVAL ; break ; } llcp_sock -> rw = ( u8 ) opt ; break ; case NFC_LLCP_MIUX : if ( sk -> sk_state == LLCP_CONNECTED || sk -> sk_state == LLCP_BOUND || sk -> sk_state == LLCP_LISTEN ) { err = - EINVAL ; break ; } err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; <S2SV_ModEnd>"
408,<S2SV_ModStart> if ( optval == NULL ) { err = - EINVAL ; break ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; if ( opt > LLCP_MAX_RW ) { err = - EINVAL ; break ; } llcp_sock -> rw = ( u8 ) opt ; break ; case NFC_LLCP_MIUX : if ( sk -> sk_state == LLCP_CONNECTED || sk -> sk_state == LLCP_BOUND || sk -> sk_state == LLCP_LISTEN ) { err = - EINVAL ; break ; } err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; <S2SV_ModEnd>"
409,<S2SV_ModStart> if ( optval == NULL ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; if ( opt > LLCP_MAX_RW ) { err = - EINVAL ; break ; } llcp_sock -> rw = ( u8 ) opt ; break ; case NFC_LLCP_MIUX : if ( sk -> sk_state == LLCP_CONNECTED || sk -> sk_state == LLCP_BOUND || sk -> sk_state == LLCP_LISTEN ) { err = - EINVAL ; break ; } err = copy_safe_from_sockptr ( & opt, sizeof ( opt ), optval, optlen ) ; if ( err ) break ; <S2SV_ModEnd>"
410,"<S2SV_ModStart> kzalloc ( sizeof ( * kn ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> dev -> parent ) ; int port1 = port_dev -> portnum ; u16 portstatus, unused ; bool disabled ; int rc ; struct kernfs_node * kn ; if (! hub ) return - ENODEV ; <S2SV_ModEnd>"
411,"<S2SV_ModStart> kzalloc ( sizeof ( struct kernfs_node ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> dev -> parent ) ; int port1 = port_dev -> portnum ; u16 portstatus, unused ; bool disabled ; int rc ; struct kernfs_node * kn ; if (! hub ) return - ENODEV ; <S2SV_ModEnd>"
412,<S2SV_ModStart> if (! hub ) { return - ENODEV ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> dev -> parent ) ; int port1 = port_dev -> portnum ; u16 portstatus, unused ; bool disabled ; int rc ; struct kernfs_node * kn ; if (! hub ) return - ENODEV ; <S2SV_ModEnd>"
413,<S2SV_ModStart> kfree ( kn ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> dev -> parent ) ; int port1 = port_dev -> portnum ; u16 portstatus, unused ; bool disabled ; int rc ; struct kernfs_node * kn ; if (! hub ) return - ENODEV ; <S2SV_ModEnd>"
414,<S2SV_ModStart> if (! hub ) return - ENODEV ; <S2SV_ModEnd>,0,"<S2SV_ModStart> dev -> parent ) ; int port1 = port_dev -> portnum ; u16 portstatus, unused ; bool disabled ; int rc ; struct kernfs_node * kn ; if (! hub ) return - ENODEV ; <S2SV_ModEnd>"
415,<S2SV_ModStart> if (! mas -> offset ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> mas_start ( mas ) ; else if ( ( mas -> offset < 2 ) && (! mas_rewind_node ( mas ) ) ) return - EBUSY ; if ( unlikely ( mas_is_none ( mas ) || mas_is_ptr ( mas ) ) ) return mas_sparse_area ( mas, min, max, size, false ) ; else if ( mas -> offset >= 2 ) mas -> offset -= 2 ; else mas -> offset = mas_data_end ( mas ) ; <S2SV_ModEnd>"
416,<S2SV_ModStart> if ( mas -> offset < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> mas_start ( mas ) ; else if ( ( mas -> offset < 2 ) && (! mas_rewind_node ( mas ) ) ) return - EBUSY ; if ( unlikely ( mas_is_none ( mas ) || mas_is_ptr ( mas ) ) ) return mas_sparse_area ( mas, min, max, size, false ) ; else if ( mas -> offset >= 2 ) mas -> offset -= 2 ; else mas -> offset = mas_data_end ( mas ) ; <S2SV_ModEnd>"
417,<S2SV_ModStart> if (! mas -> offset )<extra_id_1>if (! mas -> offset )<extra_id_2>mas -> offset = MAPLE_NODE_SLOTS ; else if (! mas_rewind_node ( mas ) ) return - EBUSY ; <S2SV_ModEnd>,0,"<S2SV_ModStart> mas_start ( mas ) ; else if ( ( mas -> offset < 2 ) && (! mas_rewind_node ( mas ) ) ) return - EBUSY ; if ( unlikely ( mas_is_none ( mas ) || mas_is_ptr ( mas ) ) ) return mas_sparse_area ( mas, min, max, size, false ) ; else if ( mas -> offset >= 2 ) mas -> offset -= 2 ; else mas -> offset = mas_data_end ( mas ) ; <S2SV_ModEnd>"
418,<S2SV_ModStart> if (! mas -> offset )<extra_id_1>if (! mas -> offset )<extra_id_2>mas -> offset = MAPLE_NODE_SLOTS ; else if (! mas_rewind_node ( mas ) ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> mas_start ( mas ) ; else if ( ( mas -> offset < 2 ) && (! mas_rewind_node ( mas ) ) ) return - EBUSY ; if ( unlikely ( mas_is_none ( mas ) || mas_is_ptr ( mas ) ) ) return mas_sparse_area ( mas, min, max, size, false ) ; else if ( mas -> offset >= 2 ) mas -> offset -= 2 ; else mas -> offset = mas_data_end ( mas ) ; <S2SV_ModEnd>"
419,<S2SV_ModStart> if (! mas -> offset )<extra_id_1>if (! mas -> offset )<extra_id_2>mas -> offset = MAPLE_NODE_SLOTS ; else if ( mas -> offset < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> mas_start ( mas ) ; else if ( ( mas -> offset < 2 ) && (! mas_rewind_node ( mas ) ) ) return - EBUSY ; if ( unlikely ( mas_is_none ( mas ) || mas_is_ptr ( mas ) ) ) return mas_sparse_area ( mas, min, max, size, false ) ; else if ( mas -> offset >= 2 ) mas -> offset -= 2 ; else mas -> offset = mas_data_end ( mas ) ; <S2SV_ModEnd>"
420,<S2SV_ModStart> if (! fw -> img ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> dma_addr_t addr ; len = ALIGN ( fw -> len, PAGE_SIZE ) ; fw -> img = dma_alloc_coherent ( fw -> device -> dev, len, & addr, GFP_KERNEL ) ; if ( fw -> img ) { memcpy ( fw -> img, src, fw -> len ) ; fw -> phys = addr ; } sg_init_one ( & fw -> mem. sgl, fw -> img, len ) ; sg_dma_address ( & fw -> mem. sgl ) = fw -> phys ; sg_dma_len ( & fw -> mem. sgl ) = len ; } break ; default : WARN_ON ( 1 ) ; return - EINVAL ; } if (! fw -> img ) return - ENOMEM ; <S2SV_ModEnd>"
421,"<S2SV_ModStart> fw -> len = ALIGN ( fw -> len, PAGE_SIZE ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> dma_addr_t addr ; len = ALIGN ( fw -> len, PAGE_SIZE ) ; fw -> img = dma_alloc_coherent ( fw -> device -> dev, len, & addr, GFP_KERNEL ) ; if ( fw -> img ) { memcpy ( fw -> img, src, fw -> len ) ; fw -> phys = addr ; } sg_init_one ( & fw -> mem. sgl, fw -> img, len ) ; sg_dma_address ( & fw -> mem. sgl ) = fw -> phys ; sg_dma_len ( & fw -> mem. sgl ) = len ; } break ; default : WARN_ON ( 1 ) ; return - EINVAL ; } if (! fw -> img ) return - ENOMEM ; <S2SV_ModEnd>"
422,<S2SV_ModStart> fw -> len < 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> dma_addr_t addr ; len = ALIGN ( fw -> len, PAGE_SIZE ) ; fw -> img = dma_alloc_coherent ( fw -> device -> dev, len, & addr, GFP_KERNEL ) ; if ( fw -> img ) { memcpy ( fw -> img, src, fw -> len ) ; fw -> phys = addr ; } sg_init_one ( & fw -> mem. sgl, fw -> img, len ) ; sg_dma_address ( & fw -> mem. sgl ) = fw -> phys ; sg_dma_len ( & fw -> mem. sgl ) = len ; } break ; default : WARN_ON ( 1 ) ; return - EINVAL ; } if (! fw -> img ) return - ENOMEM ; <S2SV_ModEnd>"
423,<S2SV_ModStart> if ( fw -> img == NULL ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> dma_addr_t addr ; len = ALIGN ( fw -> len, PAGE_SIZE ) ; fw -> img = dma_alloc_coherent ( fw -> device -> dev, len, & addr, GFP_KERNEL ) ; if ( fw -> img ) { memcpy ( fw -> img, src, fw -> len ) ; fw -> phys = addr ; } sg_init_one ( & fw -> mem. sgl, fw -> img, len ) ; sg_dma_address ( & fw -> mem. sgl ) = fw -> phys ; sg_dma_len ( & fw -> mem. sgl ) = len ; } break ; default : WARN_ON ( 1 ) ; return - EINVAL ; } if (! fw -> img ) return - ENOMEM ; <S2SV_ModEnd>"
424,<S2SV_ModStart> fw -> len <= 0 ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> dma_addr_t addr ; len = ALIGN ( fw -> len, PAGE_SIZE ) ; fw -> img = dma_alloc_coherent ( fw -> device -> dev, len, & addr, GFP_KERNEL ) ; if ( fw -> img ) { memcpy ( fw -> img, src, fw -> len ) ; fw -> phys = addr ; } sg_init_one ( & fw -> mem. sgl, fw -> img, len ) ; sg_dma_address ( & fw -> mem. sgl ) = fw -> phys ; sg_dma_len ( & fw -> mem. sgl ) = len ; } break ; default : WARN_ON ( 1 ) ; return - EINVAL ; } if (! fw -> img ) return - ENOMEM ; <S2SV_ModEnd>"
425,<S2SV_ModStart> if ( adev -> kfd. client == NULL ) return 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> || adev -> kfd. client. dev ) return 0 ; <S2SV_ModEnd>
426,<S2SV_ModStart> if (! adev -> kfd. client ) return 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> || adev -> kfd. client. dev ) return 0 ; <S2SV_ModEnd>
427,<S2SV_ModStart> if ( adev -> kfd. client == NULL ) { return 0 ; } <S2SV_ModEnd>,0,<S2SV_ModStart> || adev -> kfd. client. dev ) return 0 ; <S2SV_ModEnd>
428,<S2SV_ModStart> if ( adev -> kfd. client == NULL ) { return 0 ; <S2SV_ModEnd>,0,<S2SV_ModStart> || adev -> kfd. client. dev ) return 0 ; <S2SV_ModEnd>
429,<S2SV_ModStart> if ( adev -> kfd. client == NULL ) return - EINVAL ; <S2SV_ModEnd>,0,<S2SV_ModStart> || adev -> kfd. client. dev ) return 0 ; <S2SV_ModEnd>
430,"<S2SV_ModStart> if (! CheckRunLengthRegularFgBg ( runLength, pbOrderHdr, pbEnd, advance ) ) { * advance = 0 ; <S2SV_ModEnd>",0,"<S2SV_ModStart> 2, pbEnd ) ) { * advance = 0 ; <S2SV_ModEnd>"
431,"<S2SV_ModStart> if (! ExtractRunLengthRegularFgBg ( * pbOrderHdr, pbEnd, advance ) ) { * advance = 0 ; <S2SV_ModEnd>",0,"<S2SV_ModStart> 2, pbEnd ) ) { * advance = 0 ; <S2SV_ModEnd>"
432,"<S2SV_ModStart> if (! CheckRunLengthRegularFgBg ( runLength, pbEnd ) ) { return 0 ; <S2SV_ModEnd>",0,"<S2SV_ModStart> 2, pbEnd ) ) { * advance = 0 ; <S2SV_ModEnd>"
433,"<S2SV_ModStart> if (! CheckRunLengthRegularFgBg ( runLength, pbEnd, pbOrderHdr ) ) { return 0 ; <S2SV_ModEnd>",0,"<S2SV_ModStart> 2, pbEnd ) ) { * advance = 0 ; <S2SV_ModEnd>"
434,"<S2SV_ModStart> if (! CheckRunLengthRegularFgBg ( * pbOrderHdr, runLength, pbEnd ) ) { return 0 ; <S2SV_ModEnd>",0,"<S2SV_ModStart> 2, pbEnd ) ) { * advance = 0 ; <S2SV_ModEnd>"
435,"<S2SV_ModStart> tfd_num < 0 ) { IWL_DEBUG_TX_QUEUES ( trans, ""Q %d inactive - ignoring idx %d\n"", txq_id, ssn ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> spin_lock_bh ( & txq -> lock ) ; read_ptr = iwl_txq_get_cmd_index ( txq, txq -> read_ptr ) ; <S2SV_ModEnd>"
436,"<S2SV_ModStart> if ( tfd_num < 0 ) { IWL_DEBUG_TX_QUEUES ( trans, ""Q %d inactive - ignoring idx %d\n"", txq_id, ssn ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> spin_lock_bh ( & txq -> lock ) ; read_ptr = iwl_txq_get_cmd_index ( txq, txq -> read_ptr ) ; <S2SV_ModEnd>"
437,"<S2SV_ModStart> if ( tfd_num < 0 ) { IWL_DEBUG_TX_QUEUES ( trans, "" %d inactive - ignoring idx %d\n"", txq_id, ssn ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> spin_lock_bh ( & txq -> lock ) ; read_ptr = iwl_txq_get_cmd_index ( txq, txq -> read_ptr ) ; <S2SV_ModEnd>"
438,"<S2SV_ModStart> tfd_num < 0 ) { IWL_DEBUG_TX_QUEUES ( trans, ""[Q %d] %d -> %d (%d)\n"", txq_id, ssn, read_ptr, tfd_num ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> spin_lock_bh ( & txq -> lock ) ; read_ptr = iwl_txq_get_cmd_index ( txq, txq -> read_ptr ) ; <S2SV_ModEnd>"
439,"<S2SV_ModStart> tfd_num < 0 ) { IWL_DEBUG_TX_QUEUES ( trans, ""[Q %d] %d -> %d (%d)\n"", txq_id, ssn, tfd_num, ssn ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> spin_lock_bh ( & txq -> lock ) ; read_ptr = iwl_txq_get_cmd_index ( txq, txq -> read_ptr ) ; <S2SV_ModEnd>"
440,<S2SV_ModStart> if (! skb -> next ) return NULL ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl6 -> flowi6_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp6_type = fl6 -> fl6_icmp_type ; <S2SV_ModEnd>
441,<S2SV_ModStart> if (! skb -> data ) return NULL ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl6 -> flowi6_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp6_type = fl6 -> fl6_icmp_type ; <S2SV_ModEnd>
442,<S2SV_ModStart> if (! skb -> next ) goto out ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl6 -> flowi6_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp6_type = fl6 -> fl6_icmp_type ; <S2SV_ModEnd>
443,<S2SV_ModStart> if (! skb -> data ) goto out ; <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl6 -> flowi6_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp6_type = fl6 -> fl6_icmp_type ; <S2SV_ModEnd>
444,<S2SV_ModStart> if (! skb -> next ) { return NULL ; } <S2SV_ModEnd>,0,<S2SV_ModStart> ( fl6 -> flowi6_flags & FLOWI_FLAG_KNOWN_NH ) ) icmp6_type = fl6 -> fl6_icmp_type ; <S2SV_ModEnd>
445,<S2SV_ModStart> if ( caplen < 0 ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> if ( caplen == 0 ) return ; if ( length == 0 ) return ; b = ( u_char * ) malloc ( caplen ) ; if ( b == NULL ) { ( * ndo -> ndo_error ) ( ndo, S_ERR_ND_MEM_ALLOC, ""%s: malloc"", __func__ ) ; } /*
	 * Unescape all the data into a temporary, private, buffer.
	 * Do this so that we don't overwrite the original packet
	 * contents.
	 */ for ( s = p, t = b, i = caplen ; i!= 0 ; i -- ) { c = GET_U_1 ( s ) ; s ++ ; if ( c == 0x7d ) { if ( i <= 1 ) break ; i -- ; c = GET_U_1 ( s ) ^ 0x20 ; s ++ ; } * t ++ = c ; } /*
	 * Switch to the output buffer for dissection, and save it
	 * on the buffer stack so it can be freed; our caller must
	 * pop it when done.
	 */ if (! nd_push_buffer ( n"
446,"<S2SV_ModStart> MIN ( ndo -> ndo_packetp, sizeof ( ndo -> ndo_packetp ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> if ( caplen == 0 ) return ; if ( length == 0 ) return ; b = ( u_char * ) malloc ( caplen ) ; if ( b == NULL ) { ( * ndo -> ndo_error ) ( ndo, S_ERR_ND_MEM_ALLOC, ""%s: malloc"", __func__ ) ; } /*
	 * Unescape all the data into a temporary, private, buffer.
	 * Do this so that we don't overwrite the original packet
	 * contents.
	 */ for ( s = p, t = b, i = caplen ; i!= 0 ; i -- ) { c = GET_U_1 ( s ) ; s ++ ; if ( c == 0x7d ) { if ( i <= 1 ) break ; i -- ; c = GET_U_1 ( s ) ^ 0x20 ; s ++ ; } * t ++ = c ; } /*
	 * Switch to the output buffer for dissection, and save it
	 * on the buffer stack so it can be freed; our caller must
	 * pop it when done.
	 */ if (! nd_push_buffer ( n"
447,"<S2SV_ModStart> MIN ( ndo -> ndo_packetp, sizeof ( netdissect_options ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> if ( caplen == 0 ) return ; if ( length == 0 ) return ; b = ( u_char * ) malloc ( caplen ) ; if ( b == NULL ) { ( * ndo -> ndo_error ) ( ndo, S_ERR_ND_MEM_ALLOC, ""%s: malloc"", __func__ ) ; } /*
	 * Unescape all the data into a temporary, private, buffer.
	 * Do this so that we don't overwrite the original packet
	 * contents.
	 */ for ( s = p, t = b, i = caplen ; i!= 0 ; i -- ) { c = GET_U_1 ( s ) ; s ++ ; if ( c == 0x7d ) { if ( i <= 1 ) break ; i -- ; c = GET_U_1 ( s ) ^ 0x20 ; s ++ ; } * t ++ = c ; } /*
	 * Switch to the output buffer for dissection, and save it
	 * on the buffer stack so it can be freed; our caller must
	 * pop it when done.
	 */ if (! nd_push_buffer ( n"
448,"<S2SV_ModStart> MIN ( caplen, sizeof ( ndo -> ndo_packetp ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> if ( caplen == 0 ) return ; if ( length == 0 ) return ; b = ( u_char * ) malloc ( caplen ) ; if ( b == NULL ) { ( * ndo -> ndo_error ) ( ndo, S_ERR_ND_MEM_ALLOC, ""%s: malloc"", __func__ ) ; } /*
	 * Unescape all the data into a temporary, private, buffer.
	 * Do this so that we don't overwrite the original packet
	 * contents.
	 */ for ( s = p, t = b, i = caplen ; i!= 0 ; i -- ) { c = GET_U_1 ( s ) ; s ++ ; if ( c == 0x7d ) { if ( i <= 1 ) break ; i -- ; c = GET_U_1 ( s ) ^ 0x20 ; s ++ ; } * t ++ = c ; } /*
	 * Switch to the output buffer for dissection, and save it
	 * on the buffer stack so it can be freed; our caller must
	 * pop it when done.
	 */ if (! nd_push_buffer ( n"
449,"<S2SV_ModStart> MIN ( ndo -> ndo_packetp, sizeof ( ppp_packet ) ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> if ( caplen == 0 ) return ; if ( length == 0 ) return ; b = ( u_char * ) malloc ( caplen ) ; if ( b == NULL ) { ( * ndo -> ndo_error ) ( ndo, S_ERR_ND_MEM_ALLOC, ""%s: malloc"", __func__ ) ; } /*
	 * Unescape all the data into a temporary, private, buffer.
	 * Do this so that we don't overwrite the original packet
	 * contents.
	 */ for ( s = p, t = b, i = caplen ; i!= 0 ; i -- ) { c = GET_U_1 ( s ) ; s ++ ; if ( c == 0x7d ) { if ( i <= 1 ) break ; i -- ; c = GET_U_1 ( s ) ^ 0x20 ; s ++ ; } * t ++ = c ; } /*
	 * Switch to the output buffer for dissection, and save it
	 * on the buffer stack so it can be freed; our caller must
	 * pop it when done.
	 */ if (! nd_push_buffer ( n"
450,<S2SV_ModStart> if ( channel -> ringbuffer_page!= NULL ) { <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug>,0,"<S2SV_ModStart> /* In a CoCo VM leak the memory if it didn't get re-encrypted */ if (! channel -> ringbuffer_gpadlhandle. decrypted ) __free_pages ( channel -> ringbuffer_page, get_order ( channel -> ringbuffer_pagecount << PAGE_SHIFT ) ) ; <S2SV_ModEnd>"
451,<S2SV_ModStart> if ( channel -> ringbuffer_page ) { <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug>,0,"<S2SV_ModStart> /* In a CoCo VM leak the memory if it didn't get re-encrypted */ if (! channel -> ringbuffer_gpadlhandle. decrypted ) __free_pages ( channel -> ringbuffer_page, get_order ( channel -> ringbuffer_pagecount << PAGE_SHIFT ) ) ; <S2SV_ModEnd>"
452,<S2SV_ModStart> if ( channel -> ringbuffer_page == NULL ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> /* In a CoCo VM leak the memory if it didn't get re-encrypted */ if (! channel -> ringbuffer_gpadlhandle. decrypted ) __free_pages ( channel -> ringbuffer_page, get_order ( channel -> ringbuffer_pagecount << PAGE_SHIFT ) ) ; <S2SV_ModEnd>"
453,<S2SV_ModStart> if ( channel -> ringbuffer_page!= NULL ) { <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug>,0,"<S2SV_ModStart> /* In a CoCo VM leak the memory if it didn't get re-encrypted */ if (! channel -> ringbuffer_gpadlhandle. decrypted ) __free_pages ( channel -> ringbuffer_page, get_order ( channel -> ringbuffer_pagecount << PAGE_SHIFT ) ) ; <S2SV_ModEnd>"
454,<S2SV_ModStart> if ( channel -> ringbuffer_page ) { <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug> <S2SV_StartBug>,0,"<S2SV_ModStart> /* In a CoCo VM leak the memory if it didn't get re-encrypted */ if (! channel -> ringbuffer_gpadlhandle. decrypted ) __free_pages ( channel -> ringbuffer_page, get_order ( channel -> ringbuffer_pagecount << PAGE_SHIFT ) ) ; <S2SV_ModEnd>"
455,<S2SV_ModStart> if ( type_len < 0 ) { return ; } <S2SV_ModEnd>,0,"int qca_tlv_check_data ( struct hci_dev * hdev, struct qca_fw_config * config, u8 * fw_data, size_t fw_size, enum qca_btsoc_type soc_type ) { const u8 * data ; u32 type_len ; u16 tag_id, tag_len ; int idx, length ; struct tlv_type_hdr * tlv ; struct tlv_type_patch * tlv_patch ; struct tlv_type_nvm * tlv_nvm ; uint8_t nvm_baud_rate = config -> user_baud_rate ; config -> dnld_mode = QCA_SKIP_EVT_NONE ; config -> dnld_type = QCA_SKIP_EVT_NONE ; switch ( config -> type ) { case ELF_TYPE_PATCH : if ( fw_size < 7 ) return - EINVAL ; config -> dnld_mode = QCA_SKIP_EVT_VSE_CC ; config -> dnld_type = QCA_SKIP_EVT_VSE_CC ; bt_dev_dbg"
456,<S2SV_ModStart> if ( type_len!= fw_data [ 4 ] ) { return ; } <S2SV_ModEnd>,0,"int qca_tlv_check_data ( struct hci_dev * hdev, struct qca_fw_config * config, u8 * fw_data, size_t fw_size, enum qca_btsoc_type soc_type ) { const u8 * data ; u32 type_len ; u16 tag_id, tag_len ; int idx, length ; struct tlv_type_hdr * tlv ; struct tlv_type_patch * tlv_patch ; struct tlv_type_nvm * tlv_nvm ; uint8_t nvm_baud_rate = config -> user_baud_rate ; config -> dnld_mode = QCA_SKIP_EVT_NONE ; config -> dnld_type = QCA_SKIP_EVT_NONE ; switch ( config -> type ) { case ELF_TYPE_PATCH : if ( fw_size < 7 ) return - EINVAL ; config -> dnld_mode = QCA_SKIP_EVT_VSE_CC ; config -> dnld_type = QCA_SKIP_EVT_VSE_CC ; bt_dev_dbg"
457,<S2SV_ModStart> le32_to_cpu ( tlv -> type_len ) ; <S2SV_ModEnd>,0,"int qca_tlv_check_data ( struct hci_dev * hdev, struct qca_fw_config * config, u8 * fw_data, size_t fw_size, enum qca_btsoc_type soc_type ) { const u8 * data ; u32 type_len ; u16 tag_id, tag_len ; int idx, length ; struct tlv_type_hdr * tlv ; struct tlv_type_patch * tlv_patch ; struct tlv_type_nvm * tlv_nvm ; uint8_t nvm_baud_rate = config -> user_baud_rate ; config -> dnld_mode = QCA_SKIP_EVT_NONE ; config -> dnld_type = QCA_SKIP_EVT_NONE ; switch ( config -> type ) { case ELF_TYPE_PATCH : if ( fw_size < 7 ) return - EINVAL ; config -> dnld_mode = QCA_SKIP_EVT_VSE_CC ; config -> dnld_type = QCA_SKIP_EVT_VSE_CC ; bt_dev_dbg"
458,<S2SV_ModStart> ( type_len < 0 ) || ( type_len > MAX_TLV_DATA ) ) { return ; } <S2SV_ModEnd>,0,"int qca_tlv_check_data ( struct hci_dev * hdev, struct qca_fw_config * config, u8 * fw_data, size_t fw_size, enum qca_btsoc_type soc_type ) { const u8 * data ; u32 type_len ; u16 tag_id, tag_len ; int idx, length ; struct tlv_type_hdr * tlv ; struct tlv_type_patch * tlv_patch ; struct tlv_type_nvm * tlv_nvm ; uint8_t nvm_baud_rate = config -> user_baud_rate ; config -> dnld_mode = QCA_SKIP_EVT_NONE ; config -> dnld_type = QCA_SKIP_EVT_NONE ; switch ( config -> type ) { case ELF_TYPE_PATCH : if ( fw_size < 7 ) return - EINVAL ; config -> dnld_mode = QCA_SKIP_EVT_VSE_CC ; config -> dnld_type = QCA_SKIP_EVT_VSE_CC ; bt_dev_dbg"
459,<S2SV_ModStart> if ( type_len < 0 ) { break ; } <S2SV_ModEnd>,0,"int qca_tlv_check_data ( struct hci_dev * hdev, struct qca_fw_config * config, u8 * fw_data, size_t fw_size, enum qca_btsoc_type soc_type ) { const u8 * data ; u32 type_len ; u16 tag_id, tag_len ; int idx, length ; struct tlv_type_hdr * tlv ; struct tlv_type_patch * tlv_patch ; struct tlv_type_nvm * tlv_nvm ; uint8_t nvm_baud_rate = config -> user_baud_rate ; config -> dnld_mode = QCA_SKIP_EVT_NONE ; config -> dnld_type = QCA_SKIP_EVT_NONE ; switch ( config -> type ) { case ELF_TYPE_PATCH : if ( fw_size < 7 ) return - EINVAL ; config -> dnld_mode = QCA_SKIP_EVT_VSE_CC ; config -> dnld_type = QCA_SKIP_EVT_VSE_CC ; bt_dev_dbg"
460,<S2SV_ModStart> if (! thermal_dbg ) return ; thermal_dbg = cdev -> debugfs ; <S2SV_ModEnd>,0,<S2SV_ModStart> ; mutex_lock ( & cdev -> lock ) ; thermal_dbg = cdev -> debugfs ; if (! thermal_dbg ) { mutex_unlock ( & cdev -> lock ) ; return ; } cdev -> debugfs = NULL ; mutex_unlock ( & cdev -> lock ) ; mutex_lock ( & thermal_dbg -> lock ) ; thermal_debugfs_cdev_clear ( & thermal_dbg -> cdev_dbg ) ; <S2SV_ModEnd>
461,<S2SV_ModStart> if (! thermal_dbg ) return ; thermal_dbg,0,<S2SV_ModStart> ; mutex_lock ( & cdev -> lock ) ; thermal_dbg = cdev -> debugfs ; if (! thermal_dbg ) { mutex_unlock ( & cdev -> lock ) ; return ; } cdev -> debugfs = NULL ; mutex_unlock ( & cdev -> lock ) ; mutex_lock ( & thermal_dbg -> lock ) ; thermal_debugfs_cdev_clear ( & thermal_dbg -> cdev_dbg ) ; <S2SV_ModEnd>
462,<S2SV_ModStart> if (! thermal_dbg ) return ; thermal_dbg = thermal_dbg_get ( ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> ; mutex_lock ( & cdev -> lock ) ; thermal_dbg = cdev -> debugfs ; if (! thermal_dbg ) { mutex_unlock ( & cdev -> lock ) ; return ; } cdev -> debugfs = NULL ; mutex_unlock ( & cdev -> lock ) ; mutex_lock ( & thermal_dbg -> lock ) ; thermal_debugfs_cdev_clear ( & thermal_dbg -> cdev_dbg ) ; <S2SV_ModEnd>
463,<S2SV_ModStart> && cdev -> debugfs ) { thermal_dbg = cdev -> debugfs ; <S2SV_ModEnd>,0,<S2SV_ModStart> ; mutex_lock ( & cdev -> lock ) ; thermal_dbg = cdev -> debugfs ; if (! thermal_dbg ) { mutex_unlock ( & cdev -> lock ) ; return ; } cdev -> debugfs = NULL ; mutex_unlock ( & cdev -> lock ) ; mutex_lock ( & thermal_dbg -> lock ) ; thermal_debugfs_cdev_clear ( & thermal_dbg -> cdev_dbg ) ; <S2SV_ModEnd>
464,<S2SV_ModStart> if (! thermal_dbg ) return ; thermal_dbg = thermal_debugfs_get ( ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> ; mutex_lock ( & cdev -> lock ) ; thermal_dbg = cdev -> debugfs ; if (! thermal_dbg ) { mutex_unlock ( & cdev -> lock ) ; return ; } cdev -> debugfs = NULL ; mutex_unlock ( & cdev -> lock ) ; mutex_lock ( & thermal_dbg -> lock ) ; thermal_debugfs_cdev_clear ( & thermal_dbg -> cdev_dbg ) ; <S2SV_ModEnd>
465,<S2SV_ModStart> if (! fw ) { return - ENOENT ; } <S2SV_ModEnd>,0,<S2SV_ModStart> goto out ; <S2SV_ModEnd>
466,"<S2SV_ModStart> memset ( fw -> data, 0, sizeof ( fw -> data ) ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> goto out ; <S2SV_ModEnd>
467,"<S2SV_ModStart> kzalloc ( size, GFP_KERNEL ) ; <S2SV_ModEnd>",0,<S2SV_ModStart> goto out ; <S2SV_ModEnd>
468,<S2SV_ModStart> fw -> size == 0 ) { return - ENOENT ; } <S2SV_ModEnd>,0,<S2SV_ModStart> goto out ; <S2SV_ModEnd>
469,<S2SV_ModStart> if (! fw ) { return - ENODEV ; } <S2SV_ModEnd>,0,<S2SV_ModStart> goto out ; <S2SV_ModEnd>
470,<S2SV_ModStart> ( unsigned long ) bmval [ 0 ] & NFSD_WRITEONLY_ATTRS_WORD1 ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; args. acl = NULL ; /*
	 * Make a local copy of the attribute bitmap that can be modified.
	 */ attrmask [ 0 ] = bmval [ 0 ] ; attrmask [ 1 ] = bmval [ 1 ] ; attrmask [ 2 ] = bmval [ 2 ] ; args. rdattr_err = 0 ; if ( exp -> ex_fslocs. migrated ) { status = fattr_handle_absent_fs ( & attrmask [ 0 ], & attrmask [ 1 ], & attrmask [ 2 ], & args. rdattr_err ) ; if ( status ) goto out ; } args. size = 0 ; if ( attrmask [ 0 ] & ( FATTR4_WORD0_CHANGE | FATTR4_WORD0_SIZE ) ) { status = nfsd4_deleg_getattr_conflict ( rqstp, d_inode ( dentry ), & file_modified, & size ) ; if ( status ) goto out ; } err = vfs_getattr ( & path, & args. stat, STATX_BASIC_STATS | STATX_BTIME | STATX_CHANGE_COOKIE, AT_"
471,<S2SV_ModStart> ( unsigned long ) bmval [ 1 ] & NFSD_WRITEONLY_ATTRS_WORD1 ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; args. acl = NULL ; /*
	 * Make a local copy of the attribute bitmap that can be modified.
	 */ attrmask [ 0 ] = bmval [ 0 ] ; attrmask [ 1 ] = bmval [ 1 ] ; attrmask [ 2 ] = bmval [ 2 ] ; args. rdattr_err = 0 ; if ( exp -> ex_fslocs. migrated ) { status = fattr_handle_absent_fs ( & attrmask [ 0 ], & attrmask [ 1 ], & attrmask [ 2 ], & args. rdattr_err ) ; if ( status ) goto out ; } args. size = 0 ; if ( attrmask [ 0 ] & ( FATTR4_WORD0_CHANGE | FATTR4_WORD0_SIZE ) ) { status = nfsd4_deleg_getattr_conflict ( rqstp, d_inode ( dentry ), & file_modified, & size ) ; if ( status ) goto out ; } err = vfs_getattr ( & path, & args. stat, STATX_BASIC_STATS | STATX_BTIME | STATX_CHANGE_COOKIE, AT_"
472,<S2SV_ModStart> ( unsigned long ) bmval [ 1 ] & NFSD_WRITEONLY_ATTRS_WORD0 ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; args. acl = NULL ; /*
	 * Make a local copy of the attribute bitmap that can be modified.
	 */ attrmask [ 0 ] = bmval [ 0 ] ; attrmask [ 1 ] = bmval [ 1 ] ; attrmask [ 2 ] = bmval [ 2 ] ; args. rdattr_err = 0 ; if ( exp -> ex_fslocs. migrated ) { status = fattr_handle_absent_fs ( & attrmask [ 0 ], & attrmask [ 1 ], & attrmask [ 2 ], & args. rdattr_err ) ; if ( status ) goto out ; } args. size = 0 ; if ( attrmask [ 0 ] & ( FATTR4_WORD0_CHANGE | FATTR4_WORD0_SIZE ) ) { status = nfsd4_deleg_getattr_conflict ( rqstp, d_inode ( dentry ), & file_modified, & size ) ; if ( status ) goto out ; } err = vfs_getattr ( & path, & args. stat, STATX_BASIC_STATS | STATX_BTIME | STATX_CHANGE_COOKIE, AT_"
473,<S2SV_ModStart> ( unsigned long ) bmval [ 0 ] & NFSD_WRITEONLY_ATTRS_WORD0 ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; args. acl = NULL ; /*
	 * Make a local copy of the attribute bitmap that can be modified.
	 */ attrmask [ 0 ] = bmval [ 0 ] ; attrmask [ 1 ] = bmval [ 1 ] ; attrmask [ 2 ] = bmval [ 2 ] ; args. rdattr_err = 0 ; if ( exp -> ex_fslocs. migrated ) { status = fattr_handle_absent_fs ( & attrmask [ 0 ], & attrmask [ 1 ], & attrmask [ 2 ], & args. rdattr_err ) ; if ( status ) goto out ; } args. size = 0 ; if ( attrmask [ 0 ] & ( FATTR4_WORD0_CHANGE | FATTR4_WORD0_SIZE ) ) { status = nfsd4_deleg_getattr_conflict ( rqstp, d_inode ( dentry ), & file_modified, & size ) ; if ( status ) goto out ; } err = vfs_getattr ( & path, & args. stat, STATX_BASIC_STATS | STATX_BTIME | STATX_CHANGE_COOKIE, AT_"
474,<S2SV_ModStart> ( unsigned long ) attr_bitmap [ 0 ] ; <S2SV_ModEnd>,0,"<S2SV_ModStart> ; args. acl = NULL ; /*
	 * Make a local copy of the attribute bitmap that can be modified.
	 */ attrmask [ 0 ] = bmval [ 0 ] ; attrmask [ 1 ] = bmval [ 1 ] ; attrmask [ 2 ] = bmval [ 2 ] ; args. rdattr_err = 0 ; if ( exp -> ex_fslocs. migrated ) { status = fattr_handle_absent_fs ( & attrmask [ 0 ], & attrmask [ 1 ], & attrmask [ 2 ], & args. rdattr_err ) ; if ( status ) goto out ; } args. size = 0 ; if ( attrmask [ 0 ] & ( FATTR4_WORD0_CHANGE | FATTR4_WORD0_SIZE ) ) { status = nfsd4_deleg_getattr_conflict ( rqstp, d_inode ( dentry ), & file_modified, & size ) ; if ( status ) goto out ; } err = vfs_getattr ( & path, & args. stat, STATX_BASIC_STATS | STATX_BTIME | STATX_CHANGE_COOKIE, AT_"
475,<S2SV_ModStart> if ( error < 0 ) { return error ; } <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
476,<S2SV_ModStart> if ( error ) { kfree ( pctldev -> desc -> pins ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
477,<S2SV_ModStart> kfree ( pinctrl_claim_hogs ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
478,<S2SV_ModStart> if ( error < 0 ) { error = pinctrl_claim_hogs ( pctldev ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
479,<S2SV_ModStart> kfree ( pctldev -> desc -> pins ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
480,<S2SV_ModStart> (! ( tile -> pkthdrstream ) ) ) { return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> jpc_streamlist_numstreams ( dec -> pkthdrstreams )!= 0 &&! ( tile -> pkthdrstream = jpc_streamlist_remove ( dec -> pkthdrstreams, 0 ) ) ) { return - 1 ; <S2SV_ModEnd>"
481,<S2SV_ModStart> if (! ( tile -> pkthdrstream ) ) { return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> jpc_streamlist_numstreams ( dec -> pkthdrstreams )!= 0 &&! ( tile -> pkthdrstream = jpc_streamlist_remove ( dec -> pkthdrstreams, 0 ) ) ) { return - 1 ; <S2SV_ModEnd>"
482,<S2SV_ModStart> if (! ( tile -> pkthdrstream ) ) ) { return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> jpc_streamlist_numstreams ( dec -> pkthdrstreams )!= 0 &&! ( tile -> pkthdrstream = jpc_streamlist_remove ( dec -> pkthdrstreams, 0 ) ) ) { return - 1 ; <S2SV_ModEnd>"
483,<S2SV_ModStart> (! tile -> pkthdrstream ) ) { return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> jpc_streamlist_numstreams ( dec -> pkthdrstreams )!= 0 &&! ( tile -> pkthdrstream = jpc_streamlist_remove ( dec -> pkthdrstreams, 0 ) ) ) { return - 1 ; <S2SV_ModEnd>"
484,<S2SV_ModStart>! ( tile -> pkthdrstream ) ) { return - 1 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> jpc_streamlist_numstreams ( dec -> pkthdrstreams )!= 0 &&! ( tile -> pkthdrstream = jpc_streamlist_remove ( dec -> pkthdrstreams, 0 ) ) ) { return - 1 ; <S2SV_ModEnd>"
485,<S2SV_ModStart> && ppci -> table_group ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> * There is an exception to the above. In case the PE goes into frozen
	 * state, firmware may not provide ibm,dma-window property at the time
	 * of LPAR boot up.
	 */ if (! pdn ) { pr_debug ( ""  no ibm,dma-window property!\n"" ) ; return ; } <S2SV_ModEnd>"
486,<S2SV_ModStart> if (! pdn ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> * There is an exception to the above. In case the PE goes into frozen
	 * state, firmware may not provide ibm,dma-window property at the time
	 * of LPAR boot up.
	 */ if (! pdn ) { pr_debug ( ""  no ibm,dma-window property!\n"" ) ; return ; } <S2SV_ModEnd>"
487,<S2SV_ModStart> && prop. window_size > 0 ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> * There is an exception to the above. In case the PE goes into frozen
	 * state, firmware may not provide ibm,dma-window property at the time
	 * of LPAR boot up.
	 */ if (! pdn ) { pr_debug ( ""  no ibm,dma-window property!\n"" ) ; return ; } <S2SV_ModEnd>"
488,<S2SV_ModStart> && prop. window_size > 0 ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> * There is an exception to the above. In case the PE goes into frozen
	 * state, firmware may not provide ibm,dma-window property at the time
	 * of LPAR boot up.
	 */ if (! pdn ) { pr_debug ( ""  no ibm,dma-window property!\n"" ) ; return ; } <S2SV_ModEnd>"
489,<S2SV_ModStart> if (! prop. window_size ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> * There is an exception to the above. In case the PE goes into frozen
	 * state, firmware may not provide ibm,dma-window property at the time
	 * of LPAR boot up.
	 */ if (! pdn ) { pr_debug ( ""  no ibm,dma-window property!\n"" ) ; return ; } <S2SV_ModEnd>"
490,<S2SV_ModStart> kfree ( pkind -> rsrc. bmap ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
491,<S2SV_ModStart> kfree ( pkind -> counters. bmap ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
492,<S2SV_ModStart> if ( rvu -> kpu_fwdata ) iounmap ( rvu -> kpu_fwdata ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
493,<S2SV_ModStart> kfree ( pkind -> counter. bmap ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
494,<S2SV_ModStart> kfree ( rvu -> kpu_fwdata ) ; <S2SV_ModEnd>,0,<S2SV_ModStart> <S2SV_ModEnd>
495,"<S2SV_ModStart> kzalloc ( nla_total_size ( 1 ) + nla_total_size ( 4 ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> rtmsg ) ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>"
496,"<S2SV_ModStart> kzalloc ( nla_total_size ( 1 ) + nla_total_size ( 4 ) + nla_total_size ( 2 ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> rtmsg ) ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>"
497,"<S2SV_ModStart> kzalloc ( nla_total_size ( 1 ) + nla_total_size ( 4 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> rtmsg ) ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>"
498,"<S2SV_ModStart> kzalloc ( sizeof ( ifaddrmsg ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> rtmsg ) ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>"
499,"<S2SV_ModStart> kzalloc ( nla_total_size ( 1 ) + nla_total_size ( 4 ) + nla_total_size ( 2 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> rtmsg ) ) + nla_total_size ( 1 ) + nla_total_size ( 4 ), GFP_KERNEL ) ; <S2SV_ModEnd>"
500,<S2SV_ModStart> if (! tz ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> struct tz_episode * tze, * tmp ; struct tz_debugfs * tz_dbg ; int * trips_crossed ; if (! thermal_dbg ) return ; tz_dbg = & thermal_dbg -> tz_dbg ; mutex_lock ( & thermal_dbg -> lock ) ; trips_crossed = tz_dbg -> trips_crossed ; list_for_each_entry_safe ( tze, tmp, & tz_dbg -> tz_episodes, node ) { list_del ( & tze -> node ) ; kfree ( tze ) ; } tz -> debugfs = NULL ; mutex_unlock ( & thermal_dbg -> lock ) ; thermal_debugfs_remove_id ( thermal_dbg ) ; kfree ( trips_crossed ) ; <S2SV_ModEnd>"
501,<S2SV_ModStart> if (! thermal_dbg ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> struct tz_episode * tze, * tmp ; struct tz_debugfs * tz_dbg ; int * trips_crossed ; if (! thermal_dbg ) return ; tz_dbg = & thermal_dbg -> tz_dbg ; mutex_lock ( & thermal_dbg -> lock ) ; trips_crossed = tz_dbg -> trips_crossed ; list_for_each_entry_safe ( tze, tmp, & tz_dbg -> tz_episodes, node ) { list_del ( & tze -> node ) ; kfree ( tze ) ; } tz -> debugfs = NULL ; mutex_unlock ( & thermal_dbg -> lock ) ; thermal_debugfs_remove_id ( thermal_dbg ) ; kfree ( trips_crossed ) ; <S2SV_ModEnd>"
502,<S2SV_ModStart>! thermal_dbg ||! tz -> debugfs ) return ; <S2SV_ModEnd>,0,"<S2SV_ModStart> struct tz_episode * tze, * tmp ; struct tz_debugfs * tz_dbg ; int * trips_crossed ; if (! thermal_dbg ) return ; tz_dbg = & thermal_dbg -> tz_dbg ; mutex_lock ( & thermal_dbg -> lock ) ; trips_crossed = tz_dbg -> trips_crossed ; list_for_each_entry_safe ( tze, tmp, & tz_dbg -> tz_episodes, node ) { list_del ( & tze -> node ) ; kfree ( tze ) ; } tz -> debugfs = NULL ; mutex_unlock ( & thermal_dbg -> lock ) ; thermal_debugfs_remove_id ( thermal_dbg ) ; kfree ( trips_crossed ) ; <S2SV_ModEnd>"
503,<S2SV_ModStart> if (! thermal_dbg ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct tz_episode * tze, * tmp ; struct tz_debugfs * tz_dbg ; int * trips_crossed ; if (! thermal_dbg ) return ; tz_dbg = & thermal_dbg -> tz_dbg ; mutex_lock ( & thermal_dbg -> lock ) ; trips_crossed = tz_dbg -> trips_crossed ; list_for_each_entry_safe ( tze, tmp, & tz_dbg -> tz_episodes, node ) { list_del ( & tze -> node ) ; kfree ( tze ) ; } tz -> debugfs = NULL ; mutex_unlock ( & thermal_dbg -> lock ) ; thermal_debugfs_remove_id ( thermal_dbg ) ; kfree ( trips_crossed ) ; <S2SV_ModEnd>"
504,<S2SV_ModStart> if (! tz ) { return ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> struct tz_episode * tze, * tmp ; struct tz_debugfs * tz_dbg ; int * trips_crossed ; if (! thermal_dbg ) return ; tz_dbg = & thermal_dbg -> tz_dbg ; mutex_lock ( & thermal_dbg -> lock ) ; trips_crossed = tz_dbg -> trips_crossed ; list_for_each_entry_safe ( tze, tmp, & tz_dbg -> tz_episodes, node ) { list_del ( & tze -> node ) ; kfree ( tze ) ; } tz -> debugfs = NULL ; mutex_unlock ( & thermal_dbg -> lock ) ; thermal_debugfs_remove_id ( thermal_dbg ) ; kfree ( trips_crossed ) ; <S2SV_ModEnd>"
505,"<S2SV_ModStart> kzalloc ( len << 2, GFP_KERNEL ) ; <S2SV_ModEnd>",0,"<S2SV_ModStart> memdup_user_nul ( buf, nbytes ) ; <S2SV_ModEnd>"
506,<S2SV_ModStart> if (! nbytes ) return - EINVAL ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, nbytes ) ; <S2SV_ModEnd>"
507,<S2SV_ModStart> kfree ( regrd_debug -> regdata ) ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, nbytes ) ; <S2SV_ModEnd>"
508,<S2SV_ModStart> if (! nbytes ) { return - EINVAL ; } <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, nbytes ) ; <S2SV_ModEnd>"
509,<S2SV_ModStart> if (! nbytes ) return 0 ; <S2SV_ModEnd>,0,"<S2SV_ModStart> memdup_user_nul ( buf, nbytes ) ; <S2SV_ModEnd>"
